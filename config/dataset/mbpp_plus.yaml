# @package dataset
# MBPP+ dataset configuration
#
# MBPP+ (Mostly Basic Python Problems Plus) is an enhanced version of MBPP
# with 35x more test cases for rigorous evaluation of code generation.
#
# Dataset: https://huggingface.co/datasets/evalplus/mbppplus
# EvalPlus: https://github.com/evalplus/evalplus
# - 378 coding problems (test split)
# - Each problem: prompt -> function implementation

dataset_path: "evalplus/mbppplus"
dataset_split: "test"  # 378 problems
subset: null  # Only process first N samples (null for all)
prompt_file: null  # No prompt template - EvalPlus API provides correct format
answer_format: "code"  # Code generation format
question_field: "question"  # EvalPlus loader uses "question" field
answer_field: "answer"  # EvalPlus loader uses "answer" field
data_name: "mbpp_plus"  # Used for evaluation routing and EvalPlus API loading

# Fields from EvalPlus API loader (llm_tts/datasets/mbpp_plus.py):
# - question: Problem prompt with docstring and example assertion (correct format!)
# - answer: Canonical solution code
# - task_id: Unique identifier (e.g., "Mbpp/2")
# - entry_point: Expected function name
# - test_list: Basic test assertions
# - assertion: Full assertion text
# - base_input, plus_input: Test inputs for full evaluation
