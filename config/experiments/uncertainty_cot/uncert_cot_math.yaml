# @package _global_
# Run: CUDA_VISIBLE_DEVICES=0 python scripts/run_tts_eval.py --config-path=../config --config-name=experiments/uncertainty_cot/uncert_cot_math
# Note: Do NOT specify CUDA_VISIBLE_DEVICES when submitting via scripts/slurm/submit.sh - SLURM assigns GPUs automatically

# Run naming
run_name: "seed${system.seed}_${now:%H-%M-%S}"

defaults:
  - /config
  - /dataset/minerva_math
  - /model/hf_qwen3
  - /generation/default
  - /system/default
  - /scorer/entropy
  - /evaluation/default
  - _self_

model:
  type: "local"
  model_path: "Qwen/Qwen3-8B"
  model_short_name: "hf_qwen3_8b"  # Short name for output directory organization
  disable_thinking_mode: true
  device: cuda

generation:
  allow_newlines: true

strategy:
  type: "uncertainty_cot"
  uncertainty_sampling: "sequence"
  candidates_per_step: 8
  max_steps: 20
  max_empty_steps: 5
  uncertainty_threshold: 0.1

  detector_step_patterns: [
            "\n**Step",
            "\n## Step",
            "\n- Step",
            "- Step",
            "\nStep",
        ]
  detector_answer_patterns: [
            "<Answer>:",
            "<answer>:",
            "final answer",
            "Final answer",
            "Answer:",
            "Answer: ",
            "answer:",
            "Answer is",
            "answer is",
            "<end of response>",
            "<|im_end|>",
        ]

dataset:
  prompt_file: ./config/prompts/default.txt
output:
  resume: false

system:
  seed: 42
  hf_cache: ".cache/huggingface"
  device: cuda
