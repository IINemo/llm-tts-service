# @package _global_
# Run: CUDA_VISIBLE_DEVICES=0,1 python scripts/run_tts_eval.py --config-path=../config --config-name=experiments/beam_search/minerva_math/beam_search_vllm_k2_think_minerva_math_llm_critic
#
# Beam Search with LLM Critic Scorer (Tree of Thoughts paper)
# Uses vLLM for local GPU inference on Minerva Math dataset
# Model: LLM360/K2-Think (33B)
#
# Based on: "Tree of Thoughts: Deliberate Problem Solving with Large Language Models"
# Paper: https://arxiv.org/abs/2305.10601

defaults:
  - /config
  - /dataset/minerva_math
  - /model/vllm_qwen3
  - /generation/default
  - /system/default
  - /strategy/beam_search
  - /scorer/llm_critic
  - /evaluation/default
  - _self_

# Run naming
run_name: "beam_search_vllm_k2_think_minerva_math_llm_critic_${now:%H-%M-%S}"

# Main configuration
verbose: true
report_to: wandb
wandb_project: llm-tts-eval-minerva-math
wandb_group: "beam_search_k2_think_minerva_math_llm_critic"

# Model overrides (LLM360/K2-Think instead of default Qwen3-8B)
model:
  model_path: "LLM360/K2-Think"
  model_short_name: "k2_think"
  max_model_len: 4096
  disable_thinking_mode: true

# Generation overrides
generation:
  max_new_tokens: 4096
  max_length: 8192

# Strategy overrides
strategy:
  beam_size: 5
  candidates_per_beam: 8
  max_steps: 30
  min_step_tokens: 10
  max_step_tokens: 256
  custom_words:
    - "for example"
    - "given that"
    - "similarly"
    - "step"
    - "therefore"
    - "thus"

# Scorer overrides
scorer:
  max_tokens: 100
  timeout: 120

# Dataset overrides
dataset:
  data_name: minerva_math
  prompt_template: "{question}"
