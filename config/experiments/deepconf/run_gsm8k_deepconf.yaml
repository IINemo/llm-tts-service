# @package _global_

defaults:
  - /dataset/gsm8k
  - /model/openrouter
  - /generation/default
  - /output/default
  - /system/default
  - _self_

# Main configuration
verbose: false

# Evaluation method: "simple" (numeric comparison) or "llm_judge" (LLM-based verification)
eval_method: llm_judge

# Model configuration (API-based)
model:
  provider: openrouter
  model_name: "openai/gpt-3.5-turbo"
  api_key: null  # Set via OPENROUTER_API_KEY env var
  top_logprobs: 20  # Required for DeepConf

# Generation settings
generation:
  max_new_tokens: 2048
  temperature: 0.6
  top_p: 0.95
  batch_size: 1

# DeepConf strategy (no scorer needed)
scorer: null

strategy:
  type: deepconf
  mode: offline  # Options: "offline", "online"
  # Offline mode parameters
  budget: 8  # Number of reasoning traces to generate
  # Online mode parameters (not used in offline mode)
  warmup_traces: 4
  total_budget: 16
  confidence_percentile: 90
  # Common parameters
  window_size: 2048
  filter_method: "top10"  # Options: "none", "top10", "threshold"
  confidence_threshold: null

# Evaluator for correctness checking
evaluator:
  provider: openrouter
  base_url: https://openrouter.ai/api/v1
  model: openai/gpt-3.5-turbo
  n_threads: 1

# Dataset settings (inherited from dataset/gsm8k.yaml)
dataset:
  subset: 3  # Start with 3 samples for testing
