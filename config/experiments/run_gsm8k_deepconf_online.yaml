# @package _global_

# DeepConf Online Mode Configuration
# This demonstrates adaptive early stopping with streaming + logprobs

defaults:
  - /dataset/gsm8k
  - /model/openrouter
  - /generation/default
  - /output/default
  - /system/default
  - _self_

# Main configuration
verbose: false

# Evaluation method: "simple" (numeric comparison) or "llm_judge" (LLM-based verification)
eval_method: llm_judge

# Model configuration (API-based)
model:
  provider: openrouter
  model_name: "openai/gpt-4o-mini"
  api_key: null  # Set via OPENROUTER_API_KEY env var
  top_logprobs: 20  # Required for DeepConf

# Generation settings
generation:
  max_new_tokens: 512
  temperature: 0.7
  top_p: 1.0
  batch_size: 1

# DeepConf strategy (no scorer needed)
scorer: null

# DeepConf online mode strategy
strategy:
  type: deepconf
  mode: "online"  # Enable online mode with adaptive early stopping

  # Budget (not used in online mode but required by config)
  budget: 10

  # Online mode parameters
  warmup_traces: 3  # Initial traces to establish confidence threshold
  total_budget: 10  # Total traces (warmup + adaptive)
  confidence_percentile: 10  # Use 90th percentile as threshold (100 - 10)

  # Generation parameters
  window_size: 5  # Sliding window for confidence computation
  temperature: 0.7
  top_p: 1.0
  max_tokens: 512
  top_logprobs: 20

  # Filtering and voting
  filter_method: "top5"  # Use top-5 traces by confidence

# Evaluator for correctness checking
evaluator:
  provider: openrouter
  base_url: https://openrouter.ai/api/v1
  model: openai/gpt-3.5-turbo
  n_threads: 1

# Dataset settings
dataset:
  subset: 10  # Number of examples to evaluate
