# @package _global_

hydra:
  run:
    dir: ${save_dir}/eval/${now:%Y-%m-%d}/${now:%H-%M-%S}

save_dir: "./workdir"  # Directory to save results (will create validity/redundancy subdirs)

defaults:
  - dataset: math
  - generation: default
  - system: default
  - scorer: uncertainty_pd
  - evaluation/llm_judge: default
  - evaluation/alignscore: default
  - _self_

model:
  type: "local"
  model_path: "Qwen/Qwen3-8B"
  disable_thinking_mode: true
  device: cuda

strategy:
  type: "uncertainty_cot"
  candidates_per_step: 3
  max_steps: 10
  max_empty_steps: 5
  uncertainty_threshold: 0.35

  detector_step_patterns: [
            "\n**Step",
            "\n## Step",
            "\n- Step",
            "- Step",
            "\nStep",
        ]
  detector_answer_patterns: [
            # "<Answer>:",
            # "<answer>:",
            # "final answer",
            # "Final answer",
            # "Answer:",
            # "Answer: ",
            # "answer:",
            # "Answer is",
            # "answer is",
            "<end of response>",
            "<|im_end|>",
        ]

generation:
  temperature: 0.7
  max_new_tokens: 512
  batch_size: 1
  top_p: 0.95
  top_k: 50

dataset:
  subset: 200
  # prompt_file: ./config/prompts/gsm8k.txt

evaluation:
  evaluators: [exact_match, alignscore]
  # evaluators: [llm_judge, exact_match, alignscore]
  alignscore:
    threshold: 0.5
    ckpt_path: https://huggingface.co/yzha/AlignScore/resolve/main/AlignScore-large.ckpt
    batch_size: 16
    target_is_claims: true

output:
  resume: false

system:
  seed: 42
  hf_cache: ".cache/huggingface"
  device: cuda
