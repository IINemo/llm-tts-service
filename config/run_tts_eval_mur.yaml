# @package _global_

defaults:
  - output: default
  - _self_

# Main configuration

dataset:
  dataset_path: "gsm8k"
  dataset_config: "main"
  dataset_split: "test"
  subset: 5
  prompt_file: "./config/prompts/default.txt"

model:
  type: "vllm"
  model_path: "Qwen/Qwen3-1.7B"
  gpu_memory_utilization: 0.6
  max_model_len: 16384

generation:
  temperature: 0.6  # Generation temperature
  max_new_tokens: 2048  # Max tokens per step
  sequential_generation: false  # Generate candidates one by one to save memory
  logprobs: 20

scorer:
  type: uncertainty

evaluator:
  base_url: https://api.deepseek.com/v1
  model: deepseek-reasoner
  n_threads: 1

strategy:
  type: mur
  max_steps: 10
  momentum_rate: 0.9
  scaling_rate: 0.9
  select_best: "entropy" # perplexity or entropy
  candidate_num: 4
  critic_model_path: "None"

system:
  device: "cuda:0"  # Device to use for base model
  seed: 42  # Random seed
  hf_cache: null  # HuggingFace cache directory
