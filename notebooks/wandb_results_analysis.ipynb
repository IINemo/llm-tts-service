{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W&B Results Analysis\n",
    "\n",
    "Pull experiment metrics from Weights & Biases, build comparison tables, and export LaTeX for the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad.smirnov/miniconda3/envs/lm-polygraph-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.Api()] Loaded credentials for https://api.wandb.ai from /home/vlad.smirnov/.netrc.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except ImportError:\n",
    "    sns = None\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "\n",
    "# Load .env from project root (parent of notebooks/)\n",
    "load_dotenv(Path(__file__).resolve().parent.parent / \".env\" if \"__file__\" in dir() else Path.cwd().parent / \".env\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", 40)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Configuration ──────────────────────────────────────────────────────────────\n",
    "#\n",
    "# Organized by dataset -> strategy. Each group entry is a dict with:\n",
    "#   \"group_url\":  link to the wandb group workspace\n",
    "#   \"runs\":       list of {\"seed\": <int>, \"run_url\": \"<url>\"}\n",
    "#\n",
    "# Single-group strategies (baseline, self_consistency):\n",
    "#   use a single dict wrapped in a list: [{\"group_url\": ..., \"runs\": [...]}]\n",
    "#\n",
    "# Multi-group strategies (offline_bon, beam_search, MUR — one group per scorer/aggregation/window):\n",
    "#   use a list of dicts: [{\"group_url\": ..., \"runs\": [...]}, ...]\n",
    "#\n",
    "# Fill in the URLs. Entries with empty group_url or runs are skipped.\n",
    "\n",
    "# ── MATH 500 ─────────────────────────────────────────────────────────────────\n",
    "\n",
    "MATH500_BASELINE_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/baseline_qwen25_math_7b_instruct_math500\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/baseline_qwen25_math_7b_instruct_math500/runs/qz0418nv\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/baseline_qwen25_math_7b_instruct_math500/runs/3bqhwvgp\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/baseline_qwen25_math_7b_instruct_math500/runs/bjzqimk4\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MATH500_SELF_CONSISTENCY_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/self_consistency_qwen25_math_7b_math500\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/self_consistency_qwen25_math_7b_math500/runs/ky44b84m\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/self_consistency_qwen25_math_7b_math500/runs/gtia4gii\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/self_consistency_qwen25_math_7b_math500/runs/v87vmndj\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MATH500_OFFLINE_BON_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/offline_bon_qwen25_math_7b_instruct_math500_multi_scorer\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/offline_bon_qwen25_math_7b_instruct_math500_multi_scorer/runs/c35z6knc\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/offline_bon_qwen25_math_7b_instruct_math500_multi_scorer/runs/d7jh7cbj\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/offline_bon_qwen25_math_7b_instruct_math500_multi_scorer/runs/cz45vmb2\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MATH500_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/offline_bon_qwen25_math_7b_instruct_math500_prm/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/offline_bon_qwen25_math_7b_instruct_math500_prm/runs/5tafmoey?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/offline_bon_qwen25_math_7b_instruct_math500_prm/runs/jhbjo8i7?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy/runs/xwne3zcp?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy/runs/i6h64mu9?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy/runs/q4irrx7s?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity/runs/j52otygf?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity/runs/2jxse47c?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity/runs/furt84c3?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob/runs/p81rd7g2?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob/runs/xzlye3bd?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob/runs/1gqrkkbz?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_all_mean/workspace?nw=nwuserkarantonis\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_all_mean/runs/3vyvg771?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_all_mean/runs/a403svwj?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_all_mean/runs/ym9gurc8?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "        # TODO: LLM_AS_A_CRITIC\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "        # TODO: UHEAD\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MATH500_BEAM_SEARCH_ALL_STEPS_MIN_RUNS = []\n",
    "\n",
    "MATH500_BEAM_SEARCH_5_STEPS_MEAN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_prm_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_prm_window_5_mean/runs/a5czzn30?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy_window_5_mean/runs/ymsvscl0?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy_window_5_mean/runs/pwzb338g?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy_window_5_mean/runs/35flk5hs?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity_window_5_mean/runs/wyx5epvb?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity_window_5_mean/runs/6nvxalna?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity_window_5_mean/runs/cr02x91m?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob_window_5_mean/runs/sgz5baov?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob_window_5_mean/runs/3aal8hbt?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob_window_5_mean/runs/invmjf46?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_5_mean/runs/t9izflf2?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_5_mean/runs/jgwxu1tf?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_5_mean/runs/1hib1872?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: LLM_AS_A_CRITIC\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MATH500_BEAM_SEARCH_5_STEPS_MIN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_prm_window_5_min/workspace?nw=nwuserkarantonis\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_prm_window_5_min/runs/xsq5qs98?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "{\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy_window_5_min/runs/s63imxgn?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy_window_5_min/runs/lboffbb6?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy_window_5_min/runs/3ty4qabr?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity_window_5_min/runs/71lpyfud?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity_window_5_min/runs/jdneto0g?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity_window_5_min/runs/s704cw0h?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob_window_5_min/runs/i0k09agh?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob_window_5_min/runs/xk8esovp?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob_window_5_min/runs/w8p45jwz?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_5_min/runs/9krm0sgu?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_5_min/runs/z0sfyacp?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_5_min/runs/rxvhmt25?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: LLM_AS_A_CRITIC\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MATH500_BEAM_SEARCH_RUNS = [\n",
    "    *MATH500_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS,\n",
    "    *MATH500_BEAM_SEARCH_ALL_STEPS_MIN_RUNS,\n",
    "    *MATH500_BEAM_SEARCH_5_STEPS_MEAN_RUNS,\n",
    "    *MATH500_BEAM_SEARCH_5_STEPS_MIN_RUNS,\n",
    "]\n",
    "\n",
    "MATH500_MUR_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_prm\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_prm/runs/vd5vmy7u\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_prm/runs/1a781e39\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_prm/runs/rj4rt3i2\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_entropy\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_entropy/runs/tfztdzjl\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_entropy/runs/ggqllnmy\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_entropy/runs/aw88mzyl\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_perplexity\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_perplexity/runs/r6oumz5s\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_perplexity/runs/4ds5ewag\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_perplexity/runs/5xe2x66l\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_sequence_prob\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_sequence_prob/runs/j9a1j7mx\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_sequence_prob/runs/zcdc7nni\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_sequence_prob/runs/otrelz7z\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: UHEAD\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MATH500_RUNS = [\n",
    "    *MATH500_BASELINE_RUNS,\n",
    "    *MATH500_SELF_CONSISTENCY_RUNS,\n",
    "    *MATH500_OFFLINE_BON_RUNS,\n",
    "    *MATH500_BEAM_SEARCH_RUNS,\n",
    "    *MATH500_MUR_RUNS,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'group_url': '',\n",
       "  'runs': [{'seed': 42, 'run_url': ''},\n",
       "   {'seed': 43, 'run_url': ''},\n",
       "   {'seed': 44, 'run_url': ''}]},)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"group_url\": \"\",\n",
    "    \"runs\": [\n",
    "        {\n",
    "            \"seed\": 42,\n",
    "            \"run_url\": \"\"\n",
    "        },\n",
    "        {\n",
    "            \"seed\": 43,\n",
    "            \"run_url\": \"\"\n",
    "        },\n",
    "        {\n",
    "            \"seed\": 44,\n",
    "            \"run_url\": \"\"\n",
    "        },\n",
    "    ]\n",
    "},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Minerva Math ─────────────────────────────────────────────────────────────\n",
    "\n",
    "MINERVA_BASELINE_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/baseline_qwen25_math_7b_instruct_minerva_math\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/baseline_qwen25_math_7b_instruct_minerva_math/runs/96zj1bj9\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/baseline_qwen25_math_7b_instruct_minerva_math/runs/uyw4bmip\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/baseline_qwen25_math_7b_instruct_minerva_math/runs/qmm3t3wa\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MINERVA_SELF_CONSISTENCY_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/self_consistency_qwen25_math_7b_minerva_math\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/self_consistency_qwen25_math_7b_minerva_math/runs/pnfkhzub\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/self_consistency_qwen25_math_7b_minerva_math/runs/puabpgai\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/self_consistency_qwen25_math_7b_minerva_math/runs/697xpya5\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MINERVA_OFFLINE_BON_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/offline_bon_qwen25_math_7b_instruct_minerva_math_multi_scorer\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/offline_bon_qwen25_math_7b_instruct_minerva_math_multi_scorer/runs/7syo0ks4\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/offline_bon_qwen25_math_7b_instruct_minerva_math_multi_scorer/runs/y6udmktu\"},\n",
    "            # TODO: seed 44\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MINERVA_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MINERVA_BEAM_SEARCH_ALL_STEPS_MIN_RUNS = []\n",
    "\n",
    "MINERVA_BEAM_SEARCH_5_STEPS_MEAN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MINERVA_BEAM_SEARCH_5_STEPS_MIN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MINERVA_BEAM_SEARCH_RUNS = [\n",
    "    *MINERVA_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS,\n",
    "    *MINERVA_BEAM_SEARCH_ALL_STEPS_MIN_RUNS,\n",
    "    *MINERVA_BEAM_SEARCH_5_STEPS_MEAN_RUNS,\n",
    "    *MINERVA_BEAM_SEARCH_5_STEPS_MIN_RUNS,\n",
    "]\n",
    "\n",
    "MINERVA_MUR_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_prm\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_prm/runs/06l86wmp\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_prm/runs/rj3c55xp\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_prm/runs/mqxinev9\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_entropy\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_entropy/runs/6x67bplt\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_entropy/runs/9byp8if5\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_entropy/runs/baw3autg\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_perplexity\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_perplexity/runs/fdqevqae\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_perplexity/runs/v9d5f19e\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_perplexity/runs/1kotu42g\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_sequence_prob\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_sequence_prob/runs/hhvycd8w\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_sequence_prob/runs/u9jsfizr\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_sequence_prob/runs/s1mch3ag\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MINERVA_RUNS = [\n",
    "    *MINERVA_BASELINE_RUNS,\n",
    "    *MINERVA_SELF_CONSISTENCY_RUNS,\n",
    "    *MINERVA_OFFLINE_BON_RUNS,\n",
    "    *MINERVA_BEAM_SEARCH_RUNS,\n",
    "    *MINERVA_MUR_RUNS,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Gaokao 2023 EN ──────────────────────────────────────────────────────────\n",
    "\n",
    "GAOKAO_BASELINE_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/baseline_qwen25_math_7b_instruct_gaokao2023en\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/baseline_qwen25_math_7b_instruct_gaokao2023en/runs/kv4jtvgi\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/baseline_qwen25_math_7b_instruct_gaokao2023en/runs/oj4i6jcg\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/baseline_qwen25_math_7b_instruct_gaokao2023en/runs/9jdwpyk5\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "GAOKAO_SELF_CONSISTENCY_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/self_consistency_qwen25_math_7b_gaokao2023en\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/self_consistency_qwen25_math_7b_gaokao2023en/runs/fr4b84ia\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/self_consistency_qwen25_math_7b_gaokao2023en/runs/cbuxlxty\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/self_consistency_qwen25_math_7b_gaokao2023en/runs/66ny6wia\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "GAOKAO_OFFLINE_BON_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/offline_bon_qwen25_math_7b_instruct_gaokao2023en_multi_scorer\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/offline_bon_qwen25_math_7b_instruct_gaokao2023en_multi_scorer/runs/qijvr95c\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/offline_bon_qwen25_math_7b_instruct_gaokao2023en_multi_scorer/runs/jboxbdly\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/offline_bon_qwen25_math_7b_instruct_gaokao2023en_multi_scorer/runs/nh8fx6pk\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "GAOKAO_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "GAOKAO_BEAM_SEARCH_ALL_STEPS_MIN_RUNS = []\n",
    "\n",
    "GAOKAO_BEAM_SEARCH_5_STEPS_MEAN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "GAOKAO_BEAM_SEARCH_5_STEPS_MIN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "GAOKAO_BEAM_SEARCH_RUNS = [\n",
    "    *GAOKAO_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS,\n",
    "    *GAOKAO_BEAM_SEARCH_ALL_STEPS_MIN_RUNS,\n",
    "    *GAOKAO_BEAM_SEARCH_5_STEPS_MEAN_RUNS,\n",
    "    *GAOKAO_BEAM_SEARCH_5_STEPS_MIN_RUNS,\n",
    "]\n",
    "\n",
    "\n",
    "GAOKAO_MUR_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_prm\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_prm/runs/s0fidl75\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_prm/runs/0ualpblk\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_prm/runs/32rg3g3i\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_entropy\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_entropy/runs/hi6vme52\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_entropy/runs/8803ke4z\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_entropy/runs/2b58rqn2\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_perplexity\",\n",
    "        \"runs\": [\n",
    "            # TODO: {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_perplexity/runs/t72yerk9\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_perplexity/runs/udabjan5\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_sequence_prob\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_sequence_prob/runs/w39yrjlx\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_sequence_prob/runs/tg0re0ml\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_sequence_prob/runs/h8ceyznr\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "GAOKAO_RUNS = [\n",
    "    *GAOKAO_BASELINE_RUNS,\n",
    "    *GAOKAO_SELF_CONSISTENCY_RUNS,\n",
    "    *GAOKAO_OFFLINE_BON_RUNS,\n",
    "    *GAOKAO_BEAM_SEARCH_RUNS,\n",
    "    *GAOKAO_MUR_RUNS,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── OlympiadBench ────────────────────────────────────────────────────────────\n",
    "\n",
    "OLYMPIAD_BASELINE_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/baseline_qwen25_math_7b_instruct_olympiadbench\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/baseline_qwen25_math_7b_instruct_olympiadbench/runs/jzmy8hfc\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/baseline_qwen25_math_7b_instruct_olympiadbench/runs/xlys9l9j\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/baseline_qwen25_math_7b_instruct_olympiadbench/runs/b72k2bg3\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "OLYMPIAD_SELF_CONSISTENCY_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/self_consistency_qwen25_math_7b_instruct_olympiadbench\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/self_consistency_qwen25_math_7b_instruct_olympiadbench/runs/fvfzlj30\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/self_consistency_qwen25_math_7b_instruct_olympiadbench/runs/ig5z868b\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/self_consistency_qwen25_math_7b_instruct_olympiadbench/runs/ivwtmfrj\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "OLYMPIAD_OFFLINE_BON_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/offline_bon_qwen25_math_7b_instruct_olympiadbench_multi_scorer\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/offline_bon_qwen25_math_7b_instruct_olympiadbench_multi_scorer/runs/scg2r5g6\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/offline_bon_qwen25_math_7b_instruct_olympiadbench_multi_scorer/runs/lrbsr0b6\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/offline_bon_qwen25_math_7b_instruct_olympiadbench_multi_scorer/runs/gzpylxq2\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "OLYMPIAD_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "OLYMPIAD_BEAM_SEARCH_ALL_STEPS_MIN_RUNS = []\n",
    "\n",
    "OLYMPIAD_BEAM_SEARCH_5_STEPS_MEAN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "OLYMPIAD_BEAM_SEARCH_5_STEPS_MIN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "OLYMPIAD_BEAM_SEARCH_RUNS = [\n",
    "    *OLYMPIAD_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS,\n",
    "    *OLYMPIAD_BEAM_SEARCH_ALL_STEPS_MIN_RUNS,\n",
    "    *OLYMPIAD_BEAM_SEARCH_5_STEPS_MEAN_RUNS,\n",
    "    *OLYMPIAD_BEAM_SEARCH_5_STEPS_MIN_RUNS,\n",
    "]\n",
    "\n",
    "OLYMPIAD_MUR_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_prm\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_prm/runs/i6z1krhj\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_prm/runs/6wvon0ez\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_prm/runs/tdm1eork\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_entropy\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_entropy/runs/vd94h0mo\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_entropy/runs/wf7xwmeq\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_entropy/runs/mysyvdxk\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_perplexity\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_perplexity/runs/v94x4z5v\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_perplexity/runs/j0wpb22k\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_perplexity/runs/ma4yye4m\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_sequence_prob\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_sequence_prob/runs/9yrxl5jg\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_sequence_prob/runs/ux4lvczy\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_sequence_prob/runs/3i0vyyzt\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "OLYMPIAD_RUNS = [\n",
    "    *OLYMPIAD_BASELINE_RUNS,\n",
    "    *OLYMPIAD_SELF_CONSISTENCY_RUNS,\n",
    "    *OLYMPIAD_OFFLINE_BON_RUNS,\n",
    "    *OLYMPIAD_BEAM_SEARCH_RUNS,\n",
    "    *OLYMPIAD_MUR_RUNS,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── GPQA Diamond ─────────────────────────────────────────────────────────────\n",
    "\n",
    "GPQA_BASELINE_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "GPQA_EXTENDED_THINKING_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "GPQA_SELF_CONSISTENCY_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "GPQA_OFFLINE_BON_RUNS = []\n",
    "\n",
    "GPQA_BEAM_SEARCH_RUNS = []\n",
    "\n",
    "GPQA_RUNS = [\n",
    "    *GPQA_BASELINE_RUNS,\n",
    "    *GPQA_EXTENDED_THINKING_RUNS,\n",
    "    *GPQA_SELF_CONSISTENCY_RUNS,\n",
    "    *GPQA_OFFLINE_BON_RUNS,\n",
    "    *GPQA_BEAM_SEARCH_RUNS,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── AIME 2024 ────────────────────────────────────────────────────────────────\n",
    "\n",
    "AIME_24_BASELINE_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/baseline_qwen3_8b_thinking_aime2024\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/baseline_qwen3_8b_thinking_aime2024/runs/xusm290p\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/baseline_qwen3_8b_thinking_aime2024/runs/rb5f45zd\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/baseline_qwen3_8b_thinking_aime2024/runs/ue7upatj\"},\n",
    "            {\"seed\": 45, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/baseline_qwen3_8b_thinking_aime2024/runs/2pxd5k62\"},\n",
    "            {\"seed\": 46, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/baseline_qwen3_8b_thinking_aime2024/runs/7wjepb0g\"},\n",
    "            {\"seed\": 47, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/baseline_qwen3_8b_thinking_aime2024/runs/mmvefyvq\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "AIME_24_EXTENDED_THINKING_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/extended_thinking_qwen3_8b_thinking_aime2024\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/extended_thinking_qwen3_8b_thinking_aime2024/runs/zpdp973a\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/extended_thinking_qwen3_8b_thinking_aime2024/runs/toj7if32\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/extended_thinking_qwen3_8b_thinking_aime2024/runs/nofu424d\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "AIME_24_SELF_CONSISTENCY_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/self_consistency_qwen3_8b_thinking_aime2024\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/self_consistency_qwen3_8b_thinking_aime2024/runs/myd2mv7s\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/self_consistency_qwen3_8b_thinking_aime2024/runs/xffzht86\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/self_consistency_qwen3_8b_thinking_aime2024/runs/1pwqvj98\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "AIME_24_OFFLINE_BON_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/offline_bon_qwen3_8b_thinking_aime2024_multi_scorer\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/offline_bon_qwen3_8b_thinking_aime2024_multi_scorer/runs/b8ljb1q8\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/offline_bon_qwen3_8b_thinking_aime2024_multi_scorer/runs/p3pcxz2f\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/offline_bon_qwen3_8b_thinking_aime2024_multi_scorer/runs/my2dup72\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "AIME_24_BEAM_SEARCH_RUNS = []\n",
    "\n",
    "AIME_24_MUR_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_prm\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_prm/runs/it11687o\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_prm/runs/jff7wjvc\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_prm/runs/lkq82tbw\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_entropy\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_entropy/runs/0e8v1y8k\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_entropy/runs/0ohmk93u\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_entropy/runs/r3835jcu\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_perplexity/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_perplexity/runs/6akbzucw\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_perplexity/runs/mqw6z61b\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_perplexity/runs/27slpoyj\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_sequence_prob\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_sequence_prob/runs/siootyv4\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_sequence_prob/runs/pbeoa8wj\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_sequence_prob/runs/ehlo2jyt\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "AIME_24_RUNS = [\n",
    "    *AIME_24_BASELINE_RUNS,\n",
    "    *AIME_24_EXTENDED_THINKING_RUNS,\n",
    "    *AIME_24_SELF_CONSISTENCY_RUNS,\n",
    "    *AIME_24_OFFLINE_BON_RUNS,\n",
    "    *AIME_24_BEAM_SEARCH_RUNS,\n",
    "    *AIME_24_MUR_RUNS,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── AIME 2025 ────────────────────────────────────────────────────────────────\n",
    "\n",
    "AIME_25_BASELINE_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/baseline_qwen3_8b_thinking_aime2025\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/baseline_qwen3_8b_thinking_aime2025/runs/5z4xazfd\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/baseline_qwen3_8b_thinking_aime2025/runs/z8961dmg\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/baseline_qwen3_8b_thinking_aime2025/runs/vqkeqd8l\"},\n",
    "            {\"seed\": 45, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/baseline_qwen3_8b_thinking_aime2025/runs/8ng35cm8\"},\n",
    "            {\"seed\": 46, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/baseline_qwen3_8b_thinking_aime2025/runs/y6l7gl0x\"},\n",
    "            {\"seed\": 47, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/baseline_qwen3_8b_thinking_aime2025/runs/bvz1mgw4\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "AIME_25_EXTENDED_THINKING_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/extended_thinking_qwen3_8b_thinking_aime2025\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/extended_thinking_qwen3_8b_thinking_aime2025/runs/ynjskyb9\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/extended_thinking_qwen3_8b_thinking_aime2025/runs/xw5oie56\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/extended_thinking_qwen3_8b_thinking_aime2025/runs/uufgljky\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "AIME_25_SELF_CONSISTENCY_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/self_consistency_qwen3_8b_thinking_aime2025/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/self_consistency_qwen3_8b_thinking_aime2025/runs/e03jj1df\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/self_consistency_qwen3_8b_thinking_aime2025/runs/4o5fp278\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/self_consistency_qwen3_8b_thinking_aime2025/runs/yvpwgde3\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "AIME_25_OFFLINE_BON_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/offline_bon_qwen3_8b_thinking_aime2025_multi_scorer\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/offline_bon_qwen3_8b_thinking_aime2025_multi_scorer/runs/ja291w66\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/offline_bon_qwen3_8b_thinking_aime2025_multi_scorer/runs/x7govl6j\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/offline_bon_qwen3_8b_thinking_aime2025_multi_scorer/runs/qgbbh2v3\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "AIME_25_BEAM_SEARCH_RUNS = []\n",
    "\n",
    "AIME_25_MUR_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_thinking_qwen3_8b_aime2025_prm/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_thinking_qwen3_8b_aime2025_prm/runs/e42u6g0w\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_thinking_qwen3_8b_aime2025_prm/runs/3nne68cg\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_thinking_qwen3_8b_aime2025_prm/runs/upxrnkxo\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_entropy\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_entropy/runs/d8m88x5o\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_entropy/runs/hor6ahou\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_entropy/runs/exlootac\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_thinking_qwen3_8b_aime2025_perplexity\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_thinking_qwen3_8b_aime2025_perplexity/runs/3hsaelln\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_thinking_qwen3_8b_aime2025_perplexity/runs/jertvzag\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_thinking_qwen3_8b_aime2025_perplexity/runs/8o0wi4y3\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_sequence_prob\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_sequence_prob/runs/tce8t6fy\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_sequence_prob/runs/krs5db1u\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_sequence_prob/runs/1ieu2i5k\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "AIME_25_RUNS = [\n",
    "    *AIME_25_BASELINE_RUNS,\n",
    "    *AIME_25_EXTENDED_THINKING_RUNS,\n",
    "    *AIME_25_SELF_CONSISTENCY_RUNS,\n",
    "    *AIME_25_OFFLINE_BON_RUNS,\n",
    "    *AIME_25_BEAM_SEARCH_RUNS,\n",
    "    *AIME_25_MUR_RUNS,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── HumanEval-Plus ────────────────────────────────────────────────────────────\n",
    "\n",
    "HUMANEVAL_BASELINE_RUNS = []\n",
    "\n",
    "HUMANEVAL_EXTENDED_THINKING_RUNS = []\n",
    "\n",
    "HUMANEVAL_SELF_CONSISTENCY_RUNS = []\n",
    "\n",
    "HUMANEVAL_OFFLINE_BON_RUNS = []\n",
    "\n",
    "HUMANEVAL_BEAM_SEARCH_RUNS = []\n",
    "\n",
    "HUMANEVAL_MUR_RUNS = []\n",
    "\n",
    "HUMANEVAL_RUNS = [\n",
    "    *HUMANEVAL_BASELINE_RUNS,\n",
    "    *HUMANEVAL_EXTENDED_THINKING_RUNS,\n",
    "    *HUMANEVAL_SELF_CONSISTENCY_RUNS,\n",
    "    *HUMANEVAL_OFFLINE_BON_RUNS,\n",
    "    *HUMANEVAL_BEAM_SEARCH_RUNS,\n",
    "    *HUMANEVAL_MUR_RUNS,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── All experiments ──────────────────────────────────────────────────────────\n",
    "\n",
    "EXPERIMENT_RUNS = [\n",
    "    *MATH500_RUNS,\n",
    "    *MINERVA_RUNS,\n",
    "    *GAOKAO_RUNS,\n",
    "    *OLYMPIAD_RUNS,\n",
    "    *GPQA_RUNS,\n",
    "    *AIME_24_RUNS,\n",
    "    *AIME_25_RUNS,\n",
    "    *HUMANEVAL_RUNS,\n",
    "]\n",
    "\n",
    "# Which evaluator metric to use as the primary accuracy column\n",
    "PRIMARY_EVALUATOR = \"exact_match\"  # or \"llm_judge\"\n",
    "\n",
    "GROUP_FILTERS = None  # e.g. [\"beam_search\", \"offline_bon\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed Coverage Tables\n",
    "\n",
    "Quick overview of how many seeds (1/2/3) are registered for each (strategy, scorer, dataset) combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Qwen2.5-Math-7B-Instruct (Non-Thinking) — Seed Coverage</h3><table style=\"border-collapse:collapse;font-family:sans-serif;font-size:14px\"><tr><th style=\"padding:6px 12px;border-bottom:2px solid #333;text-align:center\">Strategy</th><th style=\"padding:6px 12px;border-bottom:2px solid #333;text-align:center\">Scorer</th><th style=\"padding:6px 12px;border-bottom:2px solid #333;text-align:center\">MATH-500</th><th style=\"padding:6px 12px;border-bottom:2px solid #333;text-align:center\">OlympiadBench</th><th style=\"padding:6px 12px;border-bottom:2px solid #333;text-align:center\">Minerva Math</th><th style=\"padding:6px 12px;border-bottom:2px solid #333;text-align:center\">Gaokao 2023 EN</th></tr><tr style=\"\"><td rowspan=\"1\" style=\"padding:4px 12px;font-weight:bold;text-align:left\">Raw CoT<br>(non-thinking)</td><td style=\"padding:4px 12px;text-align:left\">—</td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/baseline_qwen25_math_7b_instruct_math500\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/baseline_qwen25_math_7b_instruct_olympiadbench\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/baseline_qwen25_math_7b_instruct_minerva_math\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/baseline_qwen25_math_7b_instruct_gaokao2023en\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td></tr><tr style=\"border-top:1px solid #ccc;\"><td rowspan=\"1\" style=\"padding:4px 12px;font-weight:bold;text-align:left\">Majority Voting<br>(self-consistency)</td><td style=\"padding:4px 12px;text-align:left\">—</td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/self_consistency_qwen25_math_7b_math500\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/self_consistency_qwen25_math_7b_instruct_olympiadbench\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/self_consistency_qwen25_math_7b_minerva_math\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/self_consistency_qwen25_math_7b_gaokao2023en\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td></tr><tr style=\"border-top:1px solid #ccc;\"><td rowspan=\"1\" style=\"padding:4px 12px;font-weight:bold;text-align:left\">Offline BoN</td><td style=\"padding:4px 12px;text-align:left\">multi_scorer</td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/offline_bon_qwen25_math_7b_instruct_math500_multi_scorer\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/offline_bon_qwen25_math_7b_instruct_olympiadbench_multi_scorer\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/offline_bon_qwen25_math_7b_instruct_minerva_math_multi_scorer\" target=\"_blank\" style=\"background:#fef9e7;padding:2px 8px;border-radius:3px;color:#f1c40f;font-weight:bold;text-decoration:none\">2</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/offline_bon_qwen25_math_7b_instruct_gaokao2023en_multi_scorer\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td></tr><tr style=\"border-top:1px solid #ccc;\"><td rowspan=\"4\" style=\"padding:4px 12px;font-weight:bold;vertical-align:middle;text-align:left\">MUR</td><td style=\"padding:4px 12px;text-align:left\">prm</td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_prm\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_prm\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_prm\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_prm\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td></tr><tr style=\"\"><td style=\"padding:4px 12px;text-align:left\">entropy</td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_entropy\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_entropy\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_entropy\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_entropy\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td></tr><tr style=\"\"><td style=\"padding:4px 12px;text-align:left\">perplexity</td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_perplexity\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_perplexity\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_perplexity\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_perplexity\" target=\"_blank\" style=\"background:#fef9e7;padding:2px 8px;border-radius:3px;color:#f1c40f;font-weight:bold;text-decoration:none\">2</a></td></tr><tr style=\"\"><td style=\"padding:4px 12px;text-align:left\">sequence_prob</td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_sequence_prob\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_sequence_prob\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_sequence_prob\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_sequence_prob\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Qwen3-8B (Thinking Mode) — Seed Coverage</h3><table style=\"border-collapse:collapse;font-family:sans-serif;font-size:14px\"><tr><th style=\"padding:6px 12px;border-bottom:2px solid #333;text-align:center\">Strategy</th><th style=\"padding:6px 12px;border-bottom:2px solid #333;text-align:center\">Scorer</th><th style=\"padding:6px 12px;border-bottom:2px solid #333;text-align:center\">AIME-2024</th><th style=\"padding:6px 12px;border-bottom:2px solid #333;text-align:center\">AIME-2025</th><th style=\"padding:6px 12px;border-bottom:2px solid #333;text-align:center\">HumanEval-Plus</th></tr><tr style=\"\"><td rowspan=\"1\" style=\"padding:4px 12px;font-weight:bold;text-align:left\">Raw CoT<br>(thinking)</td><td style=\"padding:4px 12px;text-align:left\">—</td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/baseline_qwen3_8b_thinking_aime2024\" target=\"_blank\" style=\"background:#eee;padding:2px 8px;border-radius:3px;color:#333;font-weight:bold;text-decoration:none\">6</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/baseline_qwen3_8b_thinking_aime2025\" target=\"_blank\" style=\"background:#eee;padding:2px 8px;border-radius:3px;color:#333;font-weight:bold;text-decoration:none\">6</a></td><td style=\"padding:4px 12px;text-align:center\"><span style=\"background:#fdedec;padding:2px 8px;border-radius:3px;color:#e74c3c;font-weight:bold\">0</span></td></tr><tr style=\"border-top:1px solid #ccc;\"><td rowspan=\"1\" style=\"padding:4px 12px;font-weight:bold;text-align:left\">Extended Thinking CoT</td><td style=\"padding:4px 12px;text-align:left\">—</td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/extended_thinking_qwen3_8b_thinking_aime2024\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/extended_thinking_qwen3_8b_thinking_aime2025\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><span style=\"background:#fdedec;padding:2px 8px;border-radius:3px;color:#e74c3c;font-weight:bold\">0</span></td></tr><tr style=\"border-top:1px solid #ccc;\"><td rowspan=\"1\" style=\"padding:4px 12px;font-weight:bold;text-align:left\">Majority Voting<br>(self-consistency)</td><td style=\"padding:4px 12px;text-align:left\">—</td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/self_consistency_qwen3_8b_thinking_aime2024\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/self_consistency_qwen3_8b_thinking_aime2025/workspace\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><span style=\"background:#fdedec;padding:2px 8px;border-radius:3px;color:#e74c3c;font-weight:bold\">0</span></td></tr><tr style=\"border-top:1px solid #ccc;\"><td rowspan=\"1\" style=\"padding:4px 12px;font-weight:bold;text-align:left\">Offline BoN</td><td style=\"padding:4px 12px;text-align:left\">multi_scorer</td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/offline_bon_qwen3_8b_thinking_aime2024_multi_scorer\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/offline_bon_qwen3_8b_thinking_aime2025_multi_scorer\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><span style=\"background:#fdedec;padding:2px 8px;border-radius:3px;color:#e74c3c;font-weight:bold\">0</span></td></tr><tr style=\"border-top:1px solid #ccc;\"><td rowspan=\"4\" style=\"padding:4px 12px;font-weight:bold;vertical-align:middle;text-align:left\">MUR</td><td style=\"padding:4px 12px;text-align:left\">prm</td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_prm\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><span style=\"background:#fdedec;padding:2px 8px;border-radius:3px;color:#e74c3c;font-weight:bold\">0</span></td><td style=\"padding:4px 12px;text-align:center\"><span style=\"background:#fdedec;padding:2px 8px;border-radius:3px;color:#e74c3c;font-weight:bold\">0</span></td></tr><tr style=\"\"><td style=\"padding:4px 12px;text-align:left\">entropy</td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_entropy\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_entropy\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><span style=\"background:#fdedec;padding:2px 8px;border-radius:3px;color:#e74c3c;font-weight:bold\">0</span></td></tr><tr style=\"\"><td style=\"padding:4px 12px;text-align:left\">perplexity</td><td style=\"padding:4px 12px;text-align:center\"><span style=\"background:#fdedec;padding:2px 8px;border-radius:3px;color:#e74c3c;font-weight:bold\">0</span></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_thinking_qwen3_8b_aime2025_perplexity\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><span style=\"background:#fdedec;padding:2px 8px;border-radius:3px;color:#e74c3c;font-weight:bold\">0</span></td></tr><tr style=\"\"><td style=\"padding:4px 12px;text-align:left\">sequence_prob</td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_sequence_prob\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><a href=\"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_sequence_prob\" target=\"_blank\" style=\"background:#eafaf1;padding:2px 8px;border-radius:3px;color:#27ae60;font-weight:bold;text-decoration:none\">3</a></td><td style=\"padding:4px 12px;text-align:center\"><span style=\"background:#fdedec;padding:2px 8px;border-radius:3px;color:#e74c3c;font-weight:bold\">0</span></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ── Seed Coverage: Qwen2.5-Math-7B-Instruct (Non-Thinking) ─────────────────\n",
    "\n",
    "import re as _re\n",
    "from urllib.parse import urlparse as _urlparse\n",
    "\n",
    "\n",
    "def _extract_scorer_from_group_url(url: str) -> str:\n",
    "    \"\"\"Extract scorer name from group URL (last segment after dataset name).\"\"\"\n",
    "    path = _urlparse(url).path.strip(\"/\")\n",
    "    group = path.split(\"/\")[-1]  # e.g. adaptive_scaling_qwen25_..._math500_prm\n",
    "    for scorer in [\"prm\", \"entropy\", \"perplexity\", \"sequence_prob\", \"uncertainty_pd\", \"multi_scorer\"]:\n",
    "        if group.endswith(f\"_{scorer}\"):\n",
    "            return scorer\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def _count_seeds_with_url(run_list: list) -> tuple:\n",
    "    \"\"\"Count total seeds and return group URL. Returns (count, url).\"\"\"\n",
    "    total = 0\n",
    "    url = \"\"\n",
    "    for entry in run_list:\n",
    "        if entry.get(\"group_url\"):\n",
    "            total += len(entry.get(\"runs\", []))\n",
    "            if not url:\n",
    "                url = entry[\"group_url\"]\n",
    "    return total, url\n",
    "\n",
    "\n",
    "def _count_seeds_by_scorer_with_url(run_list: list) -> dict:\n",
    "    \"\"\"Count seeds per scorer with group URLs. Returns {scorer: (count, url)}.\"\"\"\n",
    "    result = {}\n",
    "    for entry in run_list:\n",
    "        if not entry.get(\"group_url\"):\n",
    "            continue\n",
    "        scorer = _extract_scorer_from_group_url(entry[\"group_url\"])\n",
    "        result[scorer] = (len(entry.get(\"runs\", [])), entry[\"group_url\"])\n",
    "    return result\n",
    "\n",
    "\n",
    "def _color_cell(n_seeds, url=\"\"):\n",
    "    \"\"\"Return styled HTML for seed count, optionally as a clickable link.\"\"\"\n",
    "    colors = {0: \"#e74c3c\", 1: \"#e67e22\", 2: \"#f1c40f\", 3: \"#27ae60\"}\n",
    "    bg = {0: \"#fdedec\", 1: \"#fdebd0\", 2: \"#fef9e7\", 3: \"#eafaf1\"}\n",
    "    style = (\n",
    "        f'background:{bg.get(n_seeds, \"#eee\")};'\n",
    "        f'padding:2px 8px;border-radius:3px;'\n",
    "        f'color:{colors.get(n_seeds, \"#333\")};font-weight:bold'\n",
    "    )\n",
    "    if url:\n",
    "        return (\n",
    "            f'<a href=\"{url}\" target=\"_blank\" '\n",
    "            f'style=\"{style};text-decoration:none\">{n_seeds}</a>'\n",
    "        )\n",
    "    return f'<span style=\"{style}\">{n_seeds}</span>'\n",
    "\n",
    "\n",
    "def build_coverage_table(title, coverage_map, datasets, strategy_order, strategy_labels,\n",
    "                         multi_scorer_strategies=None, scorer_list=None,\n",
    "                         scorer_overrides=None):\n",
    "    \"\"\"Build an HTML coverage table with rowspan-merged strategy cells.\n",
    "\n",
    "    Args:\n",
    "        title: Table heading.\n",
    "        coverage_map: {dataset: {strategy_key: run_list, ...}, ...}\n",
    "        datasets: Column order for datasets.\n",
    "        strategy_order: Row order for strategies.\n",
    "        strategy_labels: {strategy_key: display_name}\n",
    "        multi_scorer_strategies: Set of strategy keys that have per-scorer breakdowns.\n",
    "        scorer_list: Ordered list of scorers for multi-scorer strategies.\n",
    "    \"\"\"\n",
    "    if multi_scorer_strategies is None:\n",
    "        multi_scorer_strategies = set()\n",
    "    if scorer_list is None:\n",
    "        scorer_list = [\"prm\", \"entropy\", \"perplexity\", \"sequence_prob\"]\n",
    "    if scorer_overrides is None:\n",
    "        scorer_overrides = {}\n",
    "\n",
    "    # Build row specs: list of (strategy_label, scorer, {ds: (count, url)})\n",
    "    row_specs = []\n",
    "    for strat in strategy_order:\n",
    "        label = strategy_labels.get(strat, strat)\n",
    "        if strat in multi_scorer_strategies:\n",
    "            for scorer in scorer_overrides.get(strat, scorer_list):\n",
    "                cells = {}\n",
    "                for ds in datasets:\n",
    "                    by_scorer = _count_seeds_by_scorer_with_url(coverage_map[ds][strat])\n",
    "                    cells[ds] = by_scorer.get(scorer, (0, \"\"))\n",
    "                row_specs.append((label, scorer, cells))\n",
    "        else:\n",
    "            cells = {}\n",
    "            for ds in datasets:\n",
    "                cells[ds] = _count_seeds_with_url(coverage_map[ds][strat])\n",
    "            row_specs.append((label, \"\", cells))\n",
    "\n",
    "    # Compute rowspans per strategy group\n",
    "    from collections import Counter\n",
    "    strategy_counts = Counter(r[0] for r in row_specs)\n",
    "\n",
    "    th = 'style=\"padding:6px 12px;border-bottom:2px solid #333;text-align:center\"'\n",
    "    html = f\"<h3>{title}</h3>\"\n",
    "    html += '<table style=\"border-collapse:collapse;font-family:sans-serif;font-size:14px\">'\n",
    "    html += f\"<tr><th {th}>Strategy</th><th {th}>Scorer</th>\"\n",
    "    for ds in datasets:\n",
    "        html += f\"<th {th}>{ds}</th>\"\n",
    "    html += \"</tr>\"\n",
    "\n",
    "    seen_strategies = set()\n",
    "    for label, scorer, cells in row_specs:\n",
    "        first_in_group = label not in seen_strategies\n",
    "        border = \"border-top:1px solid #ccc;\" if first_in_group and seen_strategies else \"\"\n",
    "        html += f'<tr style=\"{border}\">'\n",
    "\n",
    "        # Strategy cell: rowspan on first row, skip on subsequent\n",
    "        if first_in_group:\n",
    "            rs = strategy_counts[label]\n",
    "            va = \"vertical-align:middle;\" if rs > 1 else \"\"\n",
    "            html += (\n",
    "                f'<td rowspan=\"{rs}\" style=\"padding:4px 12px;font-weight:bold;'\n",
    "                f'{va}text-align:left\">{label}</td>'\n",
    "            )\n",
    "            seen_strategies.add(label)\n",
    "\n",
    "        # Scorer cell (left-aligned)\n",
    "        scorer_display = scorer if scorer else \"—\"\n",
    "        html += f'<td style=\"padding:4px 12px;text-align:left\">{scorer_display}</td>'\n",
    "\n",
    "        # Dataset cells\n",
    "        for ds in datasets:\n",
    "            n, url = cells[ds]\n",
    "            html += f'<td style=\"padding:4px 12px;text-align:center\">{_color_cell(n, url)}</td>'\n",
    "\n",
    "        html += \"</tr>\"\n",
    "\n",
    "    html += \"</table>\"\n",
    "    return html\n",
    "\n",
    "\n",
    "# ── Build Qwen2.5-Math-7B table ──\n",
    "QWEN25_COVERAGE = {\n",
    "    \"MATH-500\": {\n",
    "        \"baseline\": MATH500_BASELINE_RUNS,\n",
    "        \"self_consistency\": MATH500_SELF_CONSISTENCY_RUNS,\n",
    "        \"mur\": MATH500_MUR_RUNS,\n",
    "        \"offline_bon\": MATH500_OFFLINE_BON_RUNS,\n",
    "    },\n",
    "    \"OlympiadBench\": {\n",
    "        \"baseline\": OLYMPIAD_BASELINE_RUNS,\n",
    "        \"self_consistency\": OLYMPIAD_SELF_CONSISTENCY_RUNS,\n",
    "        \"mur\": OLYMPIAD_MUR_RUNS,\n",
    "        \"offline_bon\": OLYMPIAD_OFFLINE_BON_RUNS,\n",
    "    },\n",
    "    \"Minerva Math\": {\n",
    "        \"baseline\": MINERVA_BASELINE_RUNS,\n",
    "        \"self_consistency\": MINERVA_SELF_CONSISTENCY_RUNS,\n",
    "        \"mur\": MINERVA_MUR_RUNS,\n",
    "        \"offline_bon\": MINERVA_OFFLINE_BON_RUNS,\n",
    "    },\n",
    "    \"Gaokao 2023 EN\": {\n",
    "        \"baseline\": GAOKAO_BASELINE_RUNS,\n",
    "        \"self_consistency\": GAOKAO_SELF_CONSISTENCY_RUNS,\n",
    "        \"mur\": GAOKAO_MUR_RUNS,\n",
    "        \"offline_bon\": GAOKAO_OFFLINE_BON_RUNS,\n",
    "    },\n",
    "}\n",
    "\n",
    "DATASETS_QWEN25 = [\"MATH-500\", \"OlympiadBench\", \"Minerva Math\", \"Gaokao 2023 EN\"]\n",
    "\n",
    "html = build_coverage_table(\n",
    "    title=\"Qwen2.5-Math-7B-Instruct (Non-Thinking) \\u2014 Seed Coverage\",\n",
    "    coverage_map=QWEN25_COVERAGE,\n",
    "    datasets=DATASETS_QWEN25,\n",
    "    strategy_order=[\"baseline\", \"self_consistency\", \"offline_bon\", \"mur\"],\n",
    "    strategy_labels={\n",
    "        \"baseline\": \"Raw CoT<br>(non-thinking)\",\n",
    "        \"self_consistency\": \"Majority Voting<br>(self-consistency)\",\n",
    "        \"offline_bon\": \"Offline BoN\",\n",
    "        \"mur\": \"MUR\"\n",
    "    },\n",
    "    multi_scorer_strategies={\"mur\", \"offline_bon\"},\n",
    "    scorer_overrides={\"offline_bon\": [\"multi_scorer\"]},\n",
    ")\n",
    "\n",
    "from IPython.display import HTML\n",
    "display(HTML(html))\n",
    "\n",
    "# ── Seed Coverage: Qwen3-8B (Thinking Mode) ──────────────────────────────────\n",
    "\n",
    "QWEN3_COVERAGE = {\n",
    "    \"AIME-2024\": {\n",
    "        \"baseline\": AIME_24_BASELINE_RUNS,\n",
    "        \"extended_thinking\": AIME_24_EXTENDED_THINKING_RUNS,\n",
    "        \"self_consistency\": AIME_24_SELF_CONSISTENCY_RUNS,\n",
    "        \"offline_bon\": AIME_24_OFFLINE_BON_RUNS,\n",
    "        \"mur\": AIME_24_MUR_RUNS,\n",
    "    },\n",
    "    \"AIME-2025\": {\n",
    "        \"baseline\": AIME_25_BASELINE_RUNS,\n",
    "        \"extended_thinking\": AIME_25_EXTENDED_THINKING_RUNS,\n",
    "        \"self_consistency\": AIME_25_SELF_CONSISTENCY_RUNS,\n",
    "        \"offline_bon\": AIME_25_OFFLINE_BON_RUNS,\n",
    "        \"mur\": AIME_25_MUR_RUNS,\n",
    "    },\n",
    "    \"HumanEval-Plus\": {\n",
    "        \"baseline\": HUMANEVAL_BASELINE_RUNS,\n",
    "        \"extended_thinking\": HUMANEVAL_EXTENDED_THINKING_RUNS,\n",
    "        \"self_consistency\": HUMANEVAL_SELF_CONSISTENCY_RUNS,\n",
    "        \"offline_bon\": HUMANEVAL_OFFLINE_BON_RUNS,\n",
    "        \"mur\": HUMANEVAL_MUR_RUNS,\n",
    "    },\n",
    "}\n",
    "\n",
    "DATASETS_QWEN3 = [\"AIME-2024\", \"AIME-2025\", \"HumanEval-Plus\"]\n",
    "\n",
    "html_qwen3 = build_coverage_table(\n",
    "    title=\"Qwen3-8B (Thinking Mode) \\u2014 Seed Coverage\",\n",
    "    coverage_map=QWEN3_COVERAGE,\n",
    "    datasets=DATASETS_QWEN3,\n",
    "    strategy_order=[\"baseline\", \"extended_thinking\", \"self_consistency\", \"offline_bon\", \"mur\"],\n",
    "    strategy_labels={\n",
    "        \"baseline\": \"Raw CoT<br>(thinking)\",\n",
    "        \"extended_thinking\": \"Extended Thinking CoT\",\n",
    "        \"self_consistency\": \"Majority Voting<br>(self-consistency)\",\n",
    "        \"offline_bon\": \"Offline BoN\",\n",
    "        \"mur\": \"MUR\",\n",
    "    },\n",
    "    multi_scorer_strategies={\"mur\", \"offline_bon\"},\n",
    "    scorer_overrides={\"offline_bon\": [\"multi_scorer\"]},\n",
    ")\n",
    "\n",
    "display(HTML(html_qwen3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching runs:   0%|          | 0/124 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: baseline_qwen25_math_7b_instruct_math500\n",
      "  seed=42  finished  exact_match=0.8320  llm_judge=0.8380\n",
      "  seed=43  finished  exact_match=0.8320  llm_judge=0.8380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching runs:   1%|          | 1/124 [00:02<04:19,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  seed=44  finished  exact_match=0.8320  llm_judge=0.8400\n",
      "Group: self_consistency_qwen25_math_7b_math500\n",
      "  seed=42  finished  exact_match=0.8620  llm_judge=0.8660\n",
      "  seed=43  finished  exact_match=0.8700  llm_judge=0.8740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching runs:   2%|▏         | 2/124 [00:04<04:50,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  seed=44  finished  exact_match=0.8600  llm_judge=0.8660\n",
      "Group: offline_bon_qwen25_math_7b_instruct_math500_multi_scorer\n",
      "  seed=42  finished  exact_match=0.8500  llm_judge=0.8540\n",
      "  seed=43  finished  exact_match=0.8540  llm_judge=0.8580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching runs:   2%|▏         | 3/124 [00:09<06:03,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  seed=44  finished  exact_match=0.8340  llm_judge=0.8420\n",
      "Group: offline_bon_qwen25_math_7b_instruct_math500_prm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot parse run URL: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 96\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m run_entry \u001b[38;5;129;01min\u001b[39;00m entry[\u001b[33m\"\u001b[39m\u001b[33mruns\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m     95\u001b[39m     seed = run_entry[\u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     run_info = \u001b[43mparse_run_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_entry\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_url\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     98\u001b[39m         record = fetch_run(run_info[\u001b[33m\"\u001b[39m\u001b[33mentity\u001b[39m\u001b[33m\"\u001b[39m], run_info[\u001b[33m\"\u001b[39m\u001b[33mproject\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     99\u001b[39m                            run_info[\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m], group_name, seed)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mparse_run_url\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m     23\u001b[39m m = re.match(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m^(?P<entity>[^/]+)/(?P<project>[^/]+)/(?:groups/[^/]+/)?runs/(?P<run_id>[^/]+)\u001b[39m\u001b[33m\"\u001b[39m, path)\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot parse run URL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m m.groupdict()\n",
      "\u001b[31mValueError\u001b[39m: Cannot parse run URL: "
     ]
    }
   ],
   "source": [
    "# ── Data Fetching ─────────────────────────────────────────────────────────────\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "def parse_group_url(url: str) -> dict:\n",
    "    \"\"\"Extract entity, project, and group name from a wandb group URL.\"\"\"\n",
    "    path = urlparse(url).path.strip(\"/\")\n",
    "    m = re.match(r\"^(?P<entity>[^/]+)/(?P<project>[^/]+)/groups/(?P<group>[^/]+)\", path)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse group URL: {url}\")\n",
    "    return m.groupdict()\n",
    "\n",
    "\n",
    "def parse_run_url(url: str) -> dict:\n",
    "    \"\"\"Extract entity, project, and run_id from a wandb run URL.\n",
    "\n",
    "    Handles both formats:\n",
    "      .../runs/RUN_ID\n",
    "      .../groups/GROUP/runs/RUN_ID\n",
    "    \"\"\"\n",
    "    path = urlparse(url).path.strip(\"/\")\n",
    "    m = re.match(r\"^(?P<entity>[^/]+)/(?P<project>[^/]+)/(?:groups/[^/]+/)?runs/(?P<run_id>[^/]+)\", path)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse run URL: {url}\")\n",
    "    return m.groupdict()\n",
    "\n",
    "\n",
    "def fetch_run(entity: str, project: str, run_id: str, group_name: str, seed: int) -> dict:\n",
    "    \"\"\"Fetch a single run and return a flat record dict.\"\"\"\n",
    "    run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "    cfg = run.config\n",
    "    s = run.summary._json_dict\n",
    "\n",
    "    strategy_cfg = cfg.get(\"strategy\", {})\n",
    "    scorer_cfg = cfg.get(\"scorer\", {})\n",
    "    model_cfg = cfg.get(\"model\", {})\n",
    "    dataset_cfg = cfg.get(\"dataset\", {})\n",
    "    system_cfg = cfg.get(\"system\", {})\n",
    "\n",
    "    return {\n",
    "        # identifiers\n",
    "        \"run_id\": run.id,\n",
    "        \"run_name\": run.name,\n",
    "        \"group\": group_name,\n",
    "        \"state\": run.state,\n",
    "        \"project\": project,\n",
    "        \"entity\": entity,\n",
    "        \"seed\": seed,\n",
    "        # config fields\n",
    "        \"strategy\": strategy_cfg.get(\"type\"),\n",
    "        \"scorer\": scorer_cfg.get(\"type\"),\n",
    "        \"aggregation\": strategy_cfg.get(\"aggregation\"),\n",
    "        \"scoring_window\": strategy_cfg.get(\"scoring_window\"),\n",
    "        \"scoring_window_label\": strategy_cfg.get(\"scoring_window_label\"),\n",
    "        \"model\": model_cfg.get(\"model_short_name\") or model_cfg.get(\"model_name\"),\n",
    "        \"dataset\": dataset_cfg.get(\"data_name\"),\n",
    "        \"beam_size\": strategy_cfg.get(\"beam_size\"),\n",
    "        \"candidates_per_beam\": strategy_cfg.get(\"candidates_per_beam\"),\n",
    "        \"num_paths\": strategy_cfg.get(\"num_paths\"),\n",
    "        \"num_candidates\": strategy_cfg.get(\"num_candidates\"),\n",
    "        \"max_steps\": strategy_cfg.get(\"max_steps\"),\n",
    "        # summary metrics\n",
    "        \"exact_match\": s.get(\"exact_match/accuracy\"),\n",
    "        \"llm_judge_accuracy\": next(\n",
    "            (v for k, v in s.items() if k.startswith(\"llm_judge\") and k.endswith(\"/accuracy\")),\n",
    "            None,\n",
    "        ),\n",
    "        \"avg_reasoning_steps\": s.get(\"avg_reasoning_steps_per_trajectory\"),\n",
    "        \"total_tokens\": s.get(\"compute/total_tokens\"),\n",
    "        \"total_input_tokens\": s.get(\"compute/total_input_tokens\"),\n",
    "        \"total_output_tokens\": s.get(\"compute/total_output_tokens\"),\n",
    "        \"total_tflops\": s.get(\"compute/total_tflops\"),\n",
    "        \"avg_tokens_per_sample\": s.get(\"compute/avg_tokens_per_sample\"),\n",
    "        \"avg_output_tokens_per_sample\": s.get(\"compute/avg_output_tokens_per_sample\"),\n",
    "        \"avg_tflops_per_sample\": s.get(\"compute/avg_tflops_per_sample\"),\n",
    "        \"total_generations\": s.get(\"compute/total_generations\"),\n",
    "        \"prm_tflops\": s.get(\"compute/prm_tflops\"),\n",
    "        \"total_samples\": s.get(\"total_samples\"),\n",
    "        \"completed\": s.get(\"completed\"),\n",
    "    }\n",
    "\n",
    "\n",
    "# Fetch all specified runs (skip entries with empty group_url or runs)\n",
    "records = []\n",
    "for entry in tqdm(EXPERIMENT_RUNS, desc=\"Fetching runs\"):\n",
    "    if not entry.get(\"group_url\") or not entry.get(\"runs\"):\n",
    "        continue\n",
    "\n",
    "    group_info = parse_group_url(entry[\"group_url\"])\n",
    "    group_name = group_info[\"group\"]\n",
    "    print(f\"Group: {group_name}\")\n",
    "\n",
    "    for run_entry in entry[\"runs\"]:\n",
    "        seed = run_entry[\"seed\"]\n",
    "        run_info = parse_run_url(run_entry[\"run_url\"])\n",
    "        try:\n",
    "            record = fetch_run(run_info[\"entity\"], run_info[\"project\"],\n",
    "                               run_info[\"run_id\"], group_name, seed)\n",
    "            records.append(record)\n",
    "            em = record.get(\"exact_match\")\n",
    "            llm = record.get(\"llm_judge_accuracy\")\n",
    "            if em is not None and llm is not None:\n",
    "                diff = abs(em - llm)\n",
    "                if diff > 0.10:\n",
    "                    print(f\"  ⚠ seed={seed}  {record['state']}  \"\n",
    "                          f\"exact_match={em:.4f}  llm_judge={llm:.4f}  \"\n",
    "                          f\"Δ={diff:.4f} — METRICS DIVERGE >10%\")\n",
    "                else:\n",
    "                    print(f\"  seed={seed}  {record['state']}  \"\n",
    "                          f\"exact_match={em:.4f}  llm_judge={llm:.4f}\")\n",
    "            else:\n",
    "                print(f\"  seed={seed}  {record['state']}  \"\n",
    "                      f\"exact_match={em}  llm_judge={llm}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR fetching seed={seed}: {e}\")\n",
    "\n",
    "raw_df = pd.DataFrame(records)\n",
    "print(f\"\\nTotal runs fetched: {len(raw_df)}\")\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 136/136 finished runs\n",
      "\n",
      "Strategies: ['adaptive', 'baseline', 'extended_thinking', 'offline_best_of_n', 'self_consistency']\n",
      "Scorers:    ['entropy', 'perplexity', 'prm', 'sequence_prob']\n",
      "Datasets:   ['AIME 2024', 'AIME 2025', 'Gaokao 2023 EN', 'MATH-500', 'Minerva Math', 'OlympiadBench']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strategy</th>\n",
       "      <th>scorer</th>\n",
       "      <th>aggregation</th>\n",
       "      <th>scoring_window</th>\n",
       "      <th>project_label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>total_tflops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MATH-500</td>\n",
       "      <td>math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>83.2</td>\n",
       "      <td>5133.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MATH-500</td>\n",
       "      <td>math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>83.2</td>\n",
       "      <td>5133.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MATH-500</td>\n",
       "      <td>math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>83.2</td>\n",
       "      <td>5133.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>self_consistency</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MATH-500</td>\n",
       "      <td>math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>86.2</td>\n",
       "      <td>35634.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>self_consistency</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MATH-500</td>\n",
       "      <td>math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>87.0</td>\n",
       "      <td>35760.256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>self_consistency</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MATH-500</td>\n",
       "      <td>math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>86.0</td>\n",
       "      <td>35646.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>offline_best_of_n</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MATH-500</td>\n",
       "      <td>math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>85.0</td>\n",
       "      <td>37234.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>offline_best_of_n</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MATH-500</td>\n",
       "      <td>math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>85.4</td>\n",
       "      <td>37780.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>offline_best_of_n</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MATH-500</td>\n",
       "      <td>math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>83.4</td>\n",
       "      <td>37954.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>prm</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MATH-500</td>\n",
       "      <td>math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>83.6</td>\n",
       "      <td>170584.442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            strategy   scorer aggregation scoring_window project_label dataset                    model  exact_match  total_tflops\n",
       "0           baseline  entropy        None           None      MATH-500    math  qwen25_math_7b_instruct         83.2      5133.156\n",
       "1           baseline  entropy        None           None      MATH-500    math  qwen25_math_7b_instruct         83.2      5133.156\n",
       "2           baseline  entropy        None           None      MATH-500    math  qwen25_math_7b_instruct         83.2      5133.156\n",
       "3   self_consistency  entropy        None           None      MATH-500    math  qwen25_math_7b_instruct         86.2     35634.144\n",
       "4   self_consistency  entropy        None           None      MATH-500    math  qwen25_math_7b_instruct         87.0     35760.256\n",
       "5   self_consistency  entropy        None           None      MATH-500    math  qwen25_math_7b_instruct         86.0     35646.268\n",
       "6  offline_best_of_n  entropy        None           None      MATH-500    math  qwen25_math_7b_instruct         85.0     37234.708\n",
       "7  offline_best_of_n  entropy        None           None      MATH-500    math  qwen25_math_7b_instruct         85.4     37780.848\n",
       "8  offline_best_of_n  entropy        None           None      MATH-500    math  qwen25_math_7b_instruct         83.4     37954.980\n",
       "9           adaptive      prm        None           None      MATH-500    math  qwen25_math_7b_instruct         83.6    170584.442"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ── Data Cleaning & Parsing ───────────────────────────────────────────────────\n",
    "\n",
    "def parse_group_name(group: str | None) -> dict:\n",
    "    \"\"\"Best-effort extraction of structured fields from the group name.\n",
    "\n",
    "    Expected patterns:\n",
    "      {strategy}_{model}_{dataset}\n",
    "      {strategy}_{model}_{dataset}_{scorer}\n",
    "      {strategy}_{model}_{dataset}_{scorer}_{window}_{aggregation}\n",
    "    \"\"\"\n",
    "    result = {\"_group_strategy\": None, \"_group_model\": None,\n",
    "              \"_group_dataset\": None, \"_group_scorer\": None,\n",
    "              \"_group_window\": None, \"_group_aggregation\": None}\n",
    "    if not group:\n",
    "        return result\n",
    "\n",
    "    known_strategies = {\n",
    "        \"baseline\", \"chain_of_thought\", \"self_consistency\",\n",
    "        \"online_bon\", \"offline_bon\", \"beam_search\",\n",
    "        \"uncertainty_cot\", \"extended_thinking\",\n",
    "        \"adaptive_scaling\", \"deepconf\",\n",
    "    }\n",
    "    known_scorers = {\n",
    "        \"prm\", \"entropy\", \"perplexity\", \"sequence_prob\",\n",
    "        \"uncertainty\", \"uncertainty_pd\", \"uncertainty_uhead\",\n",
    "    }\n",
    "    known_aggregations = {\"mean\", \"min\", \"max\", \"sum\", \"product\", \"median\"}\n",
    "    known_datasets = {\n",
    "        \"minerva_math\", \"math500\", \"aime2024\", \"aime2025\",\n",
    "        \"gaokao2023en\", \"human_eval_plus\", \"olympiadbench\",\n",
    "    }\n",
    "\n",
    "    parts = group.split(\"_\")\n",
    "\n",
    "    # Greedy match strategy prefix (try longest first)\n",
    "    strategy = None\n",
    "    for length in range(min(3, len(parts)), 0, -1):\n",
    "        candidate = \"_\".join(parts[:length])\n",
    "        if candidate in known_strategies:\n",
    "            strategy = candidate\n",
    "            parts = parts[length:]\n",
    "            break\n",
    "    result[\"_group_strategy\"] = strategy\n",
    "\n",
    "    # Scan remaining parts for known tokens\n",
    "    remaining = \"_\".join(parts)\n",
    "    for ds in sorted(known_datasets, key=len, reverse=True):\n",
    "        if ds in remaining:\n",
    "            result[\"_group_dataset\"] = ds\n",
    "            remaining = remaining.replace(ds, \"\", 1)\n",
    "            break\n",
    "    for sc in sorted(known_scorers, key=len, reverse=True):\n",
    "        if f\"_{sc}\" in f\"_{remaining}\":\n",
    "            result[\"_group_scorer\"] = sc\n",
    "            remaining = remaining.replace(sc, \"\", 1)\n",
    "            break\n",
    "    for ag in known_aggregations:\n",
    "        if f\"_{ag}\" in f\"_{remaining}\":\n",
    "            result[\"_group_aggregation\"] = ag\n",
    "            break\n",
    "    # window: look for a bare integer or \"all\"\n",
    "    for p in remaining.split(\"_\"):\n",
    "        if p.isdigit():\n",
    "            result[\"_group_window\"] = p\n",
    "            break\n",
    "        if p == \"all\":\n",
    "            result[\"_group_window\"] = \"all\"\n",
    "            break\n",
    "\n",
    "    # model: whatever remains after removing known tokens is likely the model\n",
    "    for tok in [result[\"_group_dataset\"], result[\"_group_scorer\"],\n",
    "                result[\"_group_aggregation\"], result[\"_group_window\"]]:\n",
    "        if tok:\n",
    "            remaining = remaining.replace(tok, \"\", 1)\n",
    "    model_str = \"_\".join(p for p in remaining.split(\"_\") if p)\n",
    "    result[\"_group_model\"] = model_str or None\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "df = raw_df.copy()\n",
    "\n",
    "# Parse group names to fill missing config columns\n",
    "parsed = df[\"group\"].apply(parse_group_name).apply(pd.Series)\n",
    "df = pd.concat([df, parsed], axis=1)\n",
    "\n",
    "# Fill missing config from parsed group name\n",
    "for col, gcol in [(\"strategy\", \"_group_strategy\"), (\"scorer\", \"_group_scorer\"),\n",
    "                   (\"aggregation\", \"_group_aggregation\"),\n",
    "                   (\"scoring_window\", \"_group_window\"),\n",
    "                   (\"dataset\", \"_group_dataset\"), (\"model\", \"_group_model\")]:\n",
    "    df[col] = df[col].fillna(df[gcol])\n",
    "\n",
    "# Drop helper columns\n",
    "df.drop(columns=[c for c in df.columns if c.startswith(\"_group_\")], inplace=True)\n",
    "\n",
    "# Filter to finished runs only\n",
    "n_before = len(df)\n",
    "df = df[df[\"state\"] == \"finished\"].copy()\n",
    "print(f\"Kept {len(df)}/{n_before} finished runs\")\n",
    "\n",
    "# Optional group filter\n",
    "if GROUP_FILTERS:\n",
    "    mask = df[\"group\"].apply(lambda g: any(f in (g or \"\") for f in GROUP_FILTERS))\n",
    "    df = df[mask].copy()\n",
    "    print(f\"After group filter: {len(df)} runs\")\n",
    "\n",
    "# Create human-readable project label from wandb project name\n",
    "PROJECT_LABEL_MAP = {\n",
    "    \"llm-tts-eval-math500\": \"MATH-500\",\n",
    "    \"llm-tts-eval-minerva-math\": \"Minerva Math\",\n",
    "    \"llm-tts-eval-minerva_math\": \"Minerva Math\",\n",
    "    \"llm-tts-eval-gaokao2023en\": \"Gaokao 2023 EN\",\n",
    "    \"llm-tts-eval-olympiadbench\": \"OlympiadBench\",\n",
    "    \"llm-tts-eval-gpqa-diamond\": \"GPQA Diamond\",\n",
    "    \"llm-tts-eval-gpqa_diamond\": \"GPQA Diamond\",\n",
    "    \"llm-tts-eval-aime24\": \"AIME 2024\",\n",
    "    \"llm-tts-eval-aime2024\": \"AIME 2024\",\n",
    "    \"llm-tts-eval-aime25\": \"AIME 2025\",\n",
    "    \"llm-tts-eval-aime2025\": \"AIME 2025\",\n",
    "}\n",
    "df[\"project_label\"] = df[\"project\"].map(PROJECT_LABEL_MAP).fillna(df[\"project\"])\n",
    "\n",
    "# Normalize accuracy to percentage\n",
    "for col in [\"exact_match\", \"llm_judge_accuracy\"]:\n",
    "    if col in df.columns:\n",
    "        # If values look like fractions (0-1), convert to pct\n",
    "        mask = df[col].notna() & (df[col] <= 1.0)\n",
    "        df.loc[mask, col] = df.loc[mask, col] * 100\n",
    "\n",
    "print(f\"\\nStrategies: {sorted(df['strategy'].dropna().unique())}\")\n",
    "print(f\"Scorers:    {sorted(df['scorer'].dropna().unique())}\")\n",
    "print(f\"Datasets:   {sorted(df['project_label'].dropna().unique())}\")\n",
    "df[[\"strategy\", \"scorer\", \"aggregation\", \"scoring_window\", \"project_label\", \"dataset\", \"model\",\n",
    "    \"exact_match\", \"total_tflops\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated configs: 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strategy</th>\n",
       "      <th>scorer</th>\n",
       "      <th>aggregation</th>\n",
       "      <th>scoring_window</th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>project_label</th>\n",
       "      <th>beam_size</th>\n",
       "      <th>candidates_per_beam</th>\n",
       "      <th>num_paths</th>\n",
       "      <th>num_candidates</th>\n",
       "      <th>exact_match_mean</th>\n",
       "      <th>exact_match_std</th>\n",
       "      <th>exact_match_count</th>\n",
       "      <th>llm_judge_accuracy_mean</th>\n",
       "      <th>llm_judge_accuracy_std</th>\n",
       "      <th>llm_judge_accuracy_count</th>\n",
       "      <th>avg_reasoning_steps_mean</th>\n",
       "      <th>avg_reasoning_steps_std</th>\n",
       "      <th>avg_reasoning_steps_count</th>\n",
       "      <th>total_tokens_mean</th>\n",
       "      <th>total_tokens_std</th>\n",
       "      <th>total_tokens_count</th>\n",
       "      <th>total_tflops_mean</th>\n",
       "      <th>total_tflops_std</th>\n",
       "      <th>total_tflops_count</th>\n",
       "      <th>avg_tokens_per_sample_mean</th>\n",
       "      <th>avg_tokens_per_sample_std</th>\n",
       "      <th>avg_tokens_per_sample_count</th>\n",
       "      <th>avg_output_tokens_per_sample_mean</th>\n",
       "      <th>avg_output_tokens_per_sample_std</th>\n",
       "      <th>avg_output_tokens_per_sample_count</th>\n",
       "      <th>avg_tflops_per_sample_mean</th>\n",
       "      <th>avg_tflops_per_sample_std</th>\n",
       "      <th>avg_tflops_per_sample_count</th>\n",
       "      <th>exact_match_fmt</th>\n",
       "      <th>llm_judge_accuracy_fmt</th>\n",
       "      <th>avg_reasoning_steps_fmt</th>\n",
       "      <th>total_tokens_fmt</th>\n",
       "      <th>total_tflops_fmt</th>\n",
       "      <th>avg_tokens_per_sample_fmt</th>\n",
       "      <th>avg_output_tokens_per_sample_fmt</th>\n",
       "      <th>avg_tflops_per_sample_fmt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>gaokao2023en</td>\n",
       "      <td>Gaokao 2023 EN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.398268</td>\n",
       "      <td>0.912178</td>\n",
       "      <td>3</td>\n",
       "      <td>72.900433</td>\n",
       "      <td>1.227485</td>\n",
       "      <td>3</td>\n",
       "      <td>6.079654</td>\n",
       "      <td>0.058677</td>\n",
       "      <td>3</td>\n",
       "      <td>2.833733e+06</td>\n",
       "      <td>7.604322e+04</td>\n",
       "      <td>3</td>\n",
       "      <td>39672.257333</td>\n",
       "      <td>1064.605083</td>\n",
       "      <td>3</td>\n",
       "      <td>7360.344589</td>\n",
       "      <td>197.514858</td>\n",
       "      <td>3</td>\n",
       "      <td>4039.057143</td>\n",
       "      <td>183.845981</td>\n",
       "      <td>3</td>\n",
       "      <td>103.044824</td>\n",
       "      <td>2.765208</td>\n",
       "      <td>3</td>\n",
       "      <td>68.4 +/- 0.9</td>\n",
       "      <td>72.9 +/- 1.2</td>\n",
       "      <td>6.1 +/- 0.1</td>\n",
       "      <td>2833732.7 +/- 76043.2</td>\n",
       "      <td>39672.3 +/- 1064.6</td>\n",
       "      <td>7360.3 +/- 197.5</td>\n",
       "      <td>4039.1 +/- 183.8</td>\n",
       "      <td>103.0 +/- 2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>math</td>\n",
       "      <td>MATH-500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.529150</td>\n",
       "      <td>3</td>\n",
       "      <td>84.533333</td>\n",
       "      <td>0.642910</td>\n",
       "      <td>3</td>\n",
       "      <td>6.054667</td>\n",
       "      <td>0.117377</td>\n",
       "      <td>3</td>\n",
       "      <td>3.527878e+06</td>\n",
       "      <td>1.084599e+05</td>\n",
       "      <td>3</td>\n",
       "      <td>49390.292000</td>\n",
       "      <td>1518.438853</td>\n",
       "      <td>3</td>\n",
       "      <td>7055.756000</td>\n",
       "      <td>216.919836</td>\n",
       "      <td>3</td>\n",
       "      <td>3910.163333</td>\n",
       "      <td>81.139192</td>\n",
       "      <td>3</td>\n",
       "      <td>98.780584</td>\n",
       "      <td>3.036878</td>\n",
       "      <td>3</td>\n",
       "      <td>84.0 +/- 0.5</td>\n",
       "      <td>84.5 +/- 0.6</td>\n",
       "      <td>6.1 +/- 0.1</td>\n",
       "      <td>3527878.0 +/- 108459.9</td>\n",
       "      <td>49390.3 +/- 1518.4</td>\n",
       "      <td>7055.8 +/- 216.9</td>\n",
       "      <td>3910.2 +/- 81.1</td>\n",
       "      <td>98.8 +/- 3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>minerva_math</td>\n",
       "      <td>Minerva Math</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.460784</td>\n",
       "      <td>2.582268</td>\n",
       "      <td>3</td>\n",
       "      <td>45.098039</td>\n",
       "      <td>2.502522</td>\n",
       "      <td>3</td>\n",
       "      <td>6.133578</td>\n",
       "      <td>0.161695</td>\n",
       "      <td>3</td>\n",
       "      <td>1.726833e+06</td>\n",
       "      <td>7.008064e+04</td>\n",
       "      <td>3</td>\n",
       "      <td>24175.666667</td>\n",
       "      <td>981.128893</td>\n",
       "      <td>3</td>\n",
       "      <td>6348.651961</td>\n",
       "      <td>257.649394</td>\n",
       "      <td>3</td>\n",
       "      <td>2792.047794</td>\n",
       "      <td>80.581655</td>\n",
       "      <td>3</td>\n",
       "      <td>88.881127</td>\n",
       "      <td>3.607092</td>\n",
       "      <td>3</td>\n",
       "      <td>39.5 +/- 2.6</td>\n",
       "      <td>45.1 +/- 2.5</td>\n",
       "      <td>6.1 +/- 0.2</td>\n",
       "      <td>1726833.3 +/- 70080.6</td>\n",
       "      <td>24175.7 +/- 981.1</td>\n",
       "      <td>6348.7 +/- 257.6</td>\n",
       "      <td>2792.0 +/- 80.6</td>\n",
       "      <td>88.9 +/- 3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>olympiadbench</td>\n",
       "      <td>OlympiadBench</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.246914</td>\n",
       "      <td>0.905200</td>\n",
       "      <td>3</td>\n",
       "      <td>43.753086</td>\n",
       "      <td>0.986419</td>\n",
       "      <td>3</td>\n",
       "      <td>7.374815</td>\n",
       "      <td>0.046069</td>\n",
       "      <td>3</td>\n",
       "      <td>6.541236e+06</td>\n",
       "      <td>1.045451e+05</td>\n",
       "      <td>3</td>\n",
       "      <td>91577.308667</td>\n",
       "      <td>1463.631096</td>\n",
       "      <td>3</td>\n",
       "      <td>9690.720494</td>\n",
       "      <td>154.881597</td>\n",
       "      <td>3</td>\n",
       "      <td>4365.265185</td>\n",
       "      <td>94.415847</td>\n",
       "      <td>3</td>\n",
       "      <td>135.670087</td>\n",
       "      <td>2.168342</td>\n",
       "      <td>3</td>\n",
       "      <td>40.2 +/- 0.9</td>\n",
       "      <td>43.8 +/- 1.0</td>\n",
       "      <td>7.4 +/- 0.0</td>\n",
       "      <td>6541236.3 +/- 104545.1</td>\n",
       "      <td>91577.3 +/- 1463.6</td>\n",
       "      <td>9690.7 +/- 154.9</td>\n",
       "      <td>4365.3 +/- 94.4</td>\n",
       "      <td>135.7 +/- 2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vllm_thinking_qwen3_8b</td>\n",
       "      <td>aime24</td>\n",
       "      <td>AIME 2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.444444</td>\n",
       "      <td>3.849002</td>\n",
       "      <td>3</td>\n",
       "      <td>74.444444</td>\n",
       "      <td>3.849002</td>\n",
       "      <td>3</td>\n",
       "      <td>68.133333</td>\n",
       "      <td>6.490249</td>\n",
       "      <td>3</td>\n",
       "      <td>1.959623e+07</td>\n",
       "      <td>2.825310e+06</td>\n",
       "      <td>3</td>\n",
       "      <td>313539.680000</td>\n",
       "      <td>45204.958464</td>\n",
       "      <td>3</td>\n",
       "      <td>653207.666667</td>\n",
       "      <td>94176.996801</td>\n",
       "      <td>3</td>\n",
       "      <td>38269.611111</td>\n",
       "      <td>1813.174750</td>\n",
       "      <td>3</td>\n",
       "      <td>10451.322667</td>\n",
       "      <td>1506.831949</td>\n",
       "      <td>3</td>\n",
       "      <td>74.4 +/- 3.8</td>\n",
       "      <td>74.4 +/- 3.8</td>\n",
       "      <td>68.1 +/- 6.5</td>\n",
       "      <td>19596230.0 +/- 2825309.9</td>\n",
       "      <td>313539.7 +/- 45205.0</td>\n",
       "      <td>653207.7 +/- 94177.0</td>\n",
       "      <td>38269.6 +/- 1813.2</td>\n",
       "      <td>10451.3 +/- 1506.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   strategy   scorer  aggregation  scoring_window                    model        dataset   project_label  beam_size  candidates_per_beam  num_paths  num_candidates  exact_match_mean  \\\n",
       "0  adaptive  entropy          NaN             NaN  qwen25_math_7b_instruct   gaokao2023en  Gaokao 2023 EN        NaN                  NaN        NaN             NaN         68.398268   \n",
       "1  adaptive  entropy          NaN             NaN  qwen25_math_7b_instruct           math        MATH-500        NaN                  NaN        NaN             NaN         84.000000   \n",
       "2  adaptive  entropy          NaN             NaN  qwen25_math_7b_instruct   minerva_math    Minerva Math        NaN                  NaN        NaN             NaN         39.460784   \n",
       "3  adaptive  entropy          NaN             NaN  qwen25_math_7b_instruct  olympiadbench   OlympiadBench        NaN                  NaN        NaN             NaN         40.246914   \n",
       "4  adaptive  entropy          NaN             NaN   vllm_thinking_qwen3_8b         aime24       AIME 2024        NaN                  NaN        NaN             NaN         74.444444   \n",
       "\n",
       "   exact_match_std  exact_match_count  llm_judge_accuracy_mean  llm_judge_accuracy_std  llm_judge_accuracy_count  avg_reasoning_steps_mean  avg_reasoning_steps_std  avg_reasoning_steps_count  \\\n",
       "0         0.912178                  3                72.900433                1.227485                         3                  6.079654                 0.058677                          3   \n",
       "1         0.529150                  3                84.533333                0.642910                         3                  6.054667                 0.117377                          3   \n",
       "2         2.582268                  3                45.098039                2.502522                         3                  6.133578                 0.161695                          3   \n",
       "3         0.905200                  3                43.753086                0.986419                         3                  7.374815                 0.046069                          3   \n",
       "4         3.849002                  3                74.444444                3.849002                         3                 68.133333                 6.490249                          3   \n",
       "\n",
       "   total_tokens_mean  total_tokens_std  total_tokens_count  total_tflops_mean  total_tflops_std  total_tflops_count  avg_tokens_per_sample_mean  avg_tokens_per_sample_std  \\\n",
       "0       2.833733e+06      7.604322e+04                   3       39672.257333       1064.605083                   3                 7360.344589                 197.514858   \n",
       "1       3.527878e+06      1.084599e+05                   3       49390.292000       1518.438853                   3                 7055.756000                 216.919836   \n",
       "2       1.726833e+06      7.008064e+04                   3       24175.666667        981.128893                   3                 6348.651961                 257.649394   \n",
       "3       6.541236e+06      1.045451e+05                   3       91577.308667       1463.631096                   3                 9690.720494                 154.881597   \n",
       "4       1.959623e+07      2.825310e+06                   3      313539.680000      45204.958464                   3               653207.666667               94176.996801   \n",
       "\n",
       "   avg_tokens_per_sample_count  avg_output_tokens_per_sample_mean  avg_output_tokens_per_sample_std  avg_output_tokens_per_sample_count  avg_tflops_per_sample_mean  avg_tflops_per_sample_std  \\\n",
       "0                            3                        4039.057143                        183.845981                                   3                  103.044824                   2.765208   \n",
       "1                            3                        3910.163333                         81.139192                                   3                   98.780584                   3.036878   \n",
       "2                            3                        2792.047794                         80.581655                                   3                   88.881127                   3.607092   \n",
       "3                            3                        4365.265185                         94.415847                                   3                  135.670087                   2.168342   \n",
       "4                            3                       38269.611111                       1813.174750                                   3                10451.322667                1506.831949   \n",
       "\n",
       "   avg_tflops_per_sample_count exact_match_fmt llm_judge_accuracy_fmt avg_reasoning_steps_fmt          total_tokens_fmt      total_tflops_fmt avg_tokens_per_sample_fmt  \\\n",
       "0                            3    68.4 +/- 0.9           72.9 +/- 1.2             6.1 +/- 0.1     2833732.7 +/- 76043.2    39672.3 +/- 1064.6          7360.3 +/- 197.5   \n",
       "1                            3    84.0 +/- 0.5           84.5 +/- 0.6             6.1 +/- 0.1    3527878.0 +/- 108459.9    49390.3 +/- 1518.4          7055.8 +/- 216.9   \n",
       "2                            3    39.5 +/- 2.6           45.1 +/- 2.5             6.1 +/- 0.2     1726833.3 +/- 70080.6     24175.7 +/- 981.1          6348.7 +/- 257.6   \n",
       "3                            3    40.2 +/- 0.9           43.8 +/- 1.0             7.4 +/- 0.0    6541236.3 +/- 104545.1    91577.3 +/- 1463.6          9690.7 +/- 154.9   \n",
       "4                            3    74.4 +/- 3.8           74.4 +/- 3.8            68.1 +/- 6.5  19596230.0 +/- 2825309.9  313539.7 +/- 45205.0      653207.7 +/- 94177.0   \n",
       "\n",
       "  avg_output_tokens_per_sample_fmt avg_tflops_per_sample_fmt  \n",
       "0                 4039.1 +/- 183.8             103.0 +/- 2.8  \n",
       "1                  3910.2 +/- 81.1              98.8 +/- 3.0  \n",
       "2                  2792.0 +/- 80.6              88.9 +/- 3.6  \n",
       "3                  4365.3 +/- 94.4             135.7 +/- 2.2  \n",
       "4               38269.6 +/- 1813.2        10451.3 +/- 1506.8  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ── Seed Averaging ────────────────────────────────────────────────────────────\n",
    "\n",
    "CONFIG_COLS = [\"strategy\", \"scorer\", \"aggregation\", \"scoring_window\",\n",
    "               \"model\", \"dataset\", \"project_label\",\n",
    "               \"beam_size\", \"candidates_per_beam\", \"num_paths\", \"num_candidates\"]\n",
    "\n",
    "METRIC_COLS = [\"exact_match\", \"llm_judge_accuracy\", \"avg_reasoning_steps\",\n",
    "               \"total_tokens\", \"total_tflops\", \"avg_tokens_per_sample\",\n",
    "               \"avg_output_tokens_per_sample\", \"avg_tflops_per_sample\"]\n",
    "\n",
    "\n",
    "def aggregate_seeds(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Group by config columns and compute mean/std over seeds.\"\"\"\n",
    "    present_cfg = [c for c in CONFIG_COLS if c in df.columns]\n",
    "    present_met = [c for c in METRIC_COLS if c in df.columns]\n",
    "\n",
    "    grouped = df.groupby(present_cfg, dropna=False)\n",
    "    agg = grouped[present_met].agg([\"mean\", \"std\", \"count\"]).reset_index()\n",
    "\n",
    "    # Flatten multi-level columns\n",
    "    flat_cols = []\n",
    "    for col in agg.columns:\n",
    "        if isinstance(col, tuple) and col[1]:\n",
    "            flat_cols.append(f\"{col[0]}_{col[1]}\")\n",
    "        else:\n",
    "            flat_cols.append(col[0] if isinstance(col, tuple) else col)\n",
    "    agg.columns = flat_cols\n",
    "\n",
    "    # Add a formatted \"mean +/- std\" column for the primary metric\n",
    "    for m in present_met:\n",
    "        mean_col, std_col = f\"{m}_mean\", f\"{m}_std\"\n",
    "        if mean_col in agg.columns:\n",
    "            agg[f\"{m}_fmt\"] = agg.apply(\n",
    "                lambda r: f\"{r[mean_col]:.1f} +/- {r[std_col]:.1f}\"\n",
    "                if pd.notna(r[std_col]) and r.get(f\"{m}_count\", 0) > 1\n",
    "                else (f\"{r[mean_col]:.1f}\" if pd.notna(r[mean_col]) else \"\"),\n",
    "                axis=1,\n",
    "            )\n",
    "    return agg\n",
    "\n",
    "\n",
    "agg_df = aggregate_seeds(df)\n",
    "print(f\"Aggregated configs: {len(agg_df)}\")\n",
    "agg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Pivot Table Helper ────────────────────────────────────────────────────────\n",
    "\n",
    "def make_comparison_table(\n",
    "    df: pd.DataFrame,\n",
    "    row_field: str,\n",
    "    col_field: str,\n",
    "    value_field: str = \"exact_match_fmt\",\n",
    "    filter_dict: dict | None = None,\n",
    "    title: str | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Build a pivot table from the aggregated DataFrame.\"\"\"\n",
    "    sub = df.copy()\n",
    "    if filter_dict:\n",
    "        for k, v in filter_dict.items():\n",
    "            if isinstance(v, list):\n",
    "                sub = sub[sub[k].isin(v)]\n",
    "            else:\n",
    "                sub = sub[sub[k] == v]\n",
    "\n",
    "    if sub.empty:\n",
    "        print(\"No data after filtering.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    pivot = sub.pivot_table(\n",
    "        index=row_field,\n",
    "        columns=col_field,\n",
    "        values=value_field,\n",
    "        aggfunc=\"first\",\n",
    "    )\n",
    "    if title:\n",
    "        print(f\"\\n{'=' * len(title)}\")\n",
    "        print(title)\n",
    "        print(f\"{'=' * len(title)}\")\n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================\n",
      "Exact Match (%) — AIME 2024\n",
      "===========================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>strategy</th>\n",
       "      <th>adaptive</th>\n",
       "      <th>baseline</th>\n",
       "      <th>extended_thinking</th>\n",
       "      <th>offline_best_of_n</th>\n",
       "      <th>self_consistency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scorer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>74.4 +/- 3.8</td>\n",
       "      <td>75.6 +/- 2.7</td>\n",
       "      <td>78.9 +/- 5.1</td>\n",
       "      <td>75.6 +/- 5.1</td>\n",
       "      <td>82.2 +/- 1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity</th>\n",
       "      <td>76.7 +/- 0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prm</th>\n",
       "      <td>77.8 +/- 3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob</th>\n",
       "      <td>76.7 +/- 3.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "strategy           adaptive      baseline extended_thinking offline_best_of_n self_consistency\n",
       "scorer                                                                                        \n",
       "entropy        74.4 +/- 3.8  75.6 +/- 2.7      78.9 +/- 5.1      75.6 +/- 5.1     82.2 +/- 1.9\n",
       "perplexity     76.7 +/- 0.0           NaN               NaN               NaN              NaN\n",
       "prm            77.8 +/- 3.8           NaN               NaN               NaN              NaN\n",
       "sequence_prob  76.7 +/- 3.3           NaN               NaN               NaN              NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================\n",
      "Exact Match (%) — AIME 2025\n",
      "===========================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>strategy</th>\n",
       "      <th>adaptive</th>\n",
       "      <th>baseline</th>\n",
       "      <th>extended_thinking</th>\n",
       "      <th>offline_best_of_n</th>\n",
       "      <th>self_consistency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scorer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>65.6 +/- 5.1</td>\n",
       "      <td>64.4 +/- 6.2</td>\n",
       "      <td>66.7 +/- 3.3</td>\n",
       "      <td>64.4 +/- 5.1</td>\n",
       "      <td>34.4 +/- 6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity</th>\n",
       "      <td>68.9 +/- 5.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prm</th>\n",
       "      <td>67.8 +/- 5.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob</th>\n",
       "      <td>70.0 +/- 5.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "strategy           adaptive      baseline extended_thinking offline_best_of_n self_consistency\n",
       "scorer                                                                                        \n",
       "entropy        65.6 +/- 5.1  64.4 +/- 6.2      66.7 +/- 3.3      64.4 +/- 5.1     34.4 +/- 6.9\n",
       "perplexity     68.9 +/- 5.1           NaN               NaN               NaN              NaN\n",
       "prm            67.8 +/- 5.1           NaN               NaN               NaN              NaN\n",
       "sequence_prob  70.0 +/- 5.8           NaN               NaN               NaN              NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================\n",
      "Exact Match (%) — Gaokao 2023 EN\n",
      "================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>strategy</th>\n",
       "      <th>adaptive</th>\n",
       "      <th>baseline</th>\n",
       "      <th>offline_best_of_n</th>\n",
       "      <th>self_consistency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scorer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>68.4 +/- 0.9</td>\n",
       "      <td>68.6 +/- 0.0</td>\n",
       "      <td>68.9 +/- 0.3</td>\n",
       "      <td>72.4 +/- 1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity</th>\n",
       "      <td>69.0 +/- 0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prm</th>\n",
       "      <td>70.6 +/- 0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob</th>\n",
       "      <td>68.8 +/- 1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "strategy           adaptive      baseline offline_best_of_n self_consistency\n",
       "scorer                                                                      \n",
       "entropy        68.4 +/- 0.9  68.6 +/- 0.0      68.9 +/- 0.3     72.4 +/- 1.2\n",
       "perplexity     69.0 +/- 0.9           NaN               NaN              NaN\n",
       "prm            70.6 +/- 0.8           NaN               NaN              NaN\n",
       "sequence_prob  68.8 +/- 1.6           NaN               NaN              NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      "Exact Match (%) — MATH-500\n",
      "==========================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>strategy</th>\n",
       "      <th>adaptive</th>\n",
       "      <th>baseline</th>\n",
       "      <th>offline_best_of_n</th>\n",
       "      <th>self_consistency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scorer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>84.0 +/- 0.5</td>\n",
       "      <td>83.2 +/- 0.0</td>\n",
       "      <td>84.6 +/- 1.1</td>\n",
       "      <td>86.4 +/- 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity</th>\n",
       "      <td>84.5 +/- 0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prm</th>\n",
       "      <td>84.0 +/- 0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob</th>\n",
       "      <td>83.6 +/- 0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "strategy           adaptive      baseline offline_best_of_n self_consistency\n",
       "scorer                                                                      \n",
       "entropy        84.0 +/- 0.5  83.2 +/- 0.0      84.6 +/- 1.1     86.4 +/- 0.5\n",
       "perplexity     84.5 +/- 0.1           NaN               NaN              NaN\n",
       "prm            84.0 +/- 0.5           NaN               NaN              NaN\n",
       "sequence_prob  83.6 +/- 0.5           NaN               NaN              NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Exact Match (%) — Minerva Math\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>strategy</th>\n",
       "      <th>adaptive</th>\n",
       "      <th>baseline</th>\n",
       "      <th>offline_best_of_n</th>\n",
       "      <th>self_consistency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scorer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>39.5 +/- 2.6</td>\n",
       "      <td>42.3 +/- 0.0</td>\n",
       "      <td>40.4 +/- 0.0</td>\n",
       "      <td>44.5 +/- 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity</th>\n",
       "      <td>40.2 +/- 0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prm</th>\n",
       "      <td>40.8 +/- 1.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob</th>\n",
       "      <td>40.1 +/- 1.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "strategy           adaptive      baseline offline_best_of_n self_consistency\n",
       "scorer                                                                      \n",
       "entropy        39.5 +/- 2.6  42.3 +/- 0.0      40.4 +/- 0.0     44.5 +/- 0.7\n",
       "perplexity     40.2 +/- 0.8           NaN               NaN              NaN\n",
       "prm            40.8 +/- 1.3           NaN               NaN              NaN\n",
       "sequence_prob  40.1 +/- 1.9           NaN               NaN              NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================\n",
      "Exact Match (%) — OlympiadBench\n",
      "===============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>strategy</th>\n",
       "      <th>adaptive</th>\n",
       "      <th>baseline</th>\n",
       "      <th>offline_best_of_n</th>\n",
       "      <th>self_consistency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scorer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>40.2 +/- 0.9</td>\n",
       "      <td>39.3 +/- 0.0</td>\n",
       "      <td>40.1 +/- 1.0</td>\n",
       "      <td>44.7 +/- 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity</th>\n",
       "      <td>40.3 +/- 1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prm</th>\n",
       "      <td>42.7 +/- 0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob</th>\n",
       "      <td>40.4 +/- 1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "strategy           adaptive      baseline offline_best_of_n self_consistency\n",
       "scorer                                                                      \n",
       "entropy        40.2 +/- 0.9  39.3 +/- 0.0      40.1 +/- 1.0     44.7 +/- 0.6\n",
       "perplexity     40.3 +/- 1.5           NaN               NaN              NaN\n",
       "prm            42.7 +/- 0.7           NaN               NaN              NaN\n",
       "sequence_prob  40.4 +/- 1.1           NaN               NaN              NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ── Table 1: Strategy x Scorer Grid ───────────────────────────────────────────\n",
    "\n",
    "for dataset_label in sorted(agg_df[\"project_label\"].dropna().unique()):\n",
    "    tbl = make_comparison_table(\n",
    "        agg_df,\n",
    "        row_field=\"scorer\",\n",
    "        col_field=\"strategy\",\n",
    "        value_field=\"exact_match_fmt\",\n",
    "        filter_dict={\"project_label\": dataset_label},\n",
    "        title=f\"Exact Match (%) — {dataset_label}\",\n",
    "    )\n",
    "    if not tbl.empty:\n",
    "        display(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No beam search runs found.\n"
     ]
    }
   ],
   "source": [
    "# ── Table 2: Aggregation x Scoring Window (beam search only) ──────────────────\n",
    "\n",
    "beam_df = agg_df[agg_df[\"strategy\"] == \"beam_search\"].copy()\n",
    "\n",
    "if beam_df.empty:\n",
    "    print(\"No beam search runs found.\")\n",
    "else:\n",
    "    for scorer in sorted(beam_df[\"scorer\"].dropna().unique()):\n",
    "        for dataset_label in sorted(beam_df[\"project_label\"].dropna().unique()):\n",
    "            tbl = make_comparison_table(\n",
    "                beam_df,\n",
    "                row_field=\"aggregation\",\n",
    "                col_field=\"scoring_window\",\n",
    "                value_field=\"exact_match_fmt\",\n",
    "                filter_dict={\"scorer\": scorer, \"project_label\": dataset_label},\n",
    "                title=f\"Beam Search — scorer={scorer}, dataset={dataset_label}\",\n",
    "            )\n",
    "            if not tbl.empty:\n",
    "                display(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute Efficiency Overview\n",
      "========================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strategy</th>\n",
       "      <th>scorer</th>\n",
       "      <th>aggregation</th>\n",
       "      <th>scoring_window</th>\n",
       "      <th>project_label</th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Total TFLOPS</th>\n",
       "      <th>Tokens/Problem</th>\n",
       "      <th>Reasoning Steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>self_consistency</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MATH-500</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>86.400000</td>\n",
       "      <td>3.568022e+04</td>\n",
       "      <td>5097.174667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>offline_best_of_n</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MATH-500</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>84.600000</td>\n",
       "      <td>3.765685e+04</td>\n",
       "      <td>5379.549333</td>\n",
       "      <td>3.580667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>perplexity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MATH-500</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>84.533333</td>\n",
       "      <td>5.240861e+04</td>\n",
       "      <td>7486.944667</td>\n",
       "      <td>6.204000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MATH-500</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>4.939029e+04</td>\n",
       "      <td>7055.756000</td>\n",
       "      <td>6.054667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>prm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MATH-500</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>1.695278e+05</td>\n",
       "      <td>9074.406667</td>\n",
       "      <td>6.216000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>sequence_prob</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MATH-500</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>83.600000</td>\n",
       "      <td>5.488382e+04</td>\n",
       "      <td>7840.545333</td>\n",
       "      <td>6.334667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>baseline</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MATH-500</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>83.200000</td>\n",
       "      <td>5.133156e+03</td>\n",
       "      <td>733.308000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>self_consistency</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIME 2024</td>\n",
       "      <td>vllm_thinking_qwen3_8b</td>\n",
       "      <td>82.222222</td>\n",
       "      <td>5.279722e+04</td>\n",
       "      <td>109994.211111</td>\n",
       "      <td>0.765278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>extended_thinking</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIME 2024</td>\n",
       "      <td>vllm_thinking_qwen3_8b</td>\n",
       "      <td>78.888889</td>\n",
       "      <td>2.647765e+04</td>\n",
       "      <td>55161.777778</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>prm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIME 2024</td>\n",
       "      <td>vllm_thinking_qwen3_8b</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>1.446222e+06</td>\n",
       "      <td>954790.988889</td>\n",
       "      <td>80.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>perplexity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIME 2024</td>\n",
       "      <td>vllm_thinking_qwen3_8b</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>3.129867e+05</td>\n",
       "      <td>652055.666667</td>\n",
       "      <td>69.155556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>sequence_prob</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIME 2024</td>\n",
       "      <td>vllm_thinking_qwen3_8b</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>3.405928e+05</td>\n",
       "      <td>709568.266667</td>\n",
       "      <td>79.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>offline_best_of_n</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIME 2024</td>\n",
       "      <td>vllm_thinking_qwen3_8b</td>\n",
       "      <td>75.555556</td>\n",
       "      <td>5.366971e+04</td>\n",
       "      <td>111811.900000</td>\n",
       "      <td>103.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>baseline</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIME 2024</td>\n",
       "      <td>vllm_thinking_qwen3_8b</td>\n",
       "      <td>75.555556</td>\n",
       "      <td>6.626936e+03</td>\n",
       "      <td>13806.116667</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIME 2024</td>\n",
       "      <td>vllm_thinking_qwen3_8b</td>\n",
       "      <td>74.444444</td>\n",
       "      <td>3.135397e+05</td>\n",
       "      <td>653207.666667</td>\n",
       "      <td>68.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>self_consistency</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gaokao 2023 EN</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>72.380952</td>\n",
       "      <td>2.881714e+04</td>\n",
       "      <td>5346.407792</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>prm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gaokao 2023 EN</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>70.649351</td>\n",
       "      <td>1.388310e+05</td>\n",
       "      <td>9458.550649</td>\n",
       "      <td>6.475325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>sequence_prob</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIME 2025</td>\n",
       "      <td>vllm_thinking_qwen3_8b</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>4.591976e+05</td>\n",
       "      <td>956661.700000</td>\n",
       "      <td>95.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>perplexity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gaokao 2023 EN</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>68.961039</td>\n",
       "      <td>4.783411e+04</td>\n",
       "      <td>8874.603896</td>\n",
       "      <td>6.446753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>offline_best_of_n</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gaokao 2023 EN</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>68.917749</td>\n",
       "      <td>3.176159e+04</td>\n",
       "      <td>5892.687446</td>\n",
       "      <td>3.281385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>perplexity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIME 2025</td>\n",
       "      <td>vllm_thinking_qwen3_8b</td>\n",
       "      <td>68.888889</td>\n",
       "      <td>3.203161e+05</td>\n",
       "      <td>667325.144444</td>\n",
       "      <td>75.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>sequence_prob</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gaokao 2023 EN</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>68.831169</td>\n",
       "      <td>4.455045e+04</td>\n",
       "      <td>8265.389610</td>\n",
       "      <td>6.394805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>baseline</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gaokao 2023 EN</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>68.571429</td>\n",
       "      <td>4.119668e+03</td>\n",
       "      <td>764.316883</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gaokao 2023 EN</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>68.398268</td>\n",
       "      <td>3.967226e+04</td>\n",
       "      <td>7360.344589</td>\n",
       "      <td>6.079654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>prm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIME 2025</td>\n",
       "      <td>vllm_thinking_qwen3_8b</td>\n",
       "      <td>67.777778</td>\n",
       "      <td>9.682975e+05</td>\n",
       "      <td>684309.833333</td>\n",
       "      <td>78.088889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>extended_thinking</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIME 2025</td>\n",
       "      <td>vllm_thinking_qwen3_8b</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>2.757390e+04</td>\n",
       "      <td>57445.633333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIME 2025</td>\n",
       "      <td>vllm_thinking_qwen3_8b</td>\n",
       "      <td>65.555556</td>\n",
       "      <td>4.577552e+05</td>\n",
       "      <td>953656.722222</td>\n",
       "      <td>72.411111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>offline_best_of_n</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIME 2025</td>\n",
       "      <td>vllm_thinking_qwen3_8b</td>\n",
       "      <td>64.444444</td>\n",
       "      <td>6.490557e+04</td>\n",
       "      <td>135219.944444</td>\n",
       "      <td>138.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>baseline</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIME 2025</td>\n",
       "      <td>vllm_thinking_qwen3_8b</td>\n",
       "      <td>64.444444</td>\n",
       "      <td>8.083627e+03</td>\n",
       "      <td>16840.888889</td>\n",
       "      <td>0.872222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>self_consistency</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OlympiadBench</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>44.691358</td>\n",
       "      <td>6.972329e+04</td>\n",
       "      <td>7378.125926</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>self_consistency</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minerva Math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>44.485294</td>\n",
       "      <td>2.079287e+04</td>\n",
       "      <td>5460.312500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>prm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OlympiadBench</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>42.716049</td>\n",
       "      <td>4.313154e+05</td>\n",
       "      <td>14887.829136</td>\n",
       "      <td>8.399506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>baseline</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minerva Math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>42.279412</td>\n",
       "      <td>3.062248e+03</td>\n",
       "      <td>804.161765</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>prm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minerva Math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>40.808824</td>\n",
       "      <td>6.783468e+04</td>\n",
       "      <td>7118.209559</td>\n",
       "      <td>6.410539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>sequence_prob</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OlympiadBench</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>40.444444</td>\n",
       "      <td>1.203994e+05</td>\n",
       "      <td>12740.678025</td>\n",
       "      <td>8.498765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>offline_best_of_n</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minerva Math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>40.441176</td>\n",
       "      <td>2.320258e+04</td>\n",
       "      <td>6093.113971</td>\n",
       "      <td>3.090074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>perplexity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OlympiadBench</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>40.345679</td>\n",
       "      <td>1.051902e+05</td>\n",
       "      <td>11131.240000</td>\n",
       "      <td>7.729383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OlympiadBench</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>40.246914</td>\n",
       "      <td>9.157731e+04</td>\n",
       "      <td>9690.720494</td>\n",
       "      <td>7.374815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>perplexity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minerva Math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>40.196078</td>\n",
       "      <td>2.594617e+04</td>\n",
       "      <td>6813.594363</td>\n",
       "      <td>6.273284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>offline_best_of_n</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OlympiadBench</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>40.148148</td>\n",
       "      <td>7.883414e+04</td>\n",
       "      <td>8342.237037</td>\n",
       "      <td>3.632593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>sequence_prob</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minerva Math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>40.073529</td>\n",
       "      <td>2.624546e+04</td>\n",
       "      <td>6892.191176</td>\n",
       "      <td>6.549020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>adaptive</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minerva Math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>39.460784</td>\n",
       "      <td>2.417567e+04</td>\n",
       "      <td>6348.651961</td>\n",
       "      <td>6.133578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>baseline</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OlympiadBench</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>39.259259</td>\n",
       "      <td>9.683716e+03</td>\n",
       "      <td>1024.731852</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>self_consistency</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIME 2025</td>\n",
       "      <td>vllm_thinking_qwen3_8b</td>\n",
       "      <td>34.444444</td>\n",
       "      <td>5.368489e+04</td>\n",
       "      <td>111843.511111</td>\n",
       "      <td>0.788889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             strategy         scorer  aggregation  scoring_window   project_label                    model  Accuracy (%)  Total TFLOPS  Tokens/Problem  Reasoning Steps\n",
       "0    self_consistency        entropy          NaN             NaN        MATH-500  qwen25_math_7b_instruct     86.400000  3.568022e+04     5097.174667         1.000000\n",
       "1   offline_best_of_n        entropy          NaN             NaN        MATH-500  qwen25_math_7b_instruct     84.600000  3.765685e+04     5379.549333         3.580667\n",
       "2            adaptive     perplexity          NaN             NaN        MATH-500  qwen25_math_7b_instruct     84.533333  5.240861e+04     7486.944667         6.204000\n",
       "3            adaptive        entropy          NaN             NaN        MATH-500  qwen25_math_7b_instruct     84.000000  4.939029e+04     7055.756000         6.054667\n",
       "4            adaptive            prm          NaN             NaN        MATH-500  qwen25_math_7b_instruct     84.000000  1.695278e+05     9074.406667         6.216000\n",
       "5            adaptive  sequence_prob          NaN             NaN        MATH-500  qwen25_math_7b_instruct     83.600000  5.488382e+04     7840.545333         6.334667\n",
       "6            baseline        entropy          NaN             NaN        MATH-500  qwen25_math_7b_instruct     83.200000  5.133156e+03      733.308000         1.000000\n",
       "7    self_consistency        entropy          NaN             NaN       AIME 2024   vllm_thinking_qwen3_8b     82.222222  5.279722e+04   109994.211111         0.765278\n",
       "8   extended_thinking        entropy          NaN             NaN       AIME 2024   vllm_thinking_qwen3_8b     78.888889  2.647765e+04    55161.777778              NaN\n",
       "9            adaptive            prm          NaN             NaN       AIME 2024   vllm_thinking_qwen3_8b     77.777778  1.446222e+06   954790.988889        80.888889\n",
       "10           adaptive     perplexity          NaN             NaN       AIME 2024   vllm_thinking_qwen3_8b     76.666667  3.129867e+05   652055.666667        69.155556\n",
       "11           adaptive  sequence_prob          NaN             NaN       AIME 2024   vllm_thinking_qwen3_8b     76.666667  3.405928e+05   709568.266667        79.933333\n",
       "12  offline_best_of_n        entropy          NaN             NaN       AIME 2024   vllm_thinking_qwen3_8b     75.555556  5.366971e+04   111811.900000       103.222222\n",
       "13           baseline        entropy          NaN             NaN       AIME 2024   vllm_thinking_qwen3_8b     75.555556  6.626936e+03    13806.116667         0.955556\n",
       "14           adaptive        entropy          NaN             NaN       AIME 2024   vllm_thinking_qwen3_8b     74.444444  3.135397e+05   653207.666667        68.133333\n",
       "15   self_consistency        entropy          NaN             NaN  Gaokao 2023 EN  qwen25_math_7b_instruct     72.380952  2.881714e+04     5346.407792         1.000000\n",
       "16           adaptive            prm          NaN             NaN  Gaokao 2023 EN  qwen25_math_7b_instruct     70.649351  1.388310e+05     9458.550649         6.475325\n",
       "17           adaptive  sequence_prob          NaN             NaN       AIME 2025   vllm_thinking_qwen3_8b     70.000000  4.591976e+05   956661.700000        95.111111\n",
       "18           adaptive     perplexity          NaN             NaN  Gaokao 2023 EN  qwen25_math_7b_instruct     68.961039  4.783411e+04     8874.603896         6.446753\n",
       "19  offline_best_of_n        entropy          NaN             NaN  Gaokao 2023 EN  qwen25_math_7b_instruct     68.917749  3.176159e+04     5892.687446         3.281385\n",
       "20           adaptive     perplexity          NaN             NaN       AIME 2025   vllm_thinking_qwen3_8b     68.888889  3.203161e+05   667325.144444        75.066667\n",
       "21           adaptive  sequence_prob          NaN             NaN  Gaokao 2023 EN  qwen25_math_7b_instruct     68.831169  4.455045e+04     8265.389610         6.394805\n",
       "22           baseline        entropy          NaN             NaN  Gaokao 2023 EN  qwen25_math_7b_instruct     68.571429  4.119668e+03      764.316883         1.000000\n",
       "23           adaptive        entropy          NaN             NaN  Gaokao 2023 EN  qwen25_math_7b_instruct     68.398268  3.967226e+04     7360.344589         6.079654\n",
       "24           adaptive            prm          NaN             NaN       AIME 2025   vllm_thinking_qwen3_8b     67.777778  9.682975e+05   684309.833333        78.088889\n",
       "25  extended_thinking        entropy          NaN             NaN       AIME 2025   vllm_thinking_qwen3_8b     66.666667  2.757390e+04    57445.633333              NaN\n",
       "26           adaptive        entropy          NaN             NaN       AIME 2025   vllm_thinking_qwen3_8b     65.555556  4.577552e+05   953656.722222        72.411111\n",
       "27  offline_best_of_n        entropy          NaN             NaN       AIME 2025   vllm_thinking_qwen3_8b     64.444444  6.490557e+04   135219.944444       138.955556\n",
       "28           baseline        entropy          NaN             NaN       AIME 2025   vllm_thinking_qwen3_8b     64.444444  8.083627e+03    16840.888889         0.872222\n",
       "29   self_consistency        entropy          NaN             NaN   OlympiadBench  qwen25_math_7b_instruct     44.691358  6.972329e+04     7378.125926         1.000000\n",
       "30   self_consistency        entropy          NaN             NaN    Minerva Math  qwen25_math_7b_instruct     44.485294  2.079287e+04     5460.312500         1.000000\n",
       "31           adaptive            prm          NaN             NaN   OlympiadBench  qwen25_math_7b_instruct     42.716049  4.313154e+05    14887.829136         8.399506\n",
       "32           baseline        entropy          NaN             NaN    Minerva Math  qwen25_math_7b_instruct     42.279412  3.062248e+03      804.161765         1.000000\n",
       "33           adaptive            prm          NaN             NaN    Minerva Math  qwen25_math_7b_instruct     40.808824  6.783468e+04     7118.209559         6.410539\n",
       "34           adaptive  sequence_prob          NaN             NaN   OlympiadBench  qwen25_math_7b_instruct     40.444444  1.203994e+05    12740.678025         8.498765\n",
       "35  offline_best_of_n        entropy          NaN             NaN    Minerva Math  qwen25_math_7b_instruct     40.441176  2.320258e+04     6093.113971         3.090074\n",
       "36           adaptive     perplexity          NaN             NaN   OlympiadBench  qwen25_math_7b_instruct     40.345679  1.051902e+05    11131.240000         7.729383\n",
       "37           adaptive        entropy          NaN             NaN   OlympiadBench  qwen25_math_7b_instruct     40.246914  9.157731e+04     9690.720494         7.374815\n",
       "38           adaptive     perplexity          NaN             NaN    Minerva Math  qwen25_math_7b_instruct     40.196078  2.594617e+04     6813.594363         6.273284\n",
       "39  offline_best_of_n        entropy          NaN             NaN   OlympiadBench  qwen25_math_7b_instruct     40.148148  7.883414e+04     8342.237037         3.632593\n",
       "40           adaptive  sequence_prob          NaN             NaN    Minerva Math  qwen25_math_7b_instruct     40.073529  2.624546e+04     6892.191176         6.549020\n",
       "41           adaptive        entropy          NaN             NaN    Minerva Math  qwen25_math_7b_instruct     39.460784  2.417567e+04     6348.651961         6.133578\n",
       "42           baseline        entropy          NaN             NaN   OlympiadBench  qwen25_math_7b_instruct     39.259259  9.683716e+03     1024.731852         1.000000\n",
       "43   self_consistency        entropy          NaN             NaN       AIME 2025   vllm_thinking_qwen3_8b     34.444444  5.368489e+04   111843.511111         0.788889"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ── Table 3: Compute Efficiency ───────────────────────────────────────────────\n",
    "\n",
    "eff_cols = [\"strategy\", \"scorer\", \"aggregation\", \"scoring_window\",\n",
    "            \"project_label\", \"model\",\n",
    "            \"exact_match_mean\", \"total_tflops_mean\",\n",
    "            \"avg_tokens_per_sample_mean\", \"avg_reasoning_steps_mean\"]\n",
    "present = [c for c in eff_cols if c in agg_df.columns]\n",
    "eff_df = agg_df[present].copy()\n",
    "\n",
    "# Rename for readability\n",
    "rename_map = {\n",
    "    \"exact_match_mean\": \"Accuracy (%)\",\n",
    "    \"total_tflops_mean\": \"Total TFLOPS\",\n",
    "    \"avg_tokens_per_sample_mean\": \"Tokens/Problem\",\n",
    "    \"avg_reasoning_steps_mean\": \"Reasoning Steps\",\n",
    "}\n",
    "eff_df.rename(columns={k: v for k, v in rename_map.items() if k in eff_df.columns},\n",
    "              inplace=True)\n",
    "\n",
    "eff_df.sort_values(\"Accuracy (%)\", ascending=False, inplace=True)\n",
    "print(\"Compute Efficiency Overview\")\n",
    "print(\"=\" * 40)\n",
    "display(eff_df.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% ── Strategy x Scorer — AIME 2024 ───────────────────────────────\n",
      "\\begin{table}[htbp]\n",
      "\\caption{Exact match accuracy (\\%) by strategy and scorer on AIME 2024.}\n",
      "\\label{tab:strategy_scorer_AIME 2024}\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "strategy & adaptive & baseline & extended\\_thinking & offline\\_best\\_of\\_n & self\\_consistency \\\\\n",
      "scorer &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "entropy & 74.4 +/- 3.8 & 75.6 +/- 2.7 & 78.9 +/- 5.1 & 75.6 +/- 5.1 & 82.2 +/- 1.9 \\\\\n",
      "perplexity & 76.7 +/- 0.0 & -- & -- & -- & -- \\\\\n",
      "prm & 77.8 +/- 3.8 & -- & -- & -- & -- \\\\\n",
      "sequence\\_prob & 76.7 +/- 3.3 & -- & -- & -- & -- \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "% ── Strategy x Scorer — AIME 2025 ───────────────────────────────\n",
      "\\begin{table}[htbp]\n",
      "\\caption{Exact match accuracy (\\%) by strategy and scorer on AIME 2025.}\n",
      "\\label{tab:strategy_scorer_AIME 2025}\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "strategy & adaptive & baseline & extended\\_thinking & offline\\_best\\_of\\_n & self\\_consistency \\\\\n",
      "scorer &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "entropy & 65.6 +/- 5.1 & 64.4 +/- 6.2 & 66.7 +/- 3.3 & 64.4 +/- 5.1 & 34.4 +/- 6.9 \\\\\n",
      "perplexity & 68.9 +/- 5.1 & -- & -- & -- & -- \\\\\n",
      "prm & 67.8 +/- 5.1 & -- & -- & -- & -- \\\\\n",
      "sequence\\_prob & 70.0 +/- 5.8 & -- & -- & -- & -- \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "% ── Strategy x Scorer — Gaokao 2023 EN ──────────────────────────\n",
      "\\begin{table}[htbp]\n",
      "\\caption{Exact match accuracy (\\%) by strategy and scorer on Gaokao 2023 EN.}\n",
      "\\label{tab:strategy_scorer_Gaokao 2023 EN}\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "strategy & adaptive & baseline & offline\\_best\\_of\\_n & self\\_consistency \\\\\n",
      "scorer &  &  &  &  \\\\\n",
      "\\midrule\n",
      "entropy & 68.4 +/- 0.9 & 68.6 +/- 0.0 & 68.9 +/- 0.3 & 72.4 +/- 1.2 \\\\\n",
      "perplexity & 69.0 +/- 0.9 & -- & -- & -- \\\\\n",
      "prm & 70.6 +/- 0.8 & -- & -- & -- \\\\\n",
      "sequence\\_prob & 68.8 +/- 1.6 & -- & -- & -- \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "% ── Strategy x Scorer — MATH-500 ────────────────────────────────\n",
      "\\begin{table}[htbp]\n",
      "\\caption{Exact match accuracy (\\%) by strategy and scorer on MATH-500.}\n",
      "\\label{tab:strategy_scorer_MATH-500}\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "strategy & adaptive & baseline & offline\\_best\\_of\\_n & self\\_consistency \\\\\n",
      "scorer &  &  &  &  \\\\\n",
      "\\midrule\n",
      "entropy & 84.0 +/- 0.5 & 83.2 +/- 0.0 & 84.6 +/- 1.1 & 86.4 +/- 0.5 \\\\\n",
      "perplexity & 84.5 +/- 0.1 & -- & -- & -- \\\\\n",
      "prm & 84.0 +/- 0.5 & -- & -- & -- \\\\\n",
      "sequence\\_prob & 83.6 +/- 0.5 & -- & -- & -- \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "% ── Strategy x Scorer — Minerva Math ────────────────────────────\n",
      "\\begin{table}[htbp]\n",
      "\\caption{Exact match accuracy (\\%) by strategy and scorer on Minerva Math.}\n",
      "\\label{tab:strategy_scorer_Minerva Math}\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "strategy & adaptive & baseline & offline\\_best\\_of\\_n & self\\_consistency \\\\\n",
      "scorer &  &  &  &  \\\\\n",
      "\\midrule\n",
      "entropy & 39.5 +/- 2.6 & 42.3 +/- 0.0 & 40.4 +/- 0.0 & 44.5 +/- 0.7 \\\\\n",
      "perplexity & 40.2 +/- 0.8 & -- & -- & -- \\\\\n",
      "prm & 40.8 +/- 1.3 & -- & -- & -- \\\\\n",
      "sequence\\_prob & 40.1 +/- 1.9 & -- & -- & -- \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "% ── Strategy x Scorer — OlympiadBench ───────────────────────────\n",
      "\\begin{table}[htbp]\n",
      "\\caption{Exact match accuracy (\\%) by strategy and scorer on OlympiadBench.}\n",
      "\\label{tab:strategy_scorer_OlympiadBench}\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "strategy & adaptive & baseline & offline\\_best\\_of\\_n & self\\_consistency \\\\\n",
      "scorer &  &  &  &  \\\\\n",
      "\\midrule\n",
      "entropy & 40.2 +/- 0.9 & 39.3 +/- 0.0 & 40.1 +/- 1.0 & 44.7 +/- 0.6 \\\\\n",
      "perplexity & 40.3 +/- 1.5 & -- & -- & -- \\\\\n",
      "prm & 42.7 +/- 0.7 & -- & -- & -- \\\\\n",
      "sequence\\_prob & 40.4 +/- 1.1 & -- & -- & -- \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "% ── Compute Efficiency ──────────────────────────────────────────\n",
      "\\begin{table}[htbp]\n",
      "\\caption{Compute efficiency comparison across strategies.}\n",
      "\\label{tab:compute_efficiency}\n",
      "\\begin{tabular}{lllrrllrrrr}\n",
      "\\toprule\n",
      " & strategy & scorer & aggregation & scoring\\_window & project\\_label & model & Accuracy (\\%) & Total TFLOPS & Tokens/Problem & Reasoning Steps \\\\\n",
      "\\midrule\n",
      "0 & self\\_consistency & entropy & -- & -- & MATH-500 & qwen25\\_math\\_7b\\_instruct & 86.400000 & 35680.222667 & 5097.174667 & 1.000000 \\\\\n",
      "1 & offline\\_best\\_of\\_n & entropy & -- & -- & MATH-500 & qwen25\\_math\\_7b\\_instruct & 84.600000 & 37656.845333 & 5379.549333 & 3.580667 \\\\\n",
      "2 & adaptive & perplexity & -- & -- & MATH-500 & qwen25\\_math\\_7b\\_instruct & 84.533333 & 52408.612667 & 7486.944667 & 6.204000 \\\\\n",
      "3 & adaptive & entropy & -- & -- & MATH-500 & qwen25\\_math\\_7b\\_instruct & 84.000000 & 49390.292000 & 7055.756000 & 6.054667 \\\\\n",
      "4 & adaptive & prm & -- & -- & MATH-500 & qwen25\\_math\\_7b\\_instruct & 84.000000 & 169527.792000 & 9074.406667 & 6.216000 \\\\\n",
      "5 & adaptive & sequence\\_prob & -- & -- & MATH-500 & qwen25\\_math\\_7b\\_instruct & 83.600000 & 54883.817333 & 7840.545333 & 6.334667 \\\\\n",
      "6 & baseline & entropy & -- & -- & MATH-500 & qwen25\\_math\\_7b\\_instruct & 83.200000 & 5133.156000 & 733.308000 & 1.000000 \\\\\n",
      "7 & self\\_consistency & entropy & -- & -- & AIME 2024 & vllm\\_thinking\\_qwen3\\_8b & 82.222222 & 52797.221333 & 109994.211111 & 0.765278 \\\\\n",
      "8 & extended\\_thinking & entropy & -- & -- & AIME 2024 & vllm\\_thinking\\_qwen3\\_8b & 78.888889 & 26477.653333 & 55161.777778 & -- \\\\\n",
      "9 & adaptive & prm & -- & -- & AIME 2024 & vllm\\_thinking\\_qwen3\\_8b & 77.777778 & 1446221.952667 & 954790.988889 & 80.888889 \\\\\n",
      "10 & adaptive & perplexity & -- & -- & AIME 2024 & vllm\\_thinking\\_qwen3\\_8b & 76.666667 & 312986.720000 & 652055.666667 & 69.155556 \\\\\n",
      "11 & adaptive & sequence\\_prob & -- & -- & AIME 2024 & vllm\\_thinking\\_qwen3\\_8b & 76.666667 & 340592.768000 & 709568.266667 & 79.933333 \\\\\n",
      "12 & offline\\_best\\_of\\_n & entropy & -- & -- & AIME 2024 & vllm\\_thinking\\_qwen3\\_8b & 75.555556 & 53669.712000 & 111811.900000 & 103.222222 \\\\\n",
      "13 & baseline & entropy & -- & -- & AIME 2024 & vllm\\_thinking\\_qwen3\\_8b & 75.555556 & 6626.936000 & 13806.116667 & 0.955556 \\\\\n",
      "14 & adaptive & entropy & -- & -- & AIME 2024 & vllm\\_thinking\\_qwen3\\_8b & 74.444444 & 313539.680000 & 653207.666667 & 68.133333 \\\\\n",
      "15 & self\\_consistency & entropy & -- & -- & Gaokao 2023 EN & qwen25\\_math\\_7b\\_instruct & 72.380952 & 28817.138000 & 5346.407792 & 1.000000 \\\\\n",
      "16 & adaptive & prm & -- & -- & Gaokao 2023 EN & qwen25\\_math\\_7b\\_instruct & 70.649351 & 138830.976667 & 9458.550649 & 6.475325 \\\\\n",
      "17 & adaptive & sequence\\_prob & -- & -- & AIME 2025 & vllm\\_thinking\\_qwen3\\_8b & 70.000000 & 459197.616000 & 956661.700000 & 95.111111 \\\\\n",
      "18 & adaptive & perplexity & -- & -- & Gaokao 2023 EN & qwen25\\_math\\_7b\\_instruct & 68.961039 & 47834.115000 & 8874.603896 & 6.446753 \\\\\n",
      "19 & offline\\_best\\_of\\_n & entropy & -- & -- & Gaokao 2023 EN & qwen25\\_math\\_7b\\_instruct & 68.917749 & 31761.585333 & 5892.687446 & 3.281385 \\\\\n",
      "20 & adaptive & perplexity & -- & -- & AIME 2025 & vllm\\_thinking\\_qwen3\\_8b & 68.888889 & 320316.069333 & 667325.144444 & 75.066667 \\\\\n",
      "21 & adaptive & sequence\\_prob & -- & -- & Gaokao 2023 EN & qwen25\\_math\\_7b\\_instruct & 68.831169 & 44550.450000 & 8265.389610 & 6.394805 \\\\\n",
      "22 & baseline & entropy & -- & -- & Gaokao 2023 EN & qwen25\\_math\\_7b\\_instruct & 68.571429 & 4119.668000 & 764.316883 & 1.000000 \\\\\n",
      "23 & adaptive & entropy & -- & -- & Gaokao 2023 EN & qwen25\\_math\\_7b\\_instruct & 68.398268 & 39672.257333 & 7360.344589 & 6.079654 \\\\\n",
      "24 & adaptive & prm & -- & -- & AIME 2025 & vllm\\_thinking\\_qwen3\\_8b & 67.777778 & 968297.513333 & 684309.833333 & 78.088889 \\\\\n",
      "25 & extended\\_thinking & entropy & -- & -- & AIME 2025 & vllm\\_thinking\\_qwen3\\_8b & 66.666667 & 27573.904000 & 57445.633333 & -- \\\\\n",
      "26 & adaptive & entropy & -- & -- & AIME 2025 & vllm\\_thinking\\_qwen3\\_8b & 65.555556 & 457755.226667 & 953656.722222 & 72.411111 \\\\\n",
      "27 & offline\\_best\\_of\\_n & entropy & -- & -- & AIME 2025 & vllm\\_thinking\\_qwen3\\_8b & 64.444444 & 64905.573333 & 135219.944444 & 138.955556 \\\\\n",
      "28 & baseline & entropy & -- & -- & AIME 2025 & vllm\\_thinking\\_qwen3\\_8b & 64.444444 & 8083.626667 & 16840.888889 & 0.872222 \\\\\n",
      "29 & self\\_consistency & entropy & -- & -- & OlympiadBench & qwen25\\_math\\_7b\\_instruct & 44.691358 & 69723.290000 & 7378.125926 & 1.000000 \\\\\n",
      "30 & self\\_consistency & entropy & -- & -- & Minerva Math & qwen25\\_math\\_7b\\_instruct & 44.485294 & 20792.870000 & 5460.312500 & 1.000000 \\\\\n",
      "31 & adaptive & prm & -- & -- & OlympiadBench & qwen25\\_math\\_7b\\_instruct & 42.716049 & 431315.416000 & 14887.829136 & 8.399506 \\\\\n",
      "32 & baseline & entropy & -- & -- & Minerva Math & qwen25\\_math\\_7b\\_instruct & 42.279412 & 3062.248000 & 804.161765 & 1.000000 \\\\\n",
      "33 & adaptive & prm & -- & -- & Minerva Math & qwen25\\_math\\_7b\\_instruct & 40.808824 & 67834.676000 & 7118.209559 & 6.410539 \\\\\n",
      "34 & adaptive & sequence\\_prob & -- & -- & OlympiadBench & qwen25\\_math\\_7b\\_instruct & 40.444444 & 120399.407333 & 12740.678025 & 8.498765 \\\\\n",
      "35 & offline\\_best\\_of\\_n & entropy & -- & -- & Minerva Math & qwen25\\_math\\_7b\\_instruct & 40.441176 & 23202.578000 & 6093.113971 & 3.090074 \\\\\n",
      "36 & adaptive & perplexity & -- & -- & OlympiadBench & qwen25\\_math\\_7b\\_instruct & 40.345679 & 105190.218000 & 11131.240000 & 7.729383 \\\\\n",
      "37 & adaptive & entropy & -- & -- & OlympiadBench & qwen25\\_math\\_7b\\_instruct & 40.246914 & 91577.308667 & 9690.720494 & 7.374815 \\\\\n",
      "38 & adaptive & perplexity & -- & -- & Minerva Math & qwen25\\_math\\_7b\\_instruct & 40.196078 & 25946.167333 & 6813.594363 & 6.273284 \\\\\n",
      "39 & offline\\_best\\_of\\_n & entropy & -- & -- & OlympiadBench & qwen25\\_math\\_7b\\_instruct & 40.148148 & 78834.140000 & 8342.237037 & 3.632593 \\\\\n",
      "40 & adaptive & sequence\\_prob & -- & -- & Minerva Math & qwen25\\_math\\_7b\\_instruct & 40.073529 & 26245.464000 & 6892.191176 & 6.549020 \\\\\n",
      "41 & adaptive & entropy & -- & -- & Minerva Math & qwen25\\_math\\_7b\\_instruct & 39.460784 & 24175.666667 & 6348.651961 & 6.133578 \\\\\n",
      "42 & baseline & entropy & -- & -- & OlympiadBench & qwen25\\_math\\_7b\\_instruct & 39.259259 & 9683.716000 & 1024.731852 & 1.000000 \\\\\n",
      "43 & self\\_consistency & entropy & -- & -- & AIME 2025 & vllm\\_thinking\\_qwen3\\_8b & 34.444444 & 53684.885333 & 111843.511111 & 0.788889 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ── LaTeX Export ──────────────────────────────────────────────────────────────\n",
    "\n",
    "def to_latex(df: pd.DataFrame, caption: str, label: str) -> str:\n",
    "    \"\"\"Convert a DataFrame to a booktabs LaTeX table string.\"\"\"\n",
    "    latex = df.to_latex(\n",
    "        index=True,\n",
    "        escape=True,\n",
    "        na_rep=\"--\",\n",
    "        caption=caption,\n",
    "        label=label,\n",
    "        position=\"htbp\",\n",
    "    )\n",
    "    # Add booktabs rules\n",
    "    latex = latex.replace(\"\\\\toprule\", \"\\\\toprule\")  # already there with booktabs\n",
    "    return latex\n",
    "\n",
    "\n",
    "# Re-generate tables and export as LaTeX\n",
    "latex_outputs = []\n",
    "\n",
    "# Strategy x Scorer tables\n",
    "for dataset_label in sorted(agg_df[\"project_label\"].dropna().unique()):\n",
    "    tbl = make_comparison_table(\n",
    "        agg_df,\n",
    "        row_field=\"scorer\",\n",
    "        col_field=\"strategy\",\n",
    "        value_field=\"exact_match_fmt\",\n",
    "        filter_dict={\"project_label\": dataset_label},\n",
    "    )\n",
    "    if not tbl.empty:\n",
    "        ltx = to_latex(\n",
    "            tbl,\n",
    "            caption=f\"Exact match accuracy (\\\\%) by strategy and scorer on {dataset_label}.\",\n",
    "            label=f\"tab:strategy_scorer_{dataset_label}\",\n",
    "        )\n",
    "        latex_outputs.append((f\"Strategy x Scorer — {dataset_label}\", ltx))\n",
    "\n",
    "# Beam search aggregation x window tables\n",
    "if not beam_df.empty:\n",
    "    for scorer in sorted(beam_df[\"scorer\"].dropna().unique()):\n",
    "        for dataset_label in sorted(beam_df[\"project_label\"].dropna().unique()):\n",
    "            tbl = make_comparison_table(\n",
    "                beam_df,\n",
    "                row_field=\"aggregation\",\n",
    "                col_field=\"scoring_window\",\n",
    "                value_field=\"exact_match_fmt\",\n",
    "                filter_dict={\"scorer\": scorer, \"project_label\": dataset_label},\n",
    "            )\n",
    "            if not tbl.empty:\n",
    "                ltx = to_latex(\n",
    "                    tbl,\n",
    "                    caption=f\"Beam search accuracy (\\\\%) — scorer={scorer}, dataset={dataset_label}.\",\n",
    "                    label=f\"tab:beam_{scorer}_{dataset_label}\",\n",
    "                )\n",
    "                latex_outputs.append((f\"Beam {scorer} — {dataset_label}\", ltx))\n",
    "\n",
    "# Efficiency table\n",
    "if not eff_df.empty:\n",
    "    ltx = to_latex(\n",
    "        eff_df.reset_index(drop=True),\n",
    "        caption=\"Compute efficiency comparison across strategies.\",\n",
    "        label=\"tab:compute_efficiency\",\n",
    "    )\n",
    "    latex_outputs.append((\"Compute Efficiency\", ltx))\n",
    "\n",
    "# Print all LaTeX\n",
    "for title, ltx in latex_outputs:\n",
    "    print(f\"% ── {title} \" + \"─\" * (60 - len(title)))\n",
    "    print(ltx)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3600x500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ── Visualization ─────────────────────────────────────────────────────────────\n",
    "\n",
    "# Bar chart: accuracy by strategy (per dataset)\n",
    "plot_df = agg_df.dropna(subset=[\"exact_match_mean\"]).copy()\n",
    "\n",
    "if not plot_df.empty:\n",
    "    fig, axes = plt.subplots(\n",
    "        1, max(1, plot_df[\"project_label\"].nunique()),\n",
    "        figsize=(6 * max(1, plot_df[\"project_label\"].nunique()), 5),\n",
    "        squeeze=False,\n",
    "    )\n",
    "    for idx, dataset_label in enumerate(sorted(plot_df[\"project_label\"].unique())):\n",
    "        ax = axes[0, idx]\n",
    "        sub = plot_df[plot_df[\"project_label\"] == dataset_label]\n",
    "        # Average across scorers/configs per strategy\n",
    "        bars = sub.groupby(\"strategy\")[\"exact_match_mean\"].mean().sort_values()\n",
    "        bars.plot.barh(ax=ax, color=\"steelblue\")\n",
    "        ax.set_xlabel(\"Exact Match (%)\")\n",
    "        ax.set_title(dataset_label)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data for bar chart.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install seaborn for heatmap visualization: pip install seaborn\n"
     ]
    }
   ],
   "source": [
    "# Heatmap: beam search scorer x aggregation x window\n",
    "\n",
    "if sns is None:\n",
    "    print(\"Install seaborn for heatmap visualization: pip install seaborn\")\n",
    "elif not beam_df.empty:\n",
    "    heat_df = beam_df.dropna(subset=[\"exact_match_mean\"]).copy()\n",
    "    heat_df[\"config\"] = heat_df[\"aggregation\"].astype(str) + \" / w=\" + heat_df[\"scoring_window\"].astype(str)\n",
    "\n",
    "    for dataset_label in sorted(heat_df[\"project_label\"].dropna().unique()):\n",
    "        sub = heat_df[heat_df[\"project_label\"] == dataset_label]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        pivot = sub.pivot_table(\n",
    "            index=\"config\", columns=\"scorer\",\n",
    "            values=\"exact_match_mean\", aggfunc=\"first\",\n",
    "        )\n",
    "        if pivot.empty:\n",
    "            continue\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(max(6, pivot.shape[1] * 2), max(4, pivot.shape[0] * 0.6)))\n",
    "        sns.heatmap(pivot, annot=True, fmt=\".1f\", cmap=\"YlGnBu\", ax=ax)\n",
    "        ax.set_title(f\"Beam Search Accuracy — {dataset_label}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No beam search data for heatmap.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline BoN Multi-Scorer Analysis\n",
    "\n",
    "Download `candidates.json` from multi-scorer offline BoN runs and re-analyze\n",
    "with different scorers, aggregation methods, and scoring windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTLR runtime and generated code versions disagree: 4.9.3!=4.7.2\n",
      "ANTLR runtime and generated code versions disagree: 4.9.3!=4.7.2\n",
      "ANTLR runtime and generated code versions disagree: 4.9.3!=4.7.2\n",
      "ANTLR runtime and generated code versions disagree: 4.9.3!=4.7.2\n",
      "Imported analyze_candidates functions\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json as _json\n",
    "from pathlib import Path as _Path\n",
    "\n",
    "# Add project root and scripts/ to path so we can import analyze_candidates\n",
    "_project_root = _Path.cwd().parent if _Path.cwd().name == \"notebooks\" else _Path.cwd()\n",
    "for _p in [str(_project_root), str(_project_root / \"scripts\")]:\n",
    "    if _p not in sys.path:\n",
    "        sys.path.insert(0, _p)\n",
    "\n",
    "from analyze_candidates import (\n",
    "    aggregate_scores,\n",
    "    select_best_candidate,\n",
    "    precompute_correctness,\n",
    "    analyze,\n",
    "    analyze_all_windows,\n",
    "    _save_csv,\n",
    ")\n",
    "\n",
    "print(\"Imported analyze_candidates functions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registry: 6 dataset(s)\n",
      "  MATH-500: 3 run(s)\n",
      "  Minerva Math: 2 run(s)\n",
      "  Gaokao 2023 EN: 3 run(s)\n",
      "  OlympiadBench: 3 run(s)\n",
      "  AIME 2024: 3 run(s)\n",
      "  AIME 2025: 3 run(s)\n"
     ]
    }
   ],
   "source": [
    "# ── Offline BoN Registry ──────────────────────────────────────────────────────\n",
    "# Maps run lists → (data_name, answer_format, display_label) for candidates.json analysis.\n",
    "\n",
    "OFFLINE_BON_REGISTRY = [\n",
    "    (MATH500_OFFLINE_BON_RUNS, \"math500\", \"numeric\", \"MATH-500\"),\n",
    "    (MINERVA_OFFLINE_BON_RUNS, \"minerva_math\", \"numeric\", \"Minerva Math\"),\n",
    "    (GAOKAO_OFFLINE_BON_RUNS, \"gaokao2023en\", \"numeric\", \"Gaokao 2023 EN\"),\n",
    "    (OLYMPIAD_OFFLINE_BON_RUNS, \"olympiadbench\", \"numeric\", \"OlympiadBench\"),\n",
    "    (AIME_24_OFFLINE_BON_RUNS, \"aime2024\", \"numeric\", \"AIME 2024\"),\n",
    "    (AIME_25_OFFLINE_BON_RUNS, \"aime2025\", \"numeric\", \"AIME 2025\"),\n",
    "    # (GPQA_OFFLINE_BON_RUNS, \"gpqa_diamond\", \"char\", \"GPQA Diamond\"),\n",
    "]\n",
    "\n",
    "print(f\"Registry: {len(OFFLINE_BON_REGISTRY)} dataset(s)\")\n",
    "for run_list, dname, fmt, label in OFFLINE_BON_REGISTRY:\n",
    "    n_runs = sum(len(e.get(\"runs\", [])) for e in run_list if e.get(\"group_url\"))\n",
    "    print(f\"  {label}: {n_runs} run(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MATH-500 (math500)\n",
      "  seed=42  samples=500\n",
      "  seed=43  samples=500\n",
      "  seed=44  samples=500\n",
      "\n",
      "Minerva Math (minerva_math)\n",
      "  seed=42  samples=272\n",
      "  seed=43  samples=272\n",
      "\n",
      "Gaokao 2023 EN (gaokao2023en)\n",
      "  seed=42  samples=385\n",
      "  seed=43  samples=385\n",
      "  seed=44  samples=385\n",
      "\n",
      "OlympiadBench (olympiadbench)\n",
      "  seed=42  samples=675\n",
      "  seed=43  samples=675\n",
      "  seed=44  samples=675\n",
      "\n",
      "AIME 2024 (aime2024)\n",
      "  seed=42  samples=30\n",
      "  seed=43  samples=30\n",
      "  seed=44  samples=30\n",
      "\n",
      "AIME 2025 (aime2025)\n",
      "  seed=42  samples=30\n",
      "  seed=43  samples=30\n",
      "  seed=44  samples=30\n",
      "\n",
      "Loaded 17 candidate file(s)\n"
     ]
    }
   ],
   "source": [
    "# ── Download candidates.json from wandb ───────────────────────────────────────\n",
    "\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "CANDIDATES_CACHE_DIR = _Path(\"cache/candidates\")\n",
    "\n",
    "\n",
    "def download_candidates(run_id: str, entity: str, project: str,\n",
    "                        data_name: str, seed: int) -> _Path:\n",
    "    \"\"\"Download candidates.json for a run, with disk caching.\"\"\"\n",
    "    cache_path = CANDIDATES_CACHE_DIR / data_name / f\"seed_{seed}\" / run_id\n",
    "    candidates_file = cache_path / \"candidates.json\"\n",
    "\n",
    "    if candidates_file.exists():\n",
    "        return candidates_file\n",
    "\n",
    "    cache_path.mkdir(parents=True, exist_ok=True)\n",
    "    run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "\n",
    "    # Download to a temp dir then move (atomic-ish)\n",
    "    with tempfile.TemporaryDirectory() as tmp:\n",
    "        try:\n",
    "            f = run.file(\"candidates.json\")\n",
    "            f.download(root=tmp, replace=True)\n",
    "            src = _Path(tmp) / \"candidates.json\"\n",
    "            shutil.move(str(src), str(candidates_file))\n",
    "            print(f\"  Downloaded → {candidates_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR downloading candidates.json for {run_id}: {e}\")\n",
    "            return None\n",
    "\n",
    "    return candidates_file\n",
    "\n",
    "\n",
    "# Download all candidates.json files\n",
    "candidates_store = {}   # (data_name, seed) -> list[dict]\n",
    "run_meta = {}           # (data_name, seed) -> metadata dict\n",
    "\n",
    "for run_list, data_name, answer_format, project_label in OFFLINE_BON_REGISTRY:\n",
    "    print(f\"\\n{project_label} ({data_name})\")\n",
    "    for entry in run_list:\n",
    "        if not entry.get(\"group_url\") or not entry.get(\"runs\"):\n",
    "            continue\n",
    "        for run_entry in entry[\"runs\"]:\n",
    "            seed = run_entry[\"seed\"]\n",
    "            run_url = run_entry.get(\"run_url\", \"\")\n",
    "            if not run_url:\n",
    "                continue\n",
    "            info = parse_run_url(run_url)\n",
    "            cpath = download_candidates(\n",
    "                info[\"run_id\"], info[\"entity\"], info[\"project\"],\n",
    "                data_name, seed,\n",
    "            )\n",
    "            if cpath and cpath.exists():\n",
    "                with open(cpath) as fh:\n",
    "                    data = _json.load(fh)\n",
    "                candidates_store[(data_name, seed)] = data\n",
    "                run_meta[(data_name, seed)] = {\n",
    "                    \"project_label\": project_label,\n",
    "                    \"answer_format\": answer_format,\n",
    "                    \"data_name\": data_name,\n",
    "                    \"run_id\": info[\"run_id\"],\n",
    "                }\n",
    "                print(f\"  seed={seed}  samples={len(data)}\")\n",
    "\n",
    "print(f\"\\nLoaded {len(candidates_store)} candidate file(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing: 100%|██████████| 17/17 [00:00<00:00, 224.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIME 2024 seed=42: loaded from cache/candidates/aime2024/seed_42/b8ljb1q8/scoring_analysis.csv\n",
      "AIME 2024 seed=43: loaded from cache/candidates/aime2024/seed_43/p3pcxz2f/scoring_analysis.csv\n",
      "AIME 2024 seed=44: loaded from cache/candidates/aime2024/seed_44/my2dup72/scoring_analysis.csv\n",
      "AIME 2025 seed=42: loaded from cache/candidates/aime2025/seed_42/ja291w66/scoring_analysis.csv\n",
      "AIME 2025 seed=43: loaded from cache/candidates/aime2025/seed_43/x7govl6j/scoring_analysis.csv\n",
      "AIME 2025 seed=44: loaded from cache/candidates/aime2025/seed_44/qgbbh2v3/scoring_analysis.csv\n",
      "Gaokao 2023 EN seed=42: loaded from cache/candidates/gaokao2023en/seed_42/qijvr95c/scoring_analysis.csv\n",
      "Gaokao 2023 EN seed=43: loaded from cache/candidates/gaokao2023en/seed_43/jboxbdly/scoring_analysis.csv\n",
      "Gaokao 2023 EN seed=44: loaded from cache/candidates/gaokao2023en/seed_44/nh8fx6pk/scoring_analysis.csv\n",
      "MATH-500 seed=42: loaded from cache/candidates/math500/seed_42/c35z6knc/scoring_analysis.csv\n",
      "MATH-500 seed=43: loaded from cache/candidates/math500/seed_43/d7jh7cbj/scoring_analysis.csv\n",
      "MATH-500 seed=44: loaded from cache/candidates/math500/seed_44/cz45vmb2/scoring_analysis.csv\n",
      "Minerva Math seed=42: loaded from cache/candidates/minerva_math/seed_42/7syo0ks4/scoring_analysis.csv\n",
      "Minerva Math seed=43: loaded from cache/candidates/minerva_math/seed_43/y6udmktu/scoring_analysis.csv\n",
      "OlympiadBench seed=42: loaded from cache/candidates/olympiadbench/seed_42/scg2r5g6/scoring_analysis.csv\n",
      "OlympiadBench seed=43: loaded from cache/candidates/olympiadbench/seed_43/lrbsr0b6/scoring_analysis.csv\n",
      "OlympiadBench seed=44: loaded from cache/candidates/olympiadbench/seed_44/gzpylxq2/scoring_analysis.csv\n",
      "\n",
      "Total records: 71217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>data_name</th>\n",
       "      <th>seed</th>\n",
       "      <th>scorer</th>\n",
       "      <th>aggregation</th>\n",
       "      <th>window</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIME 2024</td>\n",
       "      <td>aime2024</td>\n",
       "      <td>42</td>\n",
       "      <td>oracle</td>\n",
       "      <td>—</td>\n",
       "      <td>all</td>\n",
       "      <td>86.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIME 2024</td>\n",
       "      <td>aime2024</td>\n",
       "      <td>42</td>\n",
       "      <td>entropy</td>\n",
       "      <td>mean</td>\n",
       "      <td>1</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIME 2024</td>\n",
       "      <td>aime2024</td>\n",
       "      <td>42</td>\n",
       "      <td>entropy</td>\n",
       "      <td>mean</td>\n",
       "      <td>2</td>\n",
       "      <td>60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIME 2024</td>\n",
       "      <td>aime2024</td>\n",
       "      <td>42</td>\n",
       "      <td>entropy</td>\n",
       "      <td>mean</td>\n",
       "      <td>3</td>\n",
       "      <td>63.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AIME 2024</td>\n",
       "      <td>aime2024</td>\n",
       "      <td>42</td>\n",
       "      <td>entropy</td>\n",
       "      <td>mean</td>\n",
       "      <td>4</td>\n",
       "      <td>63.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset data_name  seed   scorer aggregation window  accuracy\n",
       "0  AIME 2024  aime2024    42   oracle           —    all     86.67\n",
       "1  AIME 2024  aime2024    42  entropy        mean      1     66.67\n",
       "2  AIME 2024  aime2024    42  entropy        mean      2     60.00\n",
       "3  AIME 2024  aime2024    42  entropy        mean      3     63.33\n",
       "4  AIME 2024  aime2024    42  entropy        mean      4     63.33"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ── Multi-scorer analysis across all windows ──────────────────────────────────\n",
    "# Computes accuracy for every (scorer × aggregation × window) combo per dataset/seed.\n",
    "# Cached: skips analysis if scoring_analysis.csv already exists next to candidates.json.\n",
    "\n",
    "import csv\n",
    "\n",
    "bon_records = []\n",
    "\n",
    "for (data_name, seed), candidates_data in tqdm(sorted(candidates_store.items()), desc=\"Analyzing\"):\n",
    "    meta = run_meta[(data_name, seed)]\n",
    "    label = meta[\"project_label\"]\n",
    "    run_cache = CANDIDATES_CACHE_DIR / data_name / f\"seed_{seed}\" / meta[\"run_id\"]\n",
    "    csv_path = run_cache / \"scoring_analysis.csv\"\n",
    "\n",
    "    if csv_path.exists():\n",
    "        # Load cached results\n",
    "        with open(csv_path) as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                bon_records.append({\n",
    "                    \"dataset\": label,\n",
    "                    \"data_name\": data_name,\n",
    "                    \"seed\": seed,\n",
    "                    \"scorer\": row[\"scorer\"],\n",
    "                    \"aggregation\": row[\"aggregation\"] or \"—\",\n",
    "                    \"window\": row[\"window\"] or \"all\",\n",
    "                    \"accuracy\": float(row[\"exact_match\"]) * 100,\n",
    "                })\n",
    "        print(f\"{label} seed={seed}: loaded from {csv_path}\")\n",
    "        continue\n",
    "\n",
    "    # Run analysis\n",
    "    all_results, correctness, oracle_acc, max_steps = analyze_all_windows(\n",
    "        candidates_data, data_name, meta[\"answer_format\"],\n",
    "    )\n",
    "    print(f\"{label} seed={seed}: {len(candidates_data)} samples, \"\n",
    "          f\"max_steps={max_steps}, oracle={oracle_acc*100:.1f}%\")\n",
    "\n",
    "    # Save CSV next to candidates.json\n",
    "    _save_csv(all_results, csv_path, oracle_acc=oracle_acc)\n",
    "\n",
    "    for window_label, scorer_dict in all_results.items():\n",
    "        wval = window_label.split(\"=\", 1)[1]\n",
    "        for scorer, agg_dict in scorer_dict.items():\n",
    "            for agg_method, accuracy in agg_dict.items():\n",
    "                bon_records.append({\n",
    "                    \"dataset\": label,\n",
    "                    \"data_name\": data_name,\n",
    "                    \"seed\": seed,\n",
    "                    \"scorer\": scorer,\n",
    "                    \"aggregation\": agg_method,\n",
    "                    \"window\": wval,\n",
    "                    \"accuracy\": accuracy * 100,\n",
    "                })\n",
    "        bon_records.append({\n",
    "            \"dataset\": label,\n",
    "            \"data_name\": data_name,\n",
    "            \"seed\": seed,\n",
    "            \"scorer\": \"oracle\",\n",
    "            \"aggregation\": \"—\",\n",
    "            \"window\": wval,\n",
    "            \"accuracy\": oracle_acc * 100,\n",
    "        })\n",
    "\n",
    "bon_analysis_df = pd.DataFrame(bon_records)\n",
    "print(f\"\\nTotal records: {len(bon_analysis_df)}\")\n",
    "bon_analysis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated: 26886 rows\n",
      "Datasets:   ['AIME 2024', 'AIME 2025', 'Gaokao 2023 EN', 'MATH-500', 'Minerva Math', 'OlympiadBench']\n",
      "Scorers:    ['entropy', 'oracle', 'pd_gap', 'perplexity', 'prm', 'sequence_prob']\n",
      "Windows:    ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '300', '301', '302', '303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '380', '381', '382', '383', '384', '385', '386', '387', '388', '389', '390', '391', '392', '393', '394', '395', '396', '397', '398', '399', '400', '401', '402', '403', '404', '405', '406', '407', '408', '409', '410', '411', '412', '413', '414', '415', '416', '417', '418', '419', '420', '421', '422', '423', '424', '425', '426', '427', '428', '429', '430', '431', '432', '433', '434', '435', '436', '437', '438', '439', '440', '441', '442', '443', '444', '445', '446', '447', '448', '449', '450', '451', '452', '453', '454', '455', '456', '457', '458', '459', '460', '461', '462', '463', '464', '465', '466', '467', '468', '469', '470', '471', '472', '473', '474', '475', '476', '477', '478', '479', '480', '481', '482', '483', '484', '485', '486', '487', '488', '489', '490', '491', '492', '493', '494', '495', '496', '497', '498', '499', '500', '501', '502', '503', '504', '505', '506', '507', '508', '509', '510', '511', '512', '513', '514', '515', '516', '517', '518', '519', '520', '521', '522', '523', '524', '525', '526', '527', '528', '529', '530', '531', '532', '533', '534', '535', '536', '537', '538', '539', '540', '541', '542', '543', '544', '545', '546', '547', '548', '549', '550', '551', '552', '553', '554', '555', '556', '557', '558', '559', '560', '561', '562', '563', '564', '565', '566', '567', '568', '569', '570', '571', '572', '573', '574', '575', '576', '577', '578', '579', '580', '581', '582', '583', '584', '585', '586', '587', '588', '589', '590', '591', '592', '593', '594', '595', '596', '597', '598', '599', '600', '601', '602', '603', '604', '605', '606', '607', '608', '609', '610', '611', '612', '613', '614', '615', '616', '617', '618', '619', '620', '621', '622', '623', '624', '625', '626', '627', '628', '629', '630', '631', '632', '633', '634', '635', '636', 'all']\n",
      "\n",
      "Qwen2.5-Math-7B-Instruct (window=all, aggregation=mean)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>MATH-500</th>\n",
       "      <th>OlympiadBench</th>\n",
       "      <th>Minerva Math</th>\n",
       "      <th>Gaokao 2023 EN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scorer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>83.2 +/- 0.0</td>\n",
       "      <td>39.3 +/- 0.0</td>\n",
       "      <td>42.3 +/- 0.0</td>\n",
       "      <td>68.6 +/- 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-consistency</th>\n",
       "      <td>86.4 +/- 0.5</td>\n",
       "      <td>44.7 +/- 0.6</td>\n",
       "      <td>44.5 +/- 0.7</td>\n",
       "      <td>72.4 +/- 1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oracle</th>\n",
       "      <td>91.1 ± 0.1</td>\n",
       "      <td>59.1 ± 1.5</td>\n",
       "      <td>50.0 ± 9.9</td>\n",
       "      <td>80.8 ± 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>85.1 ± 1.0</td>\n",
       "      <td>40.3 ± 0.9</td>\n",
       "      <td>36.0 ± 7.8</td>\n",
       "      <td>69.8 ± 1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity</th>\n",
       "      <td>86.0 ± 0.5</td>\n",
       "      <td>42.0 ± 0.9</td>\n",
       "      <td>38.8 ± 8.6</td>\n",
       "      <td>71.4 ± 0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob</th>\n",
       "      <td>85.9 ± 0.2</td>\n",
       "      <td>40.7 ± 1.1</td>\n",
       "      <td>39.7 ± 7.8</td>\n",
       "      <td>71.0 ± 0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd_gap</th>\n",
       "      <td>85.9 ± 1.0</td>\n",
       "      <td>41.8 ± 0.4</td>\n",
       "      <td>37.9 ± 9.4</td>\n",
       "      <td>71.6 ± 1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prm</th>\n",
       "      <td>87.6 ± 0.7</td>\n",
       "      <td>45.2 ± 1.7</td>\n",
       "      <td>40.3 ± 9.1</td>\n",
       "      <td>74.2 ± 0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset               MATH-500 OlympiadBench  Minerva Math Gaokao 2023 EN\n",
       "scorer                                                                   \n",
       "baseline          83.2 +/- 0.0  39.3 +/- 0.0  42.3 +/- 0.0   68.6 +/- 0.0\n",
       "self-consistency  86.4 +/- 0.5  44.7 +/- 0.6  44.5 +/- 0.7   72.4 +/- 1.2\n",
       "oracle              91.1 ± 0.1    59.1 ± 1.5    50.0 ± 9.9     80.8 ± 0.7\n",
       "entropy             85.1 ± 1.0    40.3 ± 0.9    36.0 ± 7.8     69.8 ± 1.1\n",
       "perplexity          86.0 ± 0.5    42.0 ± 0.9    38.8 ± 8.6     71.4 ± 0.8\n",
       "sequence_prob       85.9 ± 0.2    40.7 ± 1.1    39.7 ± 7.8     71.0 ± 0.4\n",
       "pd_gap              85.9 ± 1.0    41.8 ± 0.4    37.9 ± 9.4     71.6 ± 1.3\n",
       "prm                 87.6 ± 0.7    45.2 ± 1.7    40.3 ± 9.1     74.2 ± 0.8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qwen3-8B (window=all, aggregation=mean)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>AIME 2024</th>\n",
       "      <th>AIME 2025</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scorer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>75.6 +/- 2.7</td>\n",
       "      <td>64.4 +/- 6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-consistency</th>\n",
       "      <td>82.2 +/- 1.9</td>\n",
       "      <td>34.4 +/- 6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oracle</th>\n",
       "      <td>85.6 ± 1.9</td>\n",
       "      <td>80.0 ± 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>66.7 ± 3.3</td>\n",
       "      <td>58.9 ± 7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity</th>\n",
       "      <td>64.4 ± 5.1</td>\n",
       "      <td>60.0 ± 3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob</th>\n",
       "      <td>68.9 ± 9.6</td>\n",
       "      <td>64.4 ± 10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd_gap</th>\n",
       "      <td>65.6 ± 5.1</td>\n",
       "      <td>58.9 ± 5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prm</th>\n",
       "      <td>78.9 ± 1.9</td>\n",
       "      <td>67.8 ± 5.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset              AIME 2024     AIME 2025\n",
       "scorer                                      \n",
       "baseline          75.6 +/- 2.7  64.4 +/- 6.2\n",
       "self-consistency  82.2 +/- 1.9  34.4 +/- 6.9\n",
       "oracle              85.6 ± 1.9    80.0 ± 0.0\n",
       "entropy             66.7 ± 3.3    58.9 ± 7.7\n",
       "perplexity          64.4 ± 5.1    60.0 ± 3.3\n",
       "sequence_prob       68.9 ± 9.6   64.4 ± 10.7\n",
       "pd_gap              65.6 ± 5.1    58.9 ± 5.1\n",
       "prm                 78.9 ± 1.9    67.8 ± 5.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ── Aggregate offline BoN results across seeds ────────────────────────────────\n",
    "\n",
    "bon_agg_df = (\n",
    "    bon_analysis_df\n",
    "    .groupby([\"dataset\", \"scorer\", \"aggregation\", \"window\"])\n",
    "    .agg(\n",
    "        accuracy_mean=(\"accuracy\", \"mean\"),\n",
    "        accuracy_std=(\"accuracy\", \"std\"),\n",
    "        accuracy_count=(\"accuracy\", \"count\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "bon_agg_df[\"accuracy_fmt\"] = bon_agg_df.apply(\n",
    "    lambda r: (\n",
    "        f\"{r['accuracy_mean']:.1f} ± {r['accuracy_std']:.1f}\"\n",
    "        if pd.notna(r[\"accuracy_std\"]) and r[\"accuracy_count\"] > 1\n",
    "        else f\"{r['accuracy_mean']:.1f}\"\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "print(f\"Aggregated: {len(bon_agg_df)} rows\")\n",
    "print(f\"Datasets:   {sorted(bon_agg_df['dataset'].unique())}\")\n",
    "print(f\"Scorers:    {sorted(bon_agg_df['scorer'].unique())}\")\n",
    "print(f\"Windows:    {sorted(bon_agg_df['window'].unique(), key=lambda w: (0, int(w)) if w != 'all' else (1, 0))}\")\n",
    "\n",
    "# Quick sanity check: show window=all, aggregation=mean — with baseline for reference\n",
    "_bon_check = (\n",
    "    bon_agg_df[\n",
    "        (bon_agg_df[\"window\"] == \"all\") & (bon_agg_df[\"aggregation\"].isin([\"mean\", \"—\"]))\n",
    "    ][[\"dataset\", \"scorer\", \"accuracy_fmt\"]]\n",
    "    .pivot(index=\"scorer\", columns=\"dataset\", values=\"accuracy_fmt\")\n",
    ")\n",
    "\n",
    "# Add baseline and self-consistency rows from wandb summary for comparison\n",
    "_baseline = agg_df[agg_df[\"strategy\"] == \"baseline\"].copy()\n",
    "if not _baseline.empty:\n",
    "    _bl_row = {}\n",
    "    for ds in _bon_check.columns:\n",
    "        _bl = _baseline[_baseline[\"project_label\"] == ds]\n",
    "        if not _bl.empty:\n",
    "            _bl_row[ds] = _bl.iloc[0].get(\"exact_match_fmt\", \"\")\n",
    "    _bon_check.loc[\"baseline\"] = _bl_row\n",
    "\n",
    "_self_cons = agg_df[agg_df[\"strategy\"] == \"self_consistency\"].copy()\n",
    "if not _self_cons.empty:\n",
    "    _sc_row = {}\n",
    "    for ds in _bon_check.columns:\n",
    "        _sc = _self_cons[_self_cons[\"project_label\"] == ds]\n",
    "        if not _sc.empty:\n",
    "            _sc_row[ds] = _sc.iloc[0].get(\"exact_match_fmt\", \"\")\n",
    "    _bon_check.loc[\"self-consistency\"] = _sc_row\n",
    "\n",
    "# Reorder rows: baseline, oracle, then scorers in specified order\n",
    "_row_order = [\"baseline\", \"self-consistency\", \"oracle\", \"entropy\", \"perplexity\", \"sequence_prob\", \"pd_gap\", \"prm\"]\n",
    "_ordered = [r for r in _row_order if r in _bon_check.index]\n",
    "_remaining = [r for r in _bon_check.index if r not in _row_order]\n",
    "_bon_check = _bon_check.reindex(_ordered + _remaining)\n",
    "\n",
    "# Display per model group\n",
    "_SANITY_GROUPS = {\n",
    "    \"Qwen2.5-Math-7B-Instruct\": [\"MATH-500\", \"OlympiadBench\", \"Minerva Math\", \"Gaokao 2023 EN\"],\n",
    "    \"Qwen3-8B\": [\"AIME 2024\", \"AIME 2025\"],\n",
    "}\n",
    "for _name, _datasets in _SANITY_GROUPS.items():\n",
    "    _cols = [c for c in _datasets if c in _bon_check.columns]\n",
    "    if _cols:\n",
    "        print(f\"\\n{_name} (window=all, aggregation=mean)\")\n",
    "        display(_bon_check[_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Qwen2.5-Math-7B-Instruct\n",
      "======================================================================\n",
      "  Candidate windows available: ['1', '2', '3', '5', '10', '15', 'all']\n",
      "  entropy           mean:w=5(58.2%), min:w=3(57.3%), max:w=3(58.0%), product:w=5(58.6%)\n",
      "  pd_gap            mean:w=5(59.4%), min:w=3(58.6%), max:w=3(59.4%), product:w=3(59.3%)\n",
      "  perplexity        mean:w=5(59.9%), min:w=1(58.8%), max:w=3(59.9%), product:w=5(59.3%)\n",
      "  prm               mean:w=10(61.9%), min:w=15(61.9%), max:w=3(61.1%), product:w=all(61.9%)\n",
      "  sequence_prob     mean:w=15(59.4%), min:w=3(58.6%), max:w=3(59.2%), product:w=3(58.9%)\n",
      "\n",
      "======================================================================\n",
      "Qwen3-8B\n",
      "======================================================================\n",
      "  Candidate windows available: ['1', '2', '3', '5', '10', '15', '20', '25', '50', 'all']\n",
      "  entropy           mean:w=20(65.6%), min:w=20(67.8%), max:w=all(70.0%), product:w=10(66.7%)\n",
      "  pd_gap            mean:w=20(65.6%), min:w=20(67.8%), max:w=all(69.4%), product:w=10(66.7%)\n",
      "  perplexity        mean:w=1(66.7%), min:w=10(68.9%), max:w=all(71.1%), product:w=1(66.7%)\n",
      "  prm               mean:w=2(75.6%), min:w=2(76.7%), max:w=1(72.2%), product:w=2(75.6%)\n",
      "  sequence_prob     mean:w=1(72.8%), min:w=3(72.8%), max:w=1(72.8%), product:w=1(72.8%)\n",
      "\n",
      "======================================================================\n",
      "Summary: best_windows[(model, scorer, aggregation)]\n",
      "======================================================================\n",
      "  Qwen2.5-Math-7B-Instruct / entropy / max: window=3, acc=58.0%\n",
      "  Qwen2.5-Math-7B-Instruct / entropy / mean: window=5, acc=58.2%\n",
      "  Qwen2.5-Math-7B-Instruct / entropy / min: window=3, acc=57.3%\n",
      "  Qwen2.5-Math-7B-Instruct / entropy / product: window=5, acc=58.6%\n",
      "  Qwen2.5-Math-7B-Instruct / pd_gap / max: window=3, acc=59.4%\n",
      "  Qwen2.5-Math-7B-Instruct / pd_gap / mean: window=5, acc=59.4%\n",
      "  Qwen2.5-Math-7B-Instruct / pd_gap / min: window=3, acc=58.6%\n",
      "  Qwen2.5-Math-7B-Instruct / pd_gap / product: window=3, acc=59.3%\n",
      "  Qwen2.5-Math-7B-Instruct / perplexity / max: window=3, acc=59.9%\n",
      "  Qwen2.5-Math-7B-Instruct / perplexity / mean: window=5, acc=59.9%\n",
      "  Qwen2.5-Math-7B-Instruct / perplexity / min: window=1, acc=58.8%\n",
      "  Qwen2.5-Math-7B-Instruct / perplexity / product: window=5, acc=59.3%\n",
      "  Qwen2.5-Math-7B-Instruct / prm / max: window=3, acc=61.1%\n",
      "  Qwen2.5-Math-7B-Instruct / prm / mean: window=10, acc=61.9%\n",
      "  Qwen2.5-Math-7B-Instruct / prm / min: window=15, acc=61.9%\n",
      "  Qwen2.5-Math-7B-Instruct / prm / product: window=all, acc=61.9%\n",
      "  Qwen2.5-Math-7B-Instruct / sequence_prob / max: window=3, acc=59.2%\n",
      "  Qwen2.5-Math-7B-Instruct / sequence_prob / mean: window=15, acc=59.4%\n",
      "  Qwen2.5-Math-7B-Instruct / sequence_prob / min: window=3, acc=58.6%\n",
      "  Qwen2.5-Math-7B-Instruct / sequence_prob / product: window=3, acc=58.9%\n",
      "  Qwen3-8B / entropy / max: window=all, acc=70.0%\n",
      "  Qwen3-8B / entropy / mean: window=20, acc=65.6%\n",
      "  Qwen3-8B / entropy / min: window=20, acc=67.8%\n",
      "  Qwen3-8B / entropy / product: window=10, acc=66.7%\n",
      "  Qwen3-8B / pd_gap / max: window=all, acc=69.4%\n",
      "  Qwen3-8B / pd_gap / mean: window=20, acc=65.6%\n",
      "  Qwen3-8B / pd_gap / min: window=20, acc=67.8%\n",
      "  Qwen3-8B / pd_gap / product: window=10, acc=66.7%\n",
      "  Qwen3-8B / perplexity / max: window=all, acc=71.1%\n",
      "  Qwen3-8B / perplexity / mean: window=1, acc=66.7%\n",
      "  Qwen3-8B / perplexity / min: window=10, acc=68.9%\n",
      "  Qwen3-8B / perplexity / product: window=1, acc=66.7%\n",
      "  Qwen3-8B / prm / max: window=1, acc=72.2%\n",
      "  Qwen3-8B / prm / mean: window=2, acc=75.6%\n",
      "  Qwen3-8B / prm / min: window=2, acc=76.7%\n",
      "  Qwen3-8B / prm / product: window=2, acc=75.6%\n",
      "  Qwen3-8B / sequence_prob / max: window=1, acc=72.8%\n",
      "  Qwen3-8B / sequence_prob / mean: window=1, acc=72.8%\n",
      "  Qwen3-8B / sequence_prob / min: window=3, acc=72.8%\n",
      "  Qwen3-8B / sequence_prob / product: window=1, acc=72.8%\n",
      "\n",
      "Qwen2.5-Math-7B-Instruct — aggregation=mean, best window per scorer\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>MATH-500</th>\n",
       "      <th>OlympiadBench</th>\n",
       "      <th>Minerva Math</th>\n",
       "      <th>Gaokao 2023 EN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scorer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>83.2 +/- 0.0</td>\n",
       "      <td>39.3 +/- 0.0</td>\n",
       "      <td>42.3 +/- 0.0</td>\n",
       "      <td>68.6 +/- 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-consistency</th>\n",
       "      <td>86.4 +/- 0.5</td>\n",
       "      <td>44.7 +/- 0.6</td>\n",
       "      <td>44.5 +/- 0.7</td>\n",
       "      <td>72.4 +/- 1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oracle</th>\n",
       "      <td>91.1 ± 0.1</td>\n",
       "      <td>59.1 ± 1.5</td>\n",
       "      <td>50.0 ± 9.9</td>\n",
       "      <td>80.8 ± 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy (w=5)</th>\n",
       "      <td>85.1 ± 1.1</td>\n",
       "      <td>40.9 ± 0.9</td>\n",
       "      <td>36.2 ± 7.5</td>\n",
       "      <td>70.7 ± 1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity (w=5)</th>\n",
       "      <td>86.0 ± 0.5</td>\n",
       "      <td>42.4 ± 0.2</td>\n",
       "      <td>38.6 ± 8.3</td>\n",
       "      <td>72.7 ± 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob (w=15)</th>\n",
       "      <td>86.0 ± 0.3</td>\n",
       "      <td>40.7 ± 1.1</td>\n",
       "      <td>39.7 ± 7.8</td>\n",
       "      <td>71.0 ± 0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd_gap (w=5)</th>\n",
       "      <td>85.9 ± 0.6</td>\n",
       "      <td>41.9 ± 0.5</td>\n",
       "      <td>37.3 ± 9.6</td>\n",
       "      <td>72.4 ± 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prm (w=10)</th>\n",
       "      <td>87.6 ± 0.7</td>\n",
       "      <td>45.3 ± 1.8</td>\n",
       "      <td>40.4 ± 9.4</td>\n",
       "      <td>74.1 ± 0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset                   MATH-500 OlympiadBench  Minerva Math Gaokao 2023 EN\n",
       "Scorer                                                                       \n",
       "baseline              83.2 +/- 0.0  39.3 +/- 0.0  42.3 +/- 0.0   68.6 +/- 0.0\n",
       "self-consistency      86.4 +/- 0.5  44.7 +/- 0.6  44.5 +/- 0.7   72.4 +/- 1.2\n",
       "oracle                  91.1 ± 0.1    59.1 ± 1.5    50.0 ± 9.9     80.8 ± 0.7\n",
       "entropy (w=5)           85.1 ± 1.1    40.9 ± 0.9    36.2 ± 7.5     70.7 ± 1.1\n",
       "perplexity (w=5)        86.0 ± 0.5    42.4 ± 0.2    38.6 ± 8.3     72.7 ± 0.7\n",
       "sequence_prob (w=15)    86.0 ± 0.3    40.7 ± 1.1    39.7 ± 7.8     71.0 ± 0.4\n",
       "pd_gap (w=5)            85.9 ± 0.6    41.9 ± 0.5    37.3 ± 9.6     72.4 ± 0.5\n",
       "prm (w=10)              87.6 ± 0.7    45.3 ± 1.8    40.4 ± 9.4     74.1 ± 0.9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qwen2.5-Math-7B-Instruct — aggregation=min, best window per scorer\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>MATH-500</th>\n",
       "      <th>OlympiadBench</th>\n",
       "      <th>Minerva Math</th>\n",
       "      <th>Gaokao 2023 EN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scorer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>83.2 +/- 0.0</td>\n",
       "      <td>39.3 +/- 0.0</td>\n",
       "      <td>42.3 +/- 0.0</td>\n",
       "      <td>68.6 +/- 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-consistency</th>\n",
       "      <td>86.4 +/- 0.5</td>\n",
       "      <td>44.7 +/- 0.6</td>\n",
       "      <td>44.5 +/- 0.7</td>\n",
       "      <td>72.4 +/- 1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oracle</th>\n",
       "      <td>91.1 ± 0.1</td>\n",
       "      <td>59.1 ± 1.5</td>\n",
       "      <td>50.0 ± 9.9</td>\n",
       "      <td>80.8 ± 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy (w=3)</th>\n",
       "      <td>84.7 ± 0.8</td>\n",
       "      <td>39.4 ± 0.7</td>\n",
       "      <td>35.5 ± 6.5</td>\n",
       "      <td>69.5 ± 1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity (w=1)</th>\n",
       "      <td>85.3 ± 0.7</td>\n",
       "      <td>41.6 ± 0.2</td>\n",
       "      <td>37.7 ± 6.0</td>\n",
       "      <td>70.6 ± 0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob (w=3)</th>\n",
       "      <td>85.4 ± 0.9</td>\n",
       "      <td>40.5 ± 0.2</td>\n",
       "      <td>37.5 ± 3.6</td>\n",
       "      <td>70.9 ± 0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd_gap (w=3)</th>\n",
       "      <td>85.4 ± 0.7</td>\n",
       "      <td>40.6 ± 1.0</td>\n",
       "      <td>37.3 ± 6.5</td>\n",
       "      <td>70.9 ± 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prm (w=15)</th>\n",
       "      <td>87.5 ± 0.4</td>\n",
       "      <td>45.7 ± 1.4</td>\n",
       "      <td>40.3 ± 9.6</td>\n",
       "      <td>74.0 ± 0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset                  MATH-500 OlympiadBench  Minerva Math Gaokao 2023 EN\n",
       "Scorer                                                                      \n",
       "baseline             83.2 +/- 0.0  39.3 +/- 0.0  42.3 +/- 0.0   68.6 +/- 0.0\n",
       "self-consistency     86.4 +/- 0.5  44.7 +/- 0.6  44.5 +/- 0.7   72.4 +/- 1.2\n",
       "oracle                 91.1 ± 0.1    59.1 ± 1.5    50.0 ± 9.9     80.8 ± 0.7\n",
       "entropy (w=3)          84.7 ± 0.8    39.4 ± 0.7    35.5 ± 6.5     69.5 ± 1.7\n",
       "perplexity (w=1)       85.3 ± 0.7    41.6 ± 0.2    37.7 ± 6.0     70.6 ± 0.3\n",
       "sequence_prob (w=3)    85.4 ± 0.9    40.5 ± 0.2    37.5 ± 3.6     70.9 ± 0.8\n",
       "pd_gap (w=3)           85.4 ± 0.7    40.6 ± 1.0    37.3 ± 6.5     70.9 ± 1.0\n",
       "prm (w=15)             87.5 ± 0.4    45.7 ± 1.4    40.3 ± 9.6     74.0 ± 0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qwen2.5-Math-7B-Instruct — aggregation=max, best window per scorer\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>MATH-500</th>\n",
       "      <th>OlympiadBench</th>\n",
       "      <th>Minerva Math</th>\n",
       "      <th>Gaokao 2023 EN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scorer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>83.2 +/- 0.0</td>\n",
       "      <td>39.3 +/- 0.0</td>\n",
       "      <td>42.3 +/- 0.0</td>\n",
       "      <td>68.6 +/- 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-consistency</th>\n",
       "      <td>86.4 +/- 0.5</td>\n",
       "      <td>44.7 +/- 0.6</td>\n",
       "      <td>44.5 +/- 0.7</td>\n",
       "      <td>72.4 +/- 1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oracle</th>\n",
       "      <td>91.1 ± 0.1</td>\n",
       "      <td>59.1 ± 1.5</td>\n",
       "      <td>50.0 ± 9.9</td>\n",
       "      <td>80.8 ± 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy (w=3)</th>\n",
       "      <td>84.9 ± 1.0</td>\n",
       "      <td>40.7 ± 0.8</td>\n",
       "      <td>37.3 ± 8.1</td>\n",
       "      <td>69.0 ± 0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity (w=3)</th>\n",
       "      <td>86.7 ± 0.6</td>\n",
       "      <td>42.6 ± 0.5</td>\n",
       "      <td>39.0 ± 7.8</td>\n",
       "      <td>71.3 ± 0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob (w=3)</th>\n",
       "      <td>85.6 ± 0.0</td>\n",
       "      <td>41.0 ± 0.9</td>\n",
       "      <td>39.3 ± 6.8</td>\n",
       "      <td>70.7 ± 0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd_gap (w=3)</th>\n",
       "      <td>86.1 ± 1.5</td>\n",
       "      <td>42.5 ± 0.8</td>\n",
       "      <td>38.4 ± 7.0</td>\n",
       "      <td>70.7 ± 1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prm (w=3)</th>\n",
       "      <td>86.5 ± 0.6</td>\n",
       "      <td>45.1 ± 1.1</td>\n",
       "      <td>39.3 ± 7.3</td>\n",
       "      <td>73.2 ± 0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset                  MATH-500 OlympiadBench  Minerva Math Gaokao 2023 EN\n",
       "Scorer                                                                      \n",
       "baseline             83.2 +/- 0.0  39.3 +/- 0.0  42.3 +/- 0.0   68.6 +/- 0.0\n",
       "self-consistency     86.4 +/- 0.5  44.7 +/- 0.6  44.5 +/- 0.7   72.4 +/- 1.2\n",
       "oracle                 91.1 ± 0.1    59.1 ± 1.5    50.0 ± 9.9     80.8 ± 0.7\n",
       "entropy (w=3)          84.9 ± 1.0    40.7 ± 0.8    37.3 ± 8.1     69.0 ± 0.8\n",
       "perplexity (w=3)       86.7 ± 0.6    42.6 ± 0.5    39.0 ± 7.8     71.3 ± 0.8\n",
       "sequence_prob (w=3)    85.6 ± 0.0    41.0 ± 0.9    39.3 ± 6.8     70.7 ± 0.4\n",
       "pd_gap (w=3)           86.1 ± 1.5    42.5 ± 0.8    38.4 ± 7.0     70.7 ± 1.1\n",
       "prm (w=3)              86.5 ± 0.6    45.1 ± 1.1    39.3 ± 7.3     73.2 ± 0.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qwen2.5-Math-7B-Instruct — aggregation=product, best window per scorer\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>MATH-500</th>\n",
       "      <th>OlympiadBench</th>\n",
       "      <th>Minerva Math</th>\n",
       "      <th>Gaokao 2023 EN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scorer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>83.2 +/- 0.0</td>\n",
       "      <td>39.3 +/- 0.0</td>\n",
       "      <td>42.3 +/- 0.0</td>\n",
       "      <td>68.6 +/- 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-consistency</th>\n",
       "      <td>86.4 +/- 0.5</td>\n",
       "      <td>44.7 +/- 0.6</td>\n",
       "      <td>44.5 +/- 0.7</td>\n",
       "      <td>72.4 +/- 1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oracle</th>\n",
       "      <td>91.1 ± 0.1</td>\n",
       "      <td>59.1 ± 1.5</td>\n",
       "      <td>50.0 ± 9.9</td>\n",
       "      <td>80.8 ± 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy (w=5)</th>\n",
       "      <td>84.5 ± 0.4</td>\n",
       "      <td>40.6 ± 1.3</td>\n",
       "      <td>37.7 ± 7.5</td>\n",
       "      <td>71.6 ± 2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity (w=5)</th>\n",
       "      <td>85.3 ± 0.5</td>\n",
       "      <td>41.8 ± 0.8</td>\n",
       "      <td>38.0 ± 7.0</td>\n",
       "      <td>72.1 ± 2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob (w=3)</th>\n",
       "      <td>85.6 ± 0.6</td>\n",
       "      <td>41.3 ± 0.3</td>\n",
       "      <td>38.0 ± 8.1</td>\n",
       "      <td>70.7 ± 1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd_gap (w=3)</th>\n",
       "      <td>85.5 ± 0.7</td>\n",
       "      <td>42.3 ± 0.3</td>\n",
       "      <td>38.2 ± 7.8</td>\n",
       "      <td>71.3 ± 0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prm (w=all)</th>\n",
       "      <td>87.4 ± 0.3</td>\n",
       "      <td>45.7 ± 1.0</td>\n",
       "      <td>40.3 ± 10.1</td>\n",
       "      <td>74.4 ± 0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset                  MATH-500 OlympiadBench  Minerva Math Gaokao 2023 EN\n",
       "Scorer                                                                      \n",
       "baseline             83.2 +/- 0.0  39.3 +/- 0.0  42.3 +/- 0.0   68.6 +/- 0.0\n",
       "self-consistency     86.4 +/- 0.5  44.7 +/- 0.6  44.5 +/- 0.7   72.4 +/- 1.2\n",
       "oracle                 91.1 ± 0.1    59.1 ± 1.5    50.0 ± 9.9     80.8 ± 0.7\n",
       "entropy (w=5)          84.5 ± 0.4    40.6 ± 1.3    37.7 ± 7.5     71.6 ± 2.1\n",
       "perplexity (w=5)       85.3 ± 0.5    41.8 ± 0.8    38.0 ± 7.0     72.1 ± 2.0\n",
       "sequence_prob (w=3)    85.6 ± 0.6    41.3 ± 0.3    38.0 ± 8.1     70.7 ± 1.1\n",
       "pd_gap (w=3)           85.5 ± 0.7    42.3 ± 0.3    38.2 ± 7.8     71.3 ± 0.9\n",
       "prm (w=all)            87.4 ± 0.3    45.7 ± 1.0   40.3 ± 10.1     74.4 ± 0.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qwen3-8B — aggregation=mean, best window per scorer\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>AIME 2024</th>\n",
       "      <th>AIME 2025</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scorer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>75.6 +/- 2.7</td>\n",
       "      <td>64.4 +/- 6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-consistency</th>\n",
       "      <td>82.2 +/- 1.9</td>\n",
       "      <td>34.4 +/- 6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oracle</th>\n",
       "      <td>85.6 ± 1.9</td>\n",
       "      <td>80.0 ± 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy (w=20)</th>\n",
       "      <td>71.1 ± 5.1</td>\n",
       "      <td>60.0 ± 10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity (w=1)</th>\n",
       "      <td>72.2 ± 1.9</td>\n",
       "      <td>61.1 ± 9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob (w=1)</th>\n",
       "      <td>76.7 ± 3.3</td>\n",
       "      <td>68.9 ± 5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd_gap (w=20)</th>\n",
       "      <td>71.1 ± 5.1</td>\n",
       "      <td>60.0 ± 6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prm (w=2)</th>\n",
       "      <td>82.2 ± 5.1</td>\n",
       "      <td>68.9 ± 1.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset                 AIME 2024     AIME 2025\n",
       "Scorer                                         \n",
       "baseline             75.6 +/- 2.7  64.4 +/- 6.2\n",
       "self-consistency     82.2 +/- 1.9  34.4 +/- 6.9\n",
       "oracle                 85.6 ± 1.9    80.0 ± 0.0\n",
       "entropy (w=20)         71.1 ± 5.1   60.0 ± 10.0\n",
       "perplexity (w=1)       72.2 ± 1.9    61.1 ± 9.6\n",
       "sequence_prob (w=1)    76.7 ± 3.3    68.9 ± 5.1\n",
       "pd_gap (w=20)          71.1 ± 5.1    60.0 ± 6.7\n",
       "prm (w=2)              82.2 ± 5.1    68.9 ± 1.9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qwen3-8B — aggregation=min, best window per scorer\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>AIME 2024</th>\n",
       "      <th>AIME 2025</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scorer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>75.6 +/- 2.7</td>\n",
       "      <td>64.4 +/- 6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-consistency</th>\n",
       "      <td>82.2 +/- 1.9</td>\n",
       "      <td>34.4 +/- 6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oracle</th>\n",
       "      <td>85.6 ± 1.9</td>\n",
       "      <td>80.0 ± 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy (w=20)</th>\n",
       "      <td>70.0 ± 3.3</td>\n",
       "      <td>65.6 ± 5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity (w=10)</th>\n",
       "      <td>73.3 ± 5.8</td>\n",
       "      <td>64.4 ± 6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob (w=3)</th>\n",
       "      <td>76.7 ± 3.3</td>\n",
       "      <td>68.9 ± 3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd_gap (w=20)</th>\n",
       "      <td>71.1 ± 1.9</td>\n",
       "      <td>64.4 ± 6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prm (w=2)</th>\n",
       "      <td>82.2 ± 5.1</td>\n",
       "      <td>71.1 ± 3.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset                 AIME 2024     AIME 2025\n",
       "Scorer                                         \n",
       "baseline             75.6 +/- 2.7  64.4 +/- 6.2\n",
       "self-consistency     82.2 +/- 1.9  34.4 +/- 6.9\n",
       "oracle                 85.6 ± 1.9    80.0 ± 0.0\n",
       "entropy (w=20)         70.0 ± 3.3    65.6 ± 5.1\n",
       "perplexity (w=10)      73.3 ± 5.8    64.4 ± 6.9\n",
       "sequence_prob (w=3)    76.7 ± 3.3    68.9 ± 3.8\n",
       "pd_gap (w=20)          71.1 ± 1.9    64.4 ± 6.9\n",
       "prm (w=2)              82.2 ± 5.1    71.1 ± 3.8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qwen3-8B — aggregation=max, best window per scorer\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>AIME 2024</th>\n",
       "      <th>AIME 2025</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scorer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>75.6 +/- 2.7</td>\n",
       "      <td>64.4 +/- 6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-consistency</th>\n",
       "      <td>82.2 +/- 1.9</td>\n",
       "      <td>34.4 +/- 6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oracle</th>\n",
       "      <td>85.6 ± 1.9</td>\n",
       "      <td>80.0 ± 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy (w=all)</th>\n",
       "      <td>75.6 ± 5.1</td>\n",
       "      <td>64.4 ± 5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity (w=all)</th>\n",
       "      <td>75.6 ± 1.9</td>\n",
       "      <td>66.7 ± 3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob (w=1)</th>\n",
       "      <td>76.7 ± 3.3</td>\n",
       "      <td>68.9 ± 5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd_gap (w=all)</th>\n",
       "      <td>73.3 ± 5.8</td>\n",
       "      <td>65.6 ± 5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prm (w=1)</th>\n",
       "      <td>76.7 ± 5.8</td>\n",
       "      <td>67.8 ± 9.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset                 AIME 2024     AIME 2025\n",
       "Scorer                                         \n",
       "baseline             75.6 +/- 2.7  64.4 +/- 6.2\n",
       "self-consistency     82.2 +/- 1.9  34.4 +/- 6.9\n",
       "oracle                 85.6 ± 1.9    80.0 ± 0.0\n",
       "entropy (w=all)        75.6 ± 5.1    64.4 ± 5.1\n",
       "perplexity (w=all)     75.6 ± 1.9    66.7 ± 3.3\n",
       "sequence_prob (w=1)    76.7 ± 3.3    68.9 ± 5.1\n",
       "pd_gap (w=all)         73.3 ± 5.8    65.6 ± 5.1\n",
       "prm (w=1)              76.7 ± 5.8    67.8 ± 9.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qwen3-8B — aggregation=product, best window per scorer\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>AIME 2024</th>\n",
       "      <th>AIME 2025</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scorer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>75.6 +/- 2.7</td>\n",
       "      <td>64.4 +/- 6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-consistency</th>\n",
       "      <td>82.2 +/- 1.9</td>\n",
       "      <td>34.4 +/- 6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oracle</th>\n",
       "      <td>85.6 ± 1.9</td>\n",
       "      <td>80.0 ± 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy (w=10)</th>\n",
       "      <td>68.9 ± 1.9</td>\n",
       "      <td>64.4 ± 5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity (w=1)</th>\n",
       "      <td>72.2 ± 1.9</td>\n",
       "      <td>61.1 ± 9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob (w=1)</th>\n",
       "      <td>76.7 ± 3.3</td>\n",
       "      <td>68.9 ± 5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd_gap (w=10)</th>\n",
       "      <td>68.9 ± 1.9</td>\n",
       "      <td>64.4 ± 5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prm (w=2)</th>\n",
       "      <td>82.2 ± 5.1</td>\n",
       "      <td>68.9 ± 1.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset                 AIME 2024     AIME 2025\n",
       "Scorer                                         \n",
       "baseline             75.6 +/- 2.7  64.4 +/- 6.2\n",
       "self-consistency     82.2 +/- 1.9  34.4 +/- 6.9\n",
       "oracle                 85.6 ± 1.9    80.0 ± 0.0\n",
       "entropy (w=10)         68.9 ± 1.9    64.4 ± 5.1\n",
       "perplexity (w=1)       72.2 ± 1.9    61.1 ± 9.6\n",
       "sequence_prob (w=1)    76.7 ± 3.3    68.9 ± 5.1\n",
       "pd_gap (w=10)          68.9 ± 1.9    64.4 ± 5.1\n",
       "prm (w=2)              82.2 ± 5.1    68.9 ± 1.9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ── Best scoring window per (scorer, aggregation) — averaged across datasets & seeds ──\n",
    "# For each model group, find the window that maximizes accuracy per (scorer, aggregation).\n",
    "\n",
    "MODEL_GROUPS = {\n",
    "    \"Qwen2.5-Math-7B-Instruct\": [\"MATH-500\", \"OlympiadBench\", \"Minerva Math\", \"Gaokao 2023 EN\"],\n",
    "    \"Qwen3-8B\": [\"AIME 2024\", \"AIME 2025\"],\n",
    "}\n",
    "\n",
    "AGGREGATIONS = [\"mean\", \"min\", \"max\", \"product\"]\n",
    "CANDIDATE_WINDOWS = [\"all\", \"1\", \"2\", \"3\", \"5\", \"10\", \"15\", \"20\", \"25\", \"50\"]\n",
    "\n",
    "best_windows = {}  # (model_group, scorer, aggregation) -> {window, accuracy}\n",
    "\n",
    "for model_name, datasets in MODEL_GROUPS.items():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{model_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    # Filter bon_agg_df to this model's datasets, exclude oracle\n",
    "    mask = (\n",
    "        bon_agg_df[\"dataset\"].isin(datasets)\n",
    "        & (bon_agg_df[\"scorer\"] != \"oracle\")\n",
    "    )\n",
    "    sub = bon_agg_df[mask].copy()\n",
    "\n",
    "    if sub.empty:\n",
    "        print(\"  No data\")\n",
    "        continue\n",
    "\n",
    "    # Only consider windows that exist for ALL datasets in the group\n",
    "    _window_sets = []\n",
    "    for ds in datasets:\n",
    "        ds_windows = set(sub[sub[\"dataset\"] == ds][\"window\"].unique())\n",
    "        if ds_windows:\n",
    "            _window_sets.append(ds_windows)\n",
    "    common_windows = set.intersection(*_window_sets) if _window_sets else set()\n",
    "    # Restrict to candidate windows only\n",
    "    common_windows = common_windows & set(CANDIDATE_WINDOWS)\n",
    "    sub = sub[sub[\"window\"].isin(common_windows)].copy()\n",
    "    print(f\"  Candidate windows available: {sorted(common_windows, key=lambda w: (0, int(w)) if w != 'all' else (1, 0))}\")\n",
    "\n",
    "    # For each (scorer, aggregation, window): average accuracy_mean across datasets\n",
    "    window_perf = (\n",
    "        sub.groupby([\"scorer\", \"aggregation\", \"window\"])[\"accuracy_mean\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"accuracy_mean\": \"avg_accuracy\"})\n",
    "    )\n",
    "\n",
    "    # For each (scorer, aggregation): find the best window\n",
    "    for scorer in sorted(sub[\"scorer\"].unique()):\n",
    "        for agg in AGGREGATIONS:\n",
    "            sa_df = window_perf[\n",
    "                (window_perf[\"scorer\"] == scorer) & (window_perf[\"aggregation\"] == agg)\n",
    "            ]\n",
    "            if sa_df.empty:\n",
    "                continue\n",
    "            best = sa_df.loc[sa_df[\"avg_accuracy\"].idxmax()]\n",
    "            best_windows[(model_name, scorer, agg)] = {\n",
    "                \"window\": best[\"window\"],\n",
    "                \"accuracy\": best[\"avg_accuracy\"],\n",
    "            }\n",
    "\n",
    "    # Print summary per scorer\n",
    "    for scorer in sorted(sub[\"scorer\"].unique()):\n",
    "        parts = []\n",
    "        for agg in AGGREGATIONS:\n",
    "            bw = best_windows.get((model_name, scorer, agg))\n",
    "            if bw:\n",
    "                parts.append(f\"{agg}:w={bw['window']}({bw['accuracy']:.1f}%)\")\n",
    "        print(f\"  {scorer:<16s}  {', '.join(parts)}\")\n",
    "\n",
    "# ── Summary ──────────────────────────────────────────────────────────────────\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Summary: best_windows[(model, scorer, aggregation)]\")\n",
    "print(f\"{'='*70}\")\n",
    "for (mg, sc, agg), info in sorted(best_windows.items()):\n",
    "    print(f\"  {mg} / {sc} / {agg}: window={info['window']}, acc={info['accuracy']:.1f}%\")\n",
    "\n",
    "# ── Display tables: one per (model_group, aggregation) ───────────────────────\n",
    "_row_order = [\"baseline\", \"oracle\", \"entropy\", \"perplexity\", \"sequence_prob\", \"pd_gap\", \"prm\"]\n",
    "\n",
    "for model_name, datasets in MODEL_GROUPS.items():\n",
    "    for agg in AGGREGATIONS:\n",
    "        _rows = {}\n",
    "        for scorer in _row_order:\n",
    "            if scorer in (\"baseline\", \"oracle\"):\n",
    "                continue\n",
    "            bw = best_windows.get((model_name, scorer, agg))\n",
    "            if bw is None:\n",
    "                continue\n",
    "            w = bw[\"window\"]\n",
    "            _row = {}\n",
    "            for ds in datasets:\n",
    "                match = bon_agg_df[\n",
    "                    (bon_agg_df[\"dataset\"] == ds)\n",
    "                    & (bon_agg_df[\"scorer\"] == scorer)\n",
    "                    & (bon_agg_df[\"aggregation\"] == agg)\n",
    "                    & (bon_agg_df[\"window\"] == w)\n",
    "                ]\n",
    "                _row[ds] = match.iloc[0][\"accuracy_fmt\"] if not match.empty else \"\"\n",
    "            _rows[f\"{scorer} (w={w})\"] = _row\n",
    "\n",
    "        if not _rows:\n",
    "            continue\n",
    "\n",
    "        # Add baseline, self-consistency, and oracle\n",
    "        _baseline_row = {}\n",
    "        _sc_row = {}\n",
    "        _oracle_row = {}\n",
    "        for ds in datasets:\n",
    "            _bl = agg_df[(agg_df[\"strategy\"] == \"baseline\") & (agg_df[\"project_label\"] == ds)]\n",
    "            _baseline_row[ds] = _bl.iloc[0].get(\"exact_match_fmt\", \"\") if not _bl.empty else \"\"\n",
    "            _sc = agg_df[(agg_df[\"strategy\"] == \"self_consistency\") & (agg_df[\"project_label\"] == ds)]\n",
    "            _sc_row[ds] = _sc.iloc[0].get(\"exact_match_fmt\", \"\") if not _sc.empty else \"\"\n",
    "            _orc = bon_agg_df[\n",
    "                (bon_agg_df[\"dataset\"] == ds)\n",
    "                & (bon_agg_df[\"scorer\"] == \"oracle\")\n",
    "                & (bon_agg_df[\"window\"] == \"all\")\n",
    "            ]\n",
    "            _oracle_row[ds] = _orc.iloc[0][\"accuracy_fmt\"] if not _orc.empty else \"\"\n",
    "\n",
    "        _all_rows = {\"baseline\": _baseline_row, \"self-consistency\": _sc_row, \"oracle\": _oracle_row, **_rows}\n",
    "        _tbl = pd.DataFrame(_all_rows).T\n",
    "        _tbl.columns.name = \"Dataset\"\n",
    "        _tbl.index.name = \"Scorer\"\n",
    "\n",
    "        print(f\"\\n{model_name} — aggregation={agg}, best window per scorer\")\n",
    "        display(_tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-Specific Results Tables\n",
    "\n",
    "Combined tables showing baseline, self-consistency, offline BoN (per-scorer from\n",
    "`candidates.json` analysis), and MUR (from wandb summary) for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_model_results_table() defined\n"
     ]
    }
   ],
   "source": [
    "# ── Model results table builder ───────────────────────────────────────────────\n",
    "\n",
    "SCORER_ORDER = [\"prm\", \"entropy\", \"perplexity\", \"sequence_prob\"]\n",
    "\n",
    "STRATEGY_DISPLAY = {\n",
    "    \"baseline\": \"Baseline\",\n",
    "    \"extended_thinking\": \"Ext. Thinking\",\n",
    "    \"self_consistency\": \"Self-Consistency\",\n",
    "    \"offline_bon\": \"Offline BoN\",\n",
    "    \"adaptive_scaling\": \"MUR\",\n",
    "}\n",
    "\n",
    "STRATEGY_ORDER = [\"baseline\", \"extended_thinking\", \"self_consistency\",\n",
    "                  \"offline_bon\", \"adaptive_scaling\"]\n",
    "\n",
    "\n",
    "def _fmt_metric(val, std=None, count=None):\n",
    "    \"\"\"Format a metric value, optionally with ± std.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return \"\"\n",
    "    if std is not None and pd.notna(std) and count is not None and count > 1:\n",
    "        return f\"{val:.1f} ± {std:.1f}\"\n",
    "    return f\"{val:.1f}\"\n",
    "\n",
    "\n",
    "def _get_wandb_row(model_df, strategy, scorer, dataset):\n",
    "    \"\"\"Extract metric values from the wandb agg_df for one (strategy, scorer, dataset).\"\"\"\n",
    "    mask = model_df[\"strategy\"] == strategy\n",
    "    mask &= model_df[\"project_label\"] == dataset\n",
    "    if scorer is not None:\n",
    "        mask &= model_df[\"scorer\"] == scorer\n",
    "    sub = model_df[mask]\n",
    "    if sub.empty:\n",
    "        return \"\", \"\", \"\"\n",
    "    r = sub.iloc[0]\n",
    "    em = r.get(\"exact_match_fmt\", _fmt_metric(r.get(\"exact_match_mean\")))\n",
    "    llm = _fmt_metric(r.get(\"llm_judge_accuracy_mean\"),\n",
    "                      r.get(\"llm_judge_accuracy_std\"),\n",
    "                      r.get(\"llm_judge_accuracy_count\"))\n",
    "    tf = _fmt_metric(r.get(\"total_tflops_mean\"),\n",
    "                     r.get(\"total_tflops_std\"),\n",
    "                     r.get(\"total_tflops_count\"))\n",
    "    return em, llm, tf\n",
    "\n",
    "\n",
    "def build_model_results_table(\n",
    "    agg_df,\n",
    "    bon_agg_df,\n",
    "    model_filter,\n",
    "    datasets,\n",
    "    bon_window=\"all\",\n",
    "    bon_aggregation=\"mean\",\n",
    "):\n",
    "    \"\"\"Build a MultiIndex DataFrame for one model's results.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    agg_df : pd.DataFrame\n",
    "        Seed-averaged wandb summary data.\n",
    "    bon_agg_df : pd.DataFrame\n",
    "        Seed-averaged offline BoN multi-scorer analysis data.\n",
    "    model_filter : str or list[str]\n",
    "        model short name(s) to include from agg_df.\n",
    "    datasets : list[str]\n",
    "        Ordered list of project_label names to show as columns.\n",
    "    bon_window : str\n",
    "        Scoring window for offline BoN rows (\"all\", \"3\", etc.).\n",
    "    bon_aggregation : str\n",
    "        Aggregation method for offline BoN rows (\"mean\", \"min\", etc.).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame with MultiIndex rows (Strategy, Scorer) and cols (Dataset, Metric).\n",
    "    \"\"\"\n",
    "    if isinstance(model_filter, str):\n",
    "        model_filter = [model_filter]\n",
    "\n",
    "    model_df = agg_df[agg_df[\"model\"].isin(model_filter)].copy()\n",
    "\n",
    "    rows = []\n",
    "    row_index = []\n",
    "    metrics = [\"EM (%)\", \"LLM (%)\", \"TFlops\"]\n",
    "\n",
    "    for strat_key in STRATEGY_ORDER:\n",
    "        strat_label = STRATEGY_DISPLAY[strat_key]\n",
    "\n",
    "        if strat_key == \"offline_bon\":\n",
    "            # Get TFlops from wandb (same for all scorers)\n",
    "            tflops_by_ds = {}\n",
    "            for ds in datasets:\n",
    "                _, _, tf = _get_wandb_row(model_df, strat_key, None, ds)\n",
    "                tflops_by_ds[ds] = tf\n",
    "\n",
    "            for scorer in SCORER_ORDER:\n",
    "                row = {}\n",
    "                for ds in datasets:\n",
    "                    # EM from offline BoN analysis\n",
    "                    mask = (\n",
    "                        (bon_agg_df[\"dataset\"] == ds)\n",
    "                        & (bon_agg_df[\"scorer\"] == scorer)\n",
    "                        & (bon_agg_df[\"aggregation\"] == bon_aggregation)\n",
    "                        & (bon_agg_df[\"window\"] == str(bon_window))\n",
    "                    )\n",
    "                    match = bon_agg_df[mask]\n",
    "                    if not match.empty:\n",
    "                        row[(ds, \"EM (%)\")] = match.iloc[0][\"accuracy_fmt\"]\n",
    "                    else:\n",
    "                        row[(ds, \"EM (%)\")] = \"\"\n",
    "                    row[(ds, \"LLM (%)\")] = \"\"  # not available per-scorer\n",
    "                    row[(ds, \"TFlops\")] = tflops_by_ds.get(ds, \"\")\n",
    "                rows.append(row)\n",
    "                row_index.append((strat_label, scorer))\n",
    "\n",
    "        elif strat_key == \"adaptive_scaling\":\n",
    "            for scorer in SCORER_ORDER:\n",
    "                row = {}\n",
    "                for ds in datasets:\n",
    "                    em, llm, tf = _get_wandb_row(model_df, strat_key, scorer, ds)\n",
    "                    row[(ds, \"EM (%)\")] = em\n",
    "                    row[(ds, \"LLM (%)\")] = llm\n",
    "                    row[(ds, \"TFlops\")] = tf\n",
    "                rows.append(row)\n",
    "                row_index.append((strat_label, scorer))\n",
    "\n",
    "        else:\n",
    "            # Single-row strategies (baseline, ext_thinking, self_consistency)\n",
    "            strat_data = model_df[model_df[\"strategy\"] == strat_key]\n",
    "            if strat_data.empty:\n",
    "                continue  # skip if no data for this strategy\n",
    "            row = {}\n",
    "            for ds in datasets:\n",
    "                em, llm, tf = _get_wandb_row(model_df, strat_key, None, ds)\n",
    "                row[(ds, \"EM (%)\")] = em\n",
    "                row[(ds, \"LLM (%)\")] = llm\n",
    "                row[(ds, \"TFlops\")] = tf\n",
    "            rows.append(row)\n",
    "            row_index.append((strat_label, \"—\"))\n",
    "\n",
    "    if not rows:\n",
    "        print(\"No data found for this model / dataset combination.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    mi_rows = pd.MultiIndex.from_tuples(row_index, names=[\"Strategy\", \"Scorer\"])\n",
    "    mi_cols = pd.MultiIndex.from_tuples(\n",
    "        [(ds, m) for ds in datasets for m in metrics],\n",
    "        names=[\"Dataset\", \"Metric\"],\n",
    "    )\n",
    "\n",
    "    result = pd.DataFrame(rows, index=mi_rows, columns=mi_cols)\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"build_model_results_table() defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Qwen2.5-Math-7B-Instruct — scoring window = all\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th colspan=\"3\" halign=\"left\">MATH-500</th>\n",
       "      <th colspan=\"3\" halign=\"left\">OlympiadBench</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Minerva Math</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Gaokao 2023 EN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>EM (%)</th>\n",
       "      <th>LLM (%)</th>\n",
       "      <th>TFlops</th>\n",
       "      <th>EM (%)</th>\n",
       "      <th>LLM (%)</th>\n",
       "      <th>TFlops</th>\n",
       "      <th>EM (%)</th>\n",
       "      <th>LLM (%)</th>\n",
       "      <th>TFlops</th>\n",
       "      <th>EM (%)</th>\n",
       "      <th>LLM (%)</th>\n",
       "      <th>TFlops</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strategy</th>\n",
       "      <th>Scorer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <th>—</th>\n",
       "      <td>83.2 +/- 0.0</td>\n",
       "      <td>83.9 ± 0.1</td>\n",
       "      <td>5133.2 ± 0.0</td>\n",
       "      <td>39.3 +/- 0.0</td>\n",
       "      <td>43.1 ± 0.1</td>\n",
       "      <td>9683.7 ± 0.0</td>\n",
       "      <td>42.3 +/- 0.0</td>\n",
       "      <td>47.7 ± 0.2</td>\n",
       "      <td>3062.2 ± 0.0</td>\n",
       "      <td>68.6 +/- 0.0</td>\n",
       "      <td>73.2 ± 0.1</td>\n",
       "      <td>4119.7 ± 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self-Consistency</th>\n",
       "      <th>—</th>\n",
       "      <td>86.4 +/- 0.5</td>\n",
       "      <td>86.9 ± 0.5</td>\n",
       "      <td>35680.2 ± 69.6</td>\n",
       "      <td>44.7 +/- 0.6</td>\n",
       "      <td>46.8 ± 0.9</td>\n",
       "      <td>69723.3 ± 464.0</td>\n",
       "      <td>44.5 +/- 0.7</td>\n",
       "      <td>51.1 ± 0.7</td>\n",
       "      <td>20792.9 ± 127.1</td>\n",
       "      <td>72.4 +/- 1.2</td>\n",
       "      <td>75.2 ± 0.9</td>\n",
       "      <td>28817.1 ± 85.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Offline BoN</th>\n",
       "      <th>prm</th>\n",
       "      <td>87.6 ± 0.7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>45.2 ± 1.7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>40.3 ± 9.1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>74.2 ± 0.8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>85.1 ± 1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>40.3 ± 0.9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>36.0 ± 7.8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>69.8 ± 1.1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity</th>\n",
       "      <td>86.0 ± 0.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>42.0 ± 0.9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>38.8 ± 8.6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>71.4 ± 0.8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob</th>\n",
       "      <td>85.9 ± 0.2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>40.7 ± 1.1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>39.7 ± 7.8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>71.0 ± 0.4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">MUR</th>\n",
       "      <th>prm</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset                             MATH-500                             OlympiadBench                               Minerva Math                              Gaokao 2023 EN              \\\n",
       "Metric                                EM (%)     LLM (%)          TFlops        EM (%)     LLM (%)           TFlops        EM (%)     LLM (%)           TFlops         EM (%)     LLM (%)   \n",
       "Strategy         Scorer                                                                                                                                                                     \n",
       "Baseline         —              83.2 +/- 0.0  83.9 ± 0.1    5133.2 ± 0.0  39.3 +/- 0.0  43.1 ± 0.1     9683.7 ± 0.0  42.3 +/- 0.0  47.7 ± 0.2     3062.2 ± 0.0   68.6 +/- 0.0  73.2 ± 0.1   \n",
       "Self-Consistency —              86.4 +/- 0.5  86.9 ± 0.5  35680.2 ± 69.6  44.7 +/- 0.6  46.8 ± 0.9  69723.3 ± 464.0  44.5 +/- 0.7  51.1 ± 0.7  20792.9 ± 127.1   72.4 +/- 1.2  75.2 ± 0.9   \n",
       "Offline BoN      prm              87.6 ± 0.7                                45.2 ± 1.7                                 40.3 ± 9.1                                  74.2 ± 0.8               \n",
       "                 entropy          85.1 ± 1.0                                40.3 ± 0.9                                 36.0 ± 7.8                                  69.8 ± 1.1               \n",
       "                 perplexity       86.0 ± 0.5                                42.0 ± 0.9                                 38.8 ± 8.6                                  71.4 ± 0.8               \n",
       "                 sequence_prob    85.9 ± 0.2                                40.7 ± 1.1                                 39.7 ± 7.8                                  71.0 ± 0.4               \n",
       "MUR              prm                                                                                                                                                                        \n",
       "                 entropy                                                                                                                                                                    \n",
       "                 perplexity                                                                                                                                                                 \n",
       "                 sequence_prob                                                                                                                                                              \n",
       "\n",
       "Dataset                                         \n",
       "Metric                                  TFlops  \n",
       "Strategy         Scorer                         \n",
       "Baseline         —                4119.7 ± 0.0  \n",
       "Self-Consistency —              28817.1 ± 85.1  \n",
       "Offline BoN      prm                            \n",
       "                 entropy                        \n",
       "                 perplexity                     \n",
       "                 sequence_prob                  \n",
       "MUR              prm                            \n",
       "                 entropy                        \n",
       "                 perplexity                     \n",
       "                 sequence_prob                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Qwen2.5-Math-7B-Instruct — scoring window = 3\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th colspan=\"3\" halign=\"left\">MATH-500</th>\n",
       "      <th colspan=\"3\" halign=\"left\">OlympiadBench</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Minerva Math</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Gaokao 2023 EN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>EM (%)</th>\n",
       "      <th>LLM (%)</th>\n",
       "      <th>TFlops</th>\n",
       "      <th>EM (%)</th>\n",
       "      <th>LLM (%)</th>\n",
       "      <th>TFlops</th>\n",
       "      <th>EM (%)</th>\n",
       "      <th>LLM (%)</th>\n",
       "      <th>TFlops</th>\n",
       "      <th>EM (%)</th>\n",
       "      <th>LLM (%)</th>\n",
       "      <th>TFlops</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strategy</th>\n",
       "      <th>Scorer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <th>—</th>\n",
       "      <td>83.2 +/- 0.0</td>\n",
       "      <td>83.9 ± 0.1</td>\n",
       "      <td>5133.2 ± 0.0</td>\n",
       "      <td>39.3 +/- 0.0</td>\n",
       "      <td>43.1 ± 0.1</td>\n",
       "      <td>9683.7 ± 0.0</td>\n",
       "      <td>42.3 +/- 0.0</td>\n",
       "      <td>47.7 ± 0.2</td>\n",
       "      <td>3062.2 ± 0.0</td>\n",
       "      <td>68.6 +/- 0.0</td>\n",
       "      <td>73.2 ± 0.1</td>\n",
       "      <td>4119.7 ± 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self-Consistency</th>\n",
       "      <th>—</th>\n",
       "      <td>86.4 +/- 0.5</td>\n",
       "      <td>86.9 ± 0.5</td>\n",
       "      <td>35680.2 ± 69.6</td>\n",
       "      <td>44.7 +/- 0.6</td>\n",
       "      <td>46.8 ± 0.9</td>\n",
       "      <td>69723.3 ± 464.0</td>\n",
       "      <td>44.5 +/- 0.7</td>\n",
       "      <td>51.1 ± 0.7</td>\n",
       "      <td>20792.9 ± 127.1</td>\n",
       "      <td>72.4 +/- 1.2</td>\n",
       "      <td>75.2 ± 0.9</td>\n",
       "      <td>28817.1 ± 85.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Offline BoN</th>\n",
       "      <th>prm</th>\n",
       "      <td>87.2 ± 0.2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>44.6 ± 1.1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>39.7 ± 8.8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>74.0 ± 0.3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>84.5 ± 1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>40.5 ± 0.2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>35.3 ± 7.3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>69.4 ± 1.4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity</th>\n",
       "      <td>86.0 ± 0.3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>42.5 ± 0.6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>38.0 ± 7.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>71.1 ± 0.4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob</th>\n",
       "      <td>85.9 ± 0.1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>41.0 ± 0.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>39.3 ± 6.2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>70.3 ± 0.8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">MUR</th>\n",
       "      <th>prm</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset                             MATH-500                             OlympiadBench                               Minerva Math                              Gaokao 2023 EN              \\\n",
       "Metric                                EM (%)     LLM (%)          TFlops        EM (%)     LLM (%)           TFlops        EM (%)     LLM (%)           TFlops         EM (%)     LLM (%)   \n",
       "Strategy         Scorer                                                                                                                                                                     \n",
       "Baseline         —              83.2 +/- 0.0  83.9 ± 0.1    5133.2 ± 0.0  39.3 +/- 0.0  43.1 ± 0.1     9683.7 ± 0.0  42.3 +/- 0.0  47.7 ± 0.2     3062.2 ± 0.0   68.6 +/- 0.0  73.2 ± 0.1   \n",
       "Self-Consistency —              86.4 +/- 0.5  86.9 ± 0.5  35680.2 ± 69.6  44.7 +/- 0.6  46.8 ± 0.9  69723.3 ± 464.0  44.5 +/- 0.7  51.1 ± 0.7  20792.9 ± 127.1   72.4 +/- 1.2  75.2 ± 0.9   \n",
       "Offline BoN      prm              87.2 ± 0.2                                44.6 ± 1.1                                 39.7 ± 8.8                                  74.0 ± 0.3               \n",
       "                 entropy          84.5 ± 1.0                                40.5 ± 0.2                                 35.3 ± 7.3                                  69.4 ± 1.4               \n",
       "                 perplexity       86.0 ± 0.3                                42.5 ± 0.6                                 38.0 ± 7.5                                  71.1 ± 0.4               \n",
       "                 sequence_prob    85.9 ± 0.1                                41.0 ± 0.5                                 39.3 ± 6.2                                  70.3 ± 0.8               \n",
       "MUR              prm                                                                                                                                                                        \n",
       "                 entropy                                                                                                                                                                    \n",
       "                 perplexity                                                                                                                                                                 \n",
       "                 sequence_prob                                                                                                                                                              \n",
       "\n",
       "Dataset                                         \n",
       "Metric                                  TFlops  \n",
       "Strategy         Scorer                         \n",
       "Baseline         —                4119.7 ± 0.0  \n",
       "Self-Consistency —              28817.1 ± 85.1  \n",
       "Offline BoN      prm                            \n",
       "                 entropy                        \n",
       "                 perplexity                     \n",
       "                 sequence_prob                  \n",
       "MUR              prm                            \n",
       "                 entropy                        \n",
       "                 perplexity                     \n",
       "                 sequence_prob                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Qwen2.5-Math-7B-Instruct — scoring window = 5\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th colspan=\"3\" halign=\"left\">MATH-500</th>\n",
       "      <th colspan=\"3\" halign=\"left\">OlympiadBench</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Minerva Math</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Gaokao 2023 EN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>EM (%)</th>\n",
       "      <th>LLM (%)</th>\n",
       "      <th>TFlops</th>\n",
       "      <th>EM (%)</th>\n",
       "      <th>LLM (%)</th>\n",
       "      <th>TFlops</th>\n",
       "      <th>EM (%)</th>\n",
       "      <th>LLM (%)</th>\n",
       "      <th>TFlops</th>\n",
       "      <th>EM (%)</th>\n",
       "      <th>LLM (%)</th>\n",
       "      <th>TFlops</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strategy</th>\n",
       "      <th>Scorer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <th>—</th>\n",
       "      <td>83.2 +/- 0.0</td>\n",
       "      <td>83.9 ± 0.1</td>\n",
       "      <td>5133.2 ± 0.0</td>\n",
       "      <td>39.3 +/- 0.0</td>\n",
       "      <td>43.1 ± 0.1</td>\n",
       "      <td>9683.7 ± 0.0</td>\n",
       "      <td>42.3 +/- 0.0</td>\n",
       "      <td>47.7 ± 0.2</td>\n",
       "      <td>3062.2 ± 0.0</td>\n",
       "      <td>68.6 +/- 0.0</td>\n",
       "      <td>73.2 ± 0.1</td>\n",
       "      <td>4119.7 ± 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self-Consistency</th>\n",
       "      <th>—</th>\n",
       "      <td>86.4 +/- 0.5</td>\n",
       "      <td>86.9 ± 0.5</td>\n",
       "      <td>35680.2 ± 69.6</td>\n",
       "      <td>44.7 +/- 0.6</td>\n",
       "      <td>46.8 ± 0.9</td>\n",
       "      <td>69723.3 ± 464.0</td>\n",
       "      <td>44.5 +/- 0.7</td>\n",
       "      <td>51.1 ± 0.7</td>\n",
       "      <td>20792.9 ± 127.1</td>\n",
       "      <td>72.4 +/- 1.2</td>\n",
       "      <td>75.2 ± 0.9</td>\n",
       "      <td>28817.1 ± 85.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Offline BoN</th>\n",
       "      <th>prm</th>\n",
       "      <td>87.2 ± 0.4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>45.0 ± 1.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>39.7 ± 8.8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>74.2 ± 0.8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>85.1 ± 1.1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>40.9 ± 0.9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>36.2 ± 7.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>70.7 ± 1.1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity</th>\n",
       "      <td>86.0 ± 0.5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>42.4 ± 0.2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>38.6 ± 8.3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>72.7 ± 0.7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob</th>\n",
       "      <td>85.3 ± 0.6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>40.8 ± 0.6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>39.0 ± 6.8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>71.6 ± 1.3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">MUR</th>\n",
       "      <th>prm</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset                             MATH-500                             OlympiadBench                               Minerva Math                              Gaokao 2023 EN              \\\n",
       "Metric                                EM (%)     LLM (%)          TFlops        EM (%)     LLM (%)           TFlops        EM (%)     LLM (%)           TFlops         EM (%)     LLM (%)   \n",
       "Strategy         Scorer                                                                                                                                                                     \n",
       "Baseline         —              83.2 +/- 0.0  83.9 ± 0.1    5133.2 ± 0.0  39.3 +/- 0.0  43.1 ± 0.1     9683.7 ± 0.0  42.3 +/- 0.0  47.7 ± 0.2     3062.2 ± 0.0   68.6 +/- 0.0  73.2 ± 0.1   \n",
       "Self-Consistency —              86.4 +/- 0.5  86.9 ± 0.5  35680.2 ± 69.6  44.7 +/- 0.6  46.8 ± 0.9  69723.3 ± 464.0  44.5 +/- 0.7  51.1 ± 0.7  20792.9 ± 127.1   72.4 +/- 1.2  75.2 ± 0.9   \n",
       "Offline BoN      prm              87.2 ± 0.4                                45.0 ± 1.5                                 39.7 ± 8.8                                  74.2 ± 0.8               \n",
       "                 entropy          85.1 ± 1.1                                40.9 ± 0.9                                 36.2 ± 7.5                                  70.7 ± 1.1               \n",
       "                 perplexity       86.0 ± 0.5                                42.4 ± 0.2                                 38.6 ± 8.3                                  72.7 ± 0.7               \n",
       "                 sequence_prob    85.3 ± 0.6                                40.8 ± 0.6                                 39.0 ± 6.8                                  71.6 ± 1.3               \n",
       "MUR              prm                                                                                                                                                                        \n",
       "                 entropy                                                                                                                                                                    \n",
       "                 perplexity                                                                                                                                                                 \n",
       "                 sequence_prob                                                                                                                                                              \n",
       "\n",
       "Dataset                                         \n",
       "Metric                                  TFlops  \n",
       "Strategy         Scorer                         \n",
       "Baseline         —                4119.7 ± 0.0  \n",
       "Self-Consistency —              28817.1 ± 85.1  \n",
       "Offline BoN      prm                            \n",
       "                 entropy                        \n",
       "                 perplexity                     \n",
       "                 sequence_prob                  \n",
       "MUR              prm                            \n",
       "                 entropy                        \n",
       "                 perplexity                     \n",
       "                 sequence_prob                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ── Qwen2.5-Math-7B-Instruct (Non-Thinking Mode) ─────────────────────────────\n",
    "\n",
    "QWEN25_DATASETS = [\"MATH-500\", \"OlympiadBench\", \"Minerva Math\", \"Gaokao 2023 EN\"]\n",
    "QWEN25_MODEL = \"qwen25_math_7b_instruct\"\n",
    "REPORT_WINDOWS = [\"all\", \"3\", \"5\"]\n",
    "\n",
    "for w in REPORT_WINDOWS:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Qwen2.5-Math-7B-Instruct — scoring window = {w}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    tbl = build_model_results_table(\n",
    "        agg_df, bon_agg_df,\n",
    "        model_filter=QWEN25_MODEL,\n",
    "        datasets=QWEN25_DATASETS,\n",
    "        bon_window=w,\n",
    "    )\n",
    "    if not tbl.empty:\n",
    "        display(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Qwen3-8B — scoring window = all\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th colspan=\"3\" halign=\"left\">AIME 2024</th>\n",
       "      <th colspan=\"3\" halign=\"left\">AIME 2025</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>EM (%)</th>\n",
       "      <th>LLM (%)</th>\n",
       "      <th>TFlops</th>\n",
       "      <th>EM (%)</th>\n",
       "      <th>LLM (%)</th>\n",
       "      <th>TFlops</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strategy</th>\n",
       "      <th>Scorer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <th>—</th>\n",
       "      <td>75.6 +/- 2.7</td>\n",
       "      <td>75.6 ± 2.7</td>\n",
       "      <td>6626.9 ± 153.1</td>\n",
       "      <td>64.4 +/- 6.2</td>\n",
       "      <td>64.4 ± 6.2</td>\n",
       "      <td>8083.6 ± 305.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ext. Thinking</th>\n",
       "      <th>—</th>\n",
       "      <td>78.9 +/- 5.1</td>\n",
       "      <td>78.9 ± 5.1</td>\n",
       "      <td>26477.7 ± 1594.4</td>\n",
       "      <td>66.7 +/- 3.3</td>\n",
       "      <td>66.7 ± 3.3</td>\n",
       "      <td>27573.9 ± 1140.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self-Consistency</th>\n",
       "      <th>—</th>\n",
       "      <td>82.2 +/- 1.9</td>\n",
       "      <td>82.2 ± 1.9</td>\n",
       "      <td>52797.2 ± 816.3</td>\n",
       "      <td>34.4 +/- 6.9</td>\n",
       "      <td>73.3 ± 5.8</td>\n",
       "      <td>53684.9 ± 1499.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Offline BoN</th>\n",
       "      <th>prm</th>\n",
       "      <td>78.9 ± 1.9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>67.8 ± 5.1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>66.7 ± 3.3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>58.9 ± 7.7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity</th>\n",
       "      <td>64.4 ± 5.1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>60.0 ± 3.3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob</th>\n",
       "      <td>68.9 ± 9.6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>64.4 ± 10.7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">MUR</th>\n",
       "      <th>prm</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset                            AIME 2024                                   AIME 2025                              \n",
       "Metric                                EM (%)     LLM (%)            TFlops        EM (%)     LLM (%)            TFlops\n",
       "Strategy         Scorer                                                                                               \n",
       "Baseline         —              75.6 +/- 2.7  75.6 ± 2.7    6626.9 ± 153.1  64.4 +/- 6.2  64.4 ± 6.2    8083.6 ± 305.2\n",
       "Ext. Thinking    —              78.9 +/- 5.1  78.9 ± 5.1  26477.7 ± 1594.4  66.7 +/- 3.3  66.7 ± 3.3  27573.9 ± 1140.5\n",
       "Self-Consistency —              82.2 +/- 1.9  82.2 ± 1.9   52797.2 ± 816.3  34.4 +/- 6.9  73.3 ± 5.8  53684.9 ± 1499.8\n",
       "Offline BoN      prm              78.9 ± 1.9                                  67.8 ± 5.1                              \n",
       "                 entropy          66.7 ± 3.3                                  58.9 ± 7.7                              \n",
       "                 perplexity       64.4 ± 5.1                                  60.0 ± 3.3                              \n",
       "                 sequence_prob    68.9 ± 9.6                                 64.4 ± 10.7                              \n",
       "MUR              prm                                                                                                  \n",
       "                 entropy                                                                                              \n",
       "                 perplexity                                                                                           \n",
       "                 sequence_prob                                                                                        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ── Qwen3-8B (Thinking Mode) ──────────────────────────────────────────────────\n",
    "\n",
    "QWEN3_DATASETS = [\"AIME 2024\", \"AIME 2025\"]\n",
    "QWEN3_MODEL = [\"vllm_thinking_qwen3_8b\", \"qwen3_8b\"]\n",
    "REPORT_WINDOWS_QWEN3 = [\"all\"]\n",
    "\n",
    "for w in REPORT_WINDOWS_QWEN3:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Qwen3-8B — scoring window = {w}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    tbl = build_model_results_table(\n",
    "        agg_df, bon_agg_df,\n",
    "        model_filter=QWEN3_MODEL,\n",
    "        datasets=QWEN3_DATASETS,\n",
    "        bon_window=w,\n",
    "    )\n",
    "    if not tbl.empty:\n",
    "        display(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "gpt-4o-mini — scoring window = all\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th colspan=\"3\" halign=\"left\">GPQA Diamond</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>EM (%)</th>\n",
       "      <th>LLM (%)</th>\n",
       "      <th>TFlops</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strategy</th>\n",
       "      <th>Scorer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Offline BoN</th>\n",
       "      <th>prm</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">MUR</th>\n",
       "      <th>prm</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perplexity</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_prob</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset                   GPQA Diamond               \n",
       "Metric                          EM (%) LLM (%) TFlops\n",
       "Strategy    Scorer                                   \n",
       "Offline BoN prm                                      \n",
       "            entropy                                  \n",
       "            perplexity                               \n",
       "            sequence_prob                            \n",
       "MUR         prm                                      \n",
       "            entropy                                  \n",
       "            perplexity                               \n",
       "            sequence_prob                            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ── gpt-4o-mini ───────────────────────────────────────────────────────────────\n",
    "\n",
    "GPT4OMINI_DATASETS = [\"GPQA Diamond\"]\n",
    "GPT4OMINI_MODEL = \"gpt4o_mini\"\n",
    "REPORT_WINDOWS_GPT = [\"all\"]\n",
    "\n",
    "for w in REPORT_WINDOWS_GPT:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"gpt-4o-mini — scoring window = {w}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    tbl = build_model_results_table(\n",
    "        agg_df, bon_agg_df,\n",
    "        model_filter=GPT4OMINI_MODEL,\n",
    "        datasets=GPT4OMINI_DATASETS,\n",
    "        bon_window=w,\n",
    "    )\n",
    "    if not tbl.empty:\n",
    "        display(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% ── Qwen2.5-Math-7B-Instruct (window=all) ───────────────────────\n",
      "\\begin{table}[htbp]\n",
      "\\caption{Results for Qwen2.5-Math-7B-Instruct (scoring window=all). EM and LLM columns show accuracy (\\%), TFlops shows total compute.}\n",
      "\\label{tab:qwen25_math_7b_instruct_wall}\n",
      "\\begin{tabular}{llllllllllllll}\n",
      "\\toprule\n",
      " & Dataset & \\multicolumn{3}{r}{MATH-500} & \\multicolumn{3}{r}{OlympiadBench} & \\multicolumn{3}{r}{Minerva Math} & \\multicolumn{3}{r}{Gaokao 2023 EN} \\\\\n",
      " & Metric & EM (\\%) & LLM (\\%) & TFlops & EM (\\%) & LLM (\\%) & TFlops & EM (\\%) & LLM (\\%) & TFlops & EM (\\%) & LLM (\\%) & TFlops \\\\\n",
      "Strategy & Scorer &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "Baseline & — & 83.2 +/- 0.0 & 83.9 ± 0.1 & 5133.2 ± 0.0 & 39.3 +/- 0.0 & 43.1 ± 0.1 & 9683.7 ± 0.0 & 42.3 +/- 0.0 & 47.7 ± 0.2 & 3062.2 ± 0.0 & 68.6 +/- 0.0 & 73.2 ± 0.1 & 4119.7 ± 0.0 \\\\\n",
      "\\cline{1-14}\n",
      "Self-Consistency & — & 86.4 +/- 0.5 & 86.9 ± 0.5 & 35680.2 ± 69.6 & 44.7 +/- 0.6 & 46.8 ± 0.9 & 69723.3 ± 464.0 & 44.5 +/- 0.7 & 51.1 ± 0.7 & 20792.9 ± 127.1 & 72.4 +/- 1.2 & 75.2 ± 0.9 & 28817.1 ± 85.1 \\\\\n",
      "\\cline{1-14}\n",
      "\\multirow[t]{4}{*}{Offline BoN} & prm & 87.6 ± 0.7 &  &  & 45.2 ± 1.7 &  &  & 40.3 ± 9.1 &  &  & 74.2 ± 0.8 &  &  \\\\\n",
      " & entropy & 85.1 ± 1.0 &  &  & 40.3 ± 0.9 &  &  & 36.0 ± 7.8 &  &  & 69.8 ± 1.1 &  &  \\\\\n",
      " & perplexity & 86.0 ± 0.5 &  &  & 42.0 ± 0.9 &  &  & 38.8 ± 8.6 &  &  & 71.4 ± 0.8 &  &  \\\\\n",
      " & sequence\\_prob & 85.9 ± 0.2 &  &  & 40.7 ± 1.1 &  &  & 39.7 ± 7.8 &  &  & 71.0 ± 0.4 &  &  \\\\\n",
      "\\cline{1-14}\n",
      "\\multirow[t]{4}{*}{MUR} & prm &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      " & entropy &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      " & perplexity &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      " & sequence\\_prob &  &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "\\cline{1-14}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "% ── Qwen3-8B (window=all) ───────────────────────────────────────\n",
      "\\begin{table}[htbp]\n",
      "\\caption{Results for Qwen3-8B (scoring window=all). EM and LLM columns show accuracy (\\%), TFlops shows total compute.}\n",
      "\\label{tab:qwen3_8b_wall}\n",
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      " & Dataset & \\multicolumn{3}{r}{AIME 2024} & \\multicolumn{3}{r}{AIME 2025} \\\\\n",
      " & Metric & EM (\\%) & LLM (\\%) & TFlops & EM (\\%) & LLM (\\%) & TFlops \\\\\n",
      "Strategy & Scorer &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "Baseline & — & 75.6 +/- 2.7 & 75.6 ± 2.7 & 6626.9 ± 153.1 & 64.4 +/- 6.2 & 64.4 ± 6.2 & 8083.6 ± 305.2 \\\\\n",
      "\\cline{1-8}\n",
      "Ext. Thinking & — & 78.9 +/- 5.1 & 78.9 ± 5.1 & 26477.7 ± 1594.4 & 66.7 +/- 3.3 & 66.7 ± 3.3 & 27573.9 ± 1140.5 \\\\\n",
      "\\cline{1-8}\n",
      "Self-Consistency & — & 82.2 +/- 1.9 & 82.2 ± 1.9 & 52797.2 ± 816.3 & 34.4 +/- 6.9 & 73.3 ± 5.8 & 53684.9 ± 1499.8 \\\\\n",
      "\\cline{1-8}\n",
      "\\multirow[t]{4}{*}{Offline BoN} & prm & 78.9 ± 1.9 &  &  & 67.8 ± 5.1 &  &  \\\\\n",
      " & entropy & 66.7 ± 3.3 &  &  & 58.9 ± 7.7 &  &  \\\\\n",
      " & perplexity & 64.4 ± 5.1 &  &  & 60.0 ± 3.3 &  &  \\\\\n",
      " & sequence\\_prob & 68.9 ± 9.6 &  &  & 64.4 ± 10.7 &  &  \\\\\n",
      "\\cline{1-8}\n",
      "\\multirow[t]{4}{*}{MUR} & prm &  &  &  &  &  &  \\\\\n",
      " & entropy &  &  &  &  &  &  \\\\\n",
      " & perplexity &  &  &  &  &  &  \\\\\n",
      " & sequence\\_prob &  &  &  &  &  &  \\\\\n",
      "\\cline{1-8}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "% ── gpt-4o-mini (window=all) ────────────────────────────────────\n",
      "\\begin{table}[htbp]\n",
      "\\caption{Results for gpt-4o-mini (scoring window=all). EM and LLM columns show accuracy (\\%), TFlops shows total compute.}\n",
      "\\label{tab:gpt_4o_mini_wall}\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      " & Dataset & \\multicolumn{3}{r}{GPQA Diamond} \\\\\n",
      " & Metric & EM (\\%) & LLM (\\%) & TFlops \\\\\n",
      "Strategy & Scorer &  &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{4}{*}{Offline BoN} & prm &  &  &  \\\\\n",
      " & entropy &  &  &  \\\\\n",
      " & perplexity &  &  &  \\\\\n",
      " & sequence\\_prob &  &  &  \\\\\n",
      "\\cline{1-5}\n",
      "\\multirow[t]{4}{*}{MUR} & prm &  &  &  \\\\\n",
      " & entropy &  &  &  \\\\\n",
      " & perplexity &  &  &  \\\\\n",
      " & sequence\\_prob &  &  &  \\\\\n",
      "\\cline{1-5}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ── LaTeX Export — Model-Specific Tables ──────────────────────────────────────\n",
    "\n",
    "MODEL_CONFIGS = [\n",
    "    (\"Qwen2.5-Math-7B-Instruct\", \"qwen25_math_7b_instruct\",\n",
    "     [\"MATH-500\", \"OlympiadBench\", \"Minerva Math\", \"Gaokao 2023 EN\"],\n",
    "     [\"all\"]),\n",
    "    (\"Qwen3-8B\", [\"vllm_thinking_qwen3_8b\", \"qwen3_8b\"],\n",
    "     [\"AIME 2024\", \"AIME 2025\"],\n",
    "     [\"all\"]),\n",
    "    (\"gpt-4o-mini\", \"gpt4o_mini\",\n",
    "     [\"GPQA Diamond\"],\n",
    "     [\"all\"]),\n",
    "]\n",
    "\n",
    "model_latex = []\n",
    "\n",
    "for model_name, model_filter, datasets, windows in MODEL_CONFIGS:\n",
    "    for w in windows:\n",
    "        tbl = build_model_results_table(\n",
    "            agg_df, bon_agg_df,\n",
    "            model_filter=model_filter,\n",
    "            datasets=datasets,\n",
    "            bon_window=w,\n",
    "        )\n",
    "        if tbl.empty:\n",
    "            continue\n",
    "        safe_name = model_name.lower().replace(\" \", \"_\").replace(\"-\", \"_\").replace(\".\", \"\")\n",
    "        ltx = to_latex(\n",
    "            tbl,\n",
    "            caption=(\n",
    "                f\"Results for {model_name} (scoring window={w}). \"\n",
    "                \"EM and LLM columns show accuracy (\\\\%), TFlops shows total compute.\"\n",
    "            ),\n",
    "            label=f\"tab:{safe_name}_w{w}\",\n",
    "        )\n",
    "        model_latex.append((f\"{model_name} (window={w})\", ltx))\n",
    "\n",
    "for title, ltx in model_latex:\n",
    "    print(f\"% ── {title} \" + \"─\" * max(1, 60 - len(title)))\n",
    "    print(ltx)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm-polygraph-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
