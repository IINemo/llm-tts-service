{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W&B Results Analysis\n",
    "\n",
    "Pull experiment metrics from Weights & Biases, build comparison tables, and export LaTeX for the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.Api()] Loaded credentials for https://api.wandb.ai from /home/vlad.smirnov/.netrc.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except ImportError:\n",
    "    sns = None\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "\n",
    "# Load .env from project root (parent of notebooks/)\n",
    "load_dotenv(Path(__file__).resolve().parent.parent / \".env\" if \"__file__\" in dir() else Path.cwd().parent / \".env\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", 40)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Configuration ──────────────────────────────────────────────────────────────\n",
    "#\n",
    "# Organized by dataset -> strategy. Each group entry is a dict with:\n",
    "#   \"group_url\":  link to the wandb group workspace\n",
    "#   \"runs\":       list of {\"seed\": <int>, \"run_url\": \"<url>\"}\n",
    "#\n",
    "# Single-group strategies (baseline, extended_thinking, self_consistency):\n",
    "#   use a single dict wrapped in a list: [{\"group_url\": ..., \"runs\": [...]}]\n",
    "#\n",
    "# Multi-group strategies (offline_bon, beam_search — one group per scorer/aggregation/window):\n",
    "#   use a list of dicts: [{\"group_url\": ..., \"runs\": [...]}, {\"group_url\": ..., \"runs\": [...]}, ...]\n",
    "#\n",
    "# Fill in the URLs. Entries with empty group_url or runs are skipped.\n",
    "\n",
    "# ── AIME 2024 ────────────────────────────────────────────────────────────────\n",
    "\n",
    "AIME_24_BASELINE_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            # {\"seed\": 42, \"run_url\": \"\"},\n",
    "            # {\"seed\": 43, \"run_url\": \"\"},\n",
    "            # {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "AIME_24_EXTENDED_THINKING_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "AIME_24_SELF_CONSISTENCY_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "AIME_24_OFFLINE_BON_RUNS = [\n",
    "    # One entry per scorer, e.g.:\n",
    "    # {\"group_url\": \".../groups/offline_bon_..._entropy\", \"runs\": [...]},\n",
    "    # {\"group_url\": \".../groups/offline_bon_..._prm\", \"runs\": [...]},\n",
    "    # {\"group_url\": \".../groups/offline_bon_..._perplexity\", \"runs\": [...]},\n",
    "    # {\"group_url\": \".../groups/offline_bon_..._sequence_prob\", \"runs\": [...]},\n",
    "]\n",
    "\n",
    "AIME_24_BEAM_SEARCH_RUNS = [\n",
    "    # One entry per scorer x aggregation x window, e.g.:\n",
    "    # {\"group_url\": \".../groups/beam_search_..._entropy_window_5_mean\", \"runs\": [...]},\n",
    "    # {\"group_url\": \".../groups/beam_search_..._entropy_window_5_max\", \"runs\": [...]},\n",
    "    # {\"group_url\": \".../groups/beam_search_..._prm_window_all_mean\", \"runs\": [...]},\n",
    "]\n",
    "\n",
    "AIME_24_RUNS = [\n",
    "    *AIME_24_BASELINE_RUNS,\n",
    "    *AIME_24_EXTENDED_THINKING_RUNS,\n",
    "    *AIME_24_SELF_CONSISTENCY_RUNS,\n",
    "    *AIME_24_OFFLINE_BON_RUNS,\n",
    "    *AIME_24_BEAM_SEARCH_RUNS,\n",
    "]\n",
    "\n",
    "# ── AIME 2025 ────────────────────────────────────────────────────────────────\n",
    "\n",
    "AIME_25_BASELINE_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "AIME_25_EXTENDED_THINKING_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "AIME_25_SELF_CONSISTENCY_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "AIME_25_OFFLINE_BON_RUNS = []\n",
    "\n",
    "AIME_25_BEAM_SEARCH_RUNS = []\n",
    "\n",
    "AIME_25_RUNS = [\n",
    "    *AIME_25_BASELINE_RUNS,\n",
    "    *AIME_25_EXTENDED_THINKING_RUNS,\n",
    "    *AIME_25_SELF_CONSISTENCY_RUNS,\n",
    "    *AIME_25_OFFLINE_BON_RUNS,\n",
    "    *AIME_25_BEAM_SEARCH_RUNS,\n",
    "]\n",
    "\n",
    "# ── MATH 500 ─────────────────────────────────────────────────────────────────\n",
    "\n",
    "MATH500_BASELINE_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/baseline_qwen25_math_7b_instruct_math500\",\n",
    "        \"runs\": [\n",
    "            {\n",
    "                \"seed\": 42,\n",
    "                \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/baseline_qwen25_math_7b_instruct_math500/runs/qz0418nv\"\n",
    "            },\n",
    "            {\n",
    "                \"seed\": 43,\n",
    "                \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/baseline_qwen25_math_7b_instruct_math500/runs/3bqhwvgp\"\n",
    "            },\n",
    "            {\n",
    "                \"seed\": 44,\n",
    "                \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/baseline_qwen25_math_7b_instruct_math500/runs/bjzqimk4\"\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "MATH500_SELF_CONSISTENCY_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/self_consistency_qwen25_math_7b_math500\",\n",
    "        \"runs\": [\n",
    "            {\n",
    "                \"seed\": 42,\n",
    "                \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/self_consistency_qwen25_math_7b_math500/runs/ky44b84m\"\n",
    "            },\n",
    "            {\n",
    "                \"seed\": 43,\n",
    "                \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/self_consistency_qwen25_math_7b_math500/runs/gtia4gii\"\n",
    "            },\n",
    "            {\n",
    "                \"seed\": 44,\n",
    "                \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/self_consistency_qwen25_math_7b_math500/runs/v87vmndj\"\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "MATH500_OFFLINE_BON_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/offline_bon_qwen25_math_7b_instruct_math500_multi_scorer\",\n",
    "        \"runs\": [\n",
    "            {\n",
    "                \"seed\": 42,\n",
    "                \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/offline_bon_qwen25_math_7b_instruct_math500_multi_scorer/runs/c35z6knc\"\n",
    "            },\n",
    "            {\n",
    "                \"seed\": 43,\n",
    "                \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/offline_bon_qwen25_math_7b_instruct_math500_multi_scorer/runs/d7jh7cbj\"\n",
    "            },\n",
    "            {\n",
    "                \"seed\": 44,\n",
    "                \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/offline_bon_qwen25_math_7b_instruct_math500_multi_scorer/runs/cz45vmb2\"\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "MATH500_BEAM_SEARCH_RUNS = []\n",
    "\n",
    "MATH500_MUR_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_prm\",\n",
    "        \"runs\": [\n",
    "            {\n",
    "                \"seed\": 42,\n",
    "                \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_prm/runs/vd5vmy7u\"\n",
    "            },\n",
    "            {\n",
    "                \"seed\": 43,\n",
    "                \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_prm/runs/1a781e39\"\n",
    "            },\n",
    "            {\n",
    "                \"seed\": 44,\n",
    "                \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_prm/runs/rj4rt3i2\"\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_entropy\",\n",
    "        \"runs\": [\n",
    "            {\n",
    "                \"seed\": 42,\n",
    "                \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_entropy/runs/tfztdzjl\"\n",
    "            },\n",
    "            {\n",
    "                \"seed\": 43,\n",
    "                \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_entropy/runs/ggqllnmy\"\n",
    "            },\n",
    "            {\n",
    "                \"seed\": 44,\n",
    "                \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_entropy/runs/aw88mzyl\"\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_perplexity\",\n",
    "        \"runs\": [\n",
    "            {\n",
    "                \"seed\": 42,\n",
    "                \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_perplexity/runs/r6oumz5s\"\n",
    "            },\n",
    "            {\n",
    "                \"seed\": 43,\n",
    "                \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_perplexity/runs/4ds5ewag\"\n",
    "            },\n",
    "            {\n",
    "                \"seed\": 44,\n",
    "                \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_perplexity/runs/5xe2x66l\"\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_sequence_prob\",\n",
    "        \"runs\": [\n",
    "            {\n",
    "                \"seed\": 42,\n",
    "                \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_sequence_prob/runs/j9a1j7mx\"\n",
    "            },\n",
    "            {\n",
    "                \"seed\": 43,\n",
    "                \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_sequence_prob/runs/zcdc7nni\"\n",
    "            },\n",
    "            {\n",
    "                \"seed\": 44,\n",
    "                \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_sequence_prob/runs/otrelz7z\"\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "MATH500_RUNS = [\n",
    "    *MATH500_BASELINE_RUNS,\n",
    "    *MATH500_SELF_CONSISTENCY_RUNS,\n",
    "    *MATH500_OFFLINE_BON_RUNS,\n",
    "    *MATH500_BEAM_SEARCH_RUNS,\n",
    "    *MATH500_MUR_RUNS\n",
    "]\n",
    "\n",
    "# ── Minerva Math ─────────────────────────────────────────────────────────────\n",
    "\n",
    "MINERVA_BASELINE_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "MINERVA_EXTENDED_THINKING_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "MINERVA_SELF_CONSISTENCY_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "MINERVA_OFFLINE_BON_RUNS = []\n",
    "\n",
    "MINERVA_BEAM_SEARCH_RUNS = []\n",
    "\n",
    "MINERVA_RUNS = [\n",
    "    *MINERVA_BASELINE_RUNS,\n",
    "    *MINERVA_EXTENDED_THINKING_RUNS,\n",
    "    *MINERVA_SELF_CONSISTENCY_RUNS,\n",
    "    *MINERVA_OFFLINE_BON_RUNS,\n",
    "    *MINERVA_BEAM_SEARCH_RUNS,\n",
    "]\n",
    "\n",
    "# ── GPQA Diamond ─────────────────────────────────────────────────────────────\n",
    "\n",
    "GPQA_BASELINE_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "GPQA_EXTENDED_THINKING_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "GPQA_SELF_CONSISTENCY_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "GPQA_OFFLINE_BON_RUNS = []\n",
    "\n",
    "GPQA_BEAM_SEARCH_RUNS = []\n",
    "\n",
    "GPQA_RUNS = [\n",
    "    *GPQA_BASELINE_RUNS,\n",
    "    *GPQA_EXTENDED_THINKING_RUNS,\n",
    "    *GPQA_SELF_CONSISTENCY_RUNS,\n",
    "    *GPQA_OFFLINE_BON_RUNS,\n",
    "    *GPQA_BEAM_SEARCH_RUNS,\n",
    "]\n",
    "\n",
    "# ── Gaokao 2023 EN ──────────────────────────────────────────────────────────\n",
    "\n",
    "GAOKAO_BASELINE_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "GAOKAO_EXTENDED_THINKING_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "GAOKAO_SELF_CONSISTENCY_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "GAOKAO_OFFLINE_BON_RUNS = []\n",
    "\n",
    "GAOKAO_BEAM_SEARCH_RUNS = []\n",
    "\n",
    "GAOKAO_RUNS = [\n",
    "    *GAOKAO_BASELINE_RUNS,\n",
    "    *GAOKAO_EXTENDED_THINKING_RUNS,\n",
    "    *GAOKAO_SELF_CONSISTENCY_RUNS,\n",
    "    *GAOKAO_OFFLINE_BON_RUNS,\n",
    "    *GAOKAO_BEAM_SEARCH_RUNS,\n",
    "]\n",
    "\n",
    "# ── OlympiadBench ────────────────────────────────────────────────────────────\n",
    "\n",
    "OLYMPIAD_BASELINE_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "OLYMPIAD_EXTENDED_THINKING_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "OLYMPIAD_SELF_CONSISTENCY_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "OLYMPIAD_OFFLINE_BON_RUNS = []\n",
    "\n",
    "OLYMPIAD_BEAM_SEARCH_RUNS = []\n",
    "\n",
    "OLYMPIAD_RUNS = [\n",
    "    *OLYMPIAD_BASELINE_RUNS,\n",
    "    *OLYMPIAD_EXTENDED_THINKING_RUNS,\n",
    "    *OLYMPIAD_SELF_CONSISTENCY_RUNS,\n",
    "    *OLYMPIAD_OFFLINE_BON_RUNS,\n",
    "    *OLYMPIAD_BEAM_SEARCH_RUNS,\n",
    "]\n",
    "\n",
    "# ── All experiments ──────────────────────────────────────────────────────────\n",
    "\n",
    "EXPERIMENT_RUNS = [\n",
    "    *AIME_24_RUNS,\n",
    "    *AIME_25_RUNS,\n",
    "    *MATH500_RUNS,\n",
    "    *MINERVA_RUNS,\n",
    "    *GPQA_RUNS,\n",
    "    *GAOKAO_RUNS,\n",
    "    *OLYMPIAD_RUNS,\n",
    "]\n",
    "\n",
    "# Which evaluator metric to use as the primary accuracy column\n",
    "PRIMARY_EVALUATOR = \"exact_match\"  # or \"llm_judge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: baseline_qwen25_math_7b_instruct_math500\n",
      "  seed=42  finished  exact_match=0.832\n",
      "  seed=43  finished  exact_match=0.832\n",
      "  seed=44  finished  exact_match=0.832\n",
      "Group: self_consistency_qwen25_math_7b_math500\n",
      "  seed=42  finished  exact_match=0.862\n",
      "  seed=43  finished  exact_match=0.87\n",
      "  seed=44  finished  exact_match=0.86\n",
      "Group: offline_bon_qwen25_math_7b_instruct_math500_multi_scorer\n",
      "  seed=42  finished  exact_match=0.85\n",
      "  seed=43  finished  exact_match=0.854\n",
      "  seed=44  finished  exact_match=0.834\n",
      "Group: adaptive_scaling_qwen25_math_7b_instruct_math500_prm\n",
      "  seed=42  finished  exact_match=0.836\n",
      "  seed=43  finished  exact_match=0.838\n",
      "  seed=44  finished  exact_match=0.846\n",
      "Group: adaptive_scaling_qwen25_math_7b_instruct_math500_entropy\n",
      "  seed=42  finished  exact_match=0.842\n",
      "  seed=43  finished  exact_match=0.834\n",
      "  seed=44  finished  exact_match=0.844\n",
      "Group: adaptive_scaling_qwen25_math_7b_instruct_math500_perplexity\n",
      "  seed=42  finished  exact_match=0.846\n",
      "  seed=43  finished  exact_match=0.846\n",
      "  seed=44  finished  exact_match=0.844\n",
      "Group: adaptive_scaling_qwen25_math_7b_instruct_math500_sequence_prob\n",
      "  seed=42  finished  exact_match=0.84\n",
      "  seed=43  finished  exact_match=0.83\n",
      "  seed=44  finished  exact_match=0.838\n",
      "\n",
      "Total runs fetched: 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>group</th>\n",
       "      <th>state</th>\n",
       "      <th>project</th>\n",
       "      <th>entity</th>\n",
       "      <th>seed</th>\n",
       "      <th>strategy</th>\n",
       "      <th>scorer</th>\n",
       "      <th>aggregation</th>\n",
       "      <th>scoring_window</th>\n",
       "      <th>scoring_window_label</th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>beam_size</th>\n",
       "      <th>candidates_per_beam</th>\n",
       "      <th>num_paths</th>\n",
       "      <th>num_candidates</th>\n",
       "      <th>max_steps</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>llm_judge_accuracy</th>\n",
       "      <th>avg_reasoning_steps</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_input_tokens</th>\n",
       "      <th>total_output_tokens</th>\n",
       "      <th>total_tflops</th>\n",
       "      <th>avg_tokens_per_sample</th>\n",
       "      <th>avg_output_tokens_per_sample</th>\n",
       "      <th>avg_tflops_per_sample</th>\n",
       "      <th>total_generations</th>\n",
       "      <th>prm_tflops</th>\n",
       "      <th>total_samples</th>\n",
       "      <th>completed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qz0418nv</td>\n",
       "      <td>2026-02-16_baseline_qwen25_math_offi...</td>\n",
       "      <td>baseline_qwen25_math_7b_instruct_mat...</td>\n",
       "      <td>finished</td>\n",
       "      <td>llm-tts-eval-math500</td>\n",
       "      <td>nlpresearch.group</td>\n",
       "      <td>42</td>\n",
       "      <td>baseline</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>math</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.832</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>366654</td>\n",
       "      <td>49470</td>\n",
       "      <td>317184</td>\n",
       "      <td>5133.156</td>\n",
       "      <td>733.308</td>\n",
       "      <td>634.368</td>\n",
       "      <td>10.266312</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3bqhwvgp</td>\n",
       "      <td>2026-02-16_baseline_qwen25_math_offi...</td>\n",
       "      <td>baseline_qwen25_math_7b_instruct_mat...</td>\n",
       "      <td>finished</td>\n",
       "      <td>llm-tts-eval-math500</td>\n",
       "      <td>nlpresearch.group</td>\n",
       "      <td>43</td>\n",
       "      <td>baseline</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>math</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.832</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>366654</td>\n",
       "      <td>49470</td>\n",
       "      <td>317184</td>\n",
       "      <td>5133.156</td>\n",
       "      <td>733.308</td>\n",
       "      <td>634.368</td>\n",
       "      <td>10.266312</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bjzqimk4</td>\n",
       "      <td>2026-02-16_baseline_qwen25_math_offi...</td>\n",
       "      <td>baseline_qwen25_math_7b_instruct_mat...</td>\n",
       "      <td>finished</td>\n",
       "      <td>llm-tts-eval-math500</td>\n",
       "      <td>nlpresearch.group</td>\n",
       "      <td>44</td>\n",
       "      <td>baseline</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>math</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.832</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>366654</td>\n",
       "      <td>49470</td>\n",
       "      <td>317184</td>\n",
       "      <td>5133.156</td>\n",
       "      <td>733.308</td>\n",
       "      <td>634.368</td>\n",
       "      <td>10.266312</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ky44b84m</td>\n",
       "      <td>2026-02-16_self_consistency_vllm_qwe...</td>\n",
       "      <td>self_consistency_qwen25_math_7b_math500</td>\n",
       "      <td>finished</td>\n",
       "      <td>llm-tts-eval-math500</td>\n",
       "      <td>nlpresearch.group</td>\n",
       "      <td>42</td>\n",
       "      <td>self_consistency</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>math</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.862</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2545296</td>\n",
       "      <td>49470</td>\n",
       "      <td>2495826</td>\n",
       "      <td>35634.144</td>\n",
       "      <td>5090.592</td>\n",
       "      <td>4991.652</td>\n",
       "      <td>71.268288</td>\n",
       "      <td>4000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gtia4gii</td>\n",
       "      <td>2026-02-16_self_consistency_vllm_qwe...</td>\n",
       "      <td>self_consistency_qwen25_math_7b_math500</td>\n",
       "      <td>finished</td>\n",
       "      <td>llm-tts-eval-math500</td>\n",
       "      <td>nlpresearch.group</td>\n",
       "      <td>43</td>\n",
       "      <td>self_consistency</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>math</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.870</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2554304</td>\n",
       "      <td>49470</td>\n",
       "      <td>2504834</td>\n",
       "      <td>35760.256</td>\n",
       "      <td>5108.608</td>\n",
       "      <td>5009.668</td>\n",
       "      <td>71.520512</td>\n",
       "      <td>4000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     run_id                                 run_name                                    group     state               project             entity  seed          strategy   scorer aggregation  \\\n",
       "0  qz0418nv  2026-02-16_baseline_qwen25_math_offi...  baseline_qwen25_math_7b_instruct_mat...  finished  llm-tts-eval-math500  nlpresearch.group    42          baseline  entropy        None   \n",
       "1  3bqhwvgp  2026-02-16_baseline_qwen25_math_offi...  baseline_qwen25_math_7b_instruct_mat...  finished  llm-tts-eval-math500  nlpresearch.group    43          baseline  entropy        None   \n",
       "2  bjzqimk4  2026-02-16_baseline_qwen25_math_offi...  baseline_qwen25_math_7b_instruct_mat...  finished  llm-tts-eval-math500  nlpresearch.group    44          baseline  entropy        None   \n",
       "3  ky44b84m  2026-02-16_self_consistency_vllm_qwe...  self_consistency_qwen25_math_7b_math500  finished  llm-tts-eval-math500  nlpresearch.group    42  self_consistency  entropy        None   \n",
       "4  gtia4gii  2026-02-16_self_consistency_vllm_qwe...  self_consistency_qwen25_math_7b_math500  finished  llm-tts-eval-math500  nlpresearch.group    43  self_consistency  entropy        None   \n",
       "\n",
       "  scoring_window scoring_window_label                    model dataset beam_size candidates_per_beam  num_paths num_candidates  max_steps  exact_match llm_judge_accuracy  avg_reasoning_steps  \\\n",
       "0           None                 None  qwen25_math_7b_instruct    math      None                None        NaN           None        NaN        0.832               None                  1.0   \n",
       "1           None                 None  qwen25_math_7b_instruct    math      None                None        NaN           None        NaN        0.832               None                  1.0   \n",
       "2           None                 None  qwen25_math_7b_instruct    math      None                None        NaN           None        NaN        0.832               None                  1.0   \n",
       "3           None                 None  qwen25_math_7b_instruct    math      None                None        8.0           None        NaN        0.862               None                  1.0   \n",
       "4           None                 None  qwen25_math_7b_instruct    math      None                None        8.0           None        NaN        0.870               None                  1.0   \n",
       "\n",
       "   total_tokens  total_input_tokens  total_output_tokens  total_tflops  avg_tokens_per_sample  avg_output_tokens_per_sample  avg_tflops_per_sample  total_generations  prm_tflops  total_samples  \\\n",
       "0        366654               49470               317184      5133.156                733.308                       634.368              10.266312                500         NaN            500   \n",
       "1        366654               49470               317184      5133.156                733.308                       634.368              10.266312                500         NaN            500   \n",
       "2        366654               49470               317184      5133.156                733.308                       634.368              10.266312                500         NaN            500   \n",
       "3       2545296               49470              2495826     35634.144               5090.592                      4991.652              71.268288               4000         NaN            500   \n",
       "4       2554304               49470              2504834     35760.256               5108.608                      5009.668              71.520512               4000         NaN            500   \n",
       "\n",
       "   completed  \n",
       "0        500  \n",
       "1        500  \n",
       "2        500  \n",
       "3        500  \n",
       "4        500  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ── Data Fetching ─────────────────────────────────────────────────────────────\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "def parse_group_url(url: str) -> dict:\n",
    "    \"\"\"Extract entity, project, and group name from a wandb group URL.\"\"\"\n",
    "    path = urlparse(url).path.strip(\"/\")\n",
    "    m = re.match(r\"^(?P<entity>[^/]+)/(?P<project>[^/]+)/groups/(?P<group>[^/]+)\", path)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse group URL: {url}\")\n",
    "    return m.groupdict()\n",
    "\n",
    "\n",
    "def parse_run_url(url: str) -> dict:\n",
    "    \"\"\"Extract entity, project, and run_id from a wandb run URL.\n",
    "\n",
    "    Handles both formats:\n",
    "      .../runs/RUN_ID\n",
    "      .../groups/GROUP/runs/RUN_ID\n",
    "    \"\"\"\n",
    "    path = urlparse(url).path.strip(\"/\")\n",
    "    m = re.match(r\"^(?P<entity>[^/]+)/(?P<project>[^/]+)/(?:groups/[^/]+/)?runs/(?P<run_id>[^/]+)\", path)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse run URL: {url}\")\n",
    "    return m.groupdict()\n",
    "\n",
    "\n",
    "def fetch_run(entity: str, project: str, run_id: str, group_name: str, seed: int) -> dict:\n",
    "    \"\"\"Fetch a single run and return a flat record dict.\"\"\"\n",
    "    run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "    cfg = run.config\n",
    "    s = run.summary._json_dict\n",
    "\n",
    "    strategy_cfg = cfg.get(\"strategy\", {})\n",
    "    scorer_cfg = cfg.get(\"scorer\", {})\n",
    "    model_cfg = cfg.get(\"model\", {})\n",
    "    dataset_cfg = cfg.get(\"dataset\", {})\n",
    "    system_cfg = cfg.get(\"system\", {})\n",
    "\n",
    "    return {\n",
    "        # identifiers\n",
    "        \"run_id\": run.id,\n",
    "        \"run_name\": run.name,\n",
    "        \"group\": group_name,\n",
    "        \"state\": run.state,\n",
    "        \"project\": project,\n",
    "        \"entity\": entity,\n",
    "        \"seed\": seed,\n",
    "        # config fields\n",
    "        \"strategy\": strategy_cfg.get(\"type\"),\n",
    "        \"scorer\": scorer_cfg.get(\"type\"),\n",
    "        \"aggregation\": strategy_cfg.get(\"aggregation\"),\n",
    "        \"scoring_window\": strategy_cfg.get(\"scoring_window\"),\n",
    "        \"scoring_window_label\": strategy_cfg.get(\"scoring_window_label\"),\n",
    "        \"model\": model_cfg.get(\"model_short_name\") or model_cfg.get(\"model_name\"),\n",
    "        \"dataset\": dataset_cfg.get(\"data_name\"),\n",
    "        \"beam_size\": strategy_cfg.get(\"beam_size\"),\n",
    "        \"candidates_per_beam\": strategy_cfg.get(\"candidates_per_beam\"),\n",
    "        \"num_paths\": strategy_cfg.get(\"num_paths\"),\n",
    "        \"num_candidates\": strategy_cfg.get(\"num_candidates\"),\n",
    "        \"max_steps\": strategy_cfg.get(\"max_steps\"),\n",
    "        # summary metrics\n",
    "        \"exact_match\": s.get(\"exact_match/accuracy\"),\n",
    "        \"llm_judge_accuracy\": s.get(\"llm_judge/accuracy\"),\n",
    "        \"avg_reasoning_steps\": s.get(\"avg_reasoning_steps_per_trajectory\"),\n",
    "        \"total_tokens\": s.get(\"compute/total_tokens\"),\n",
    "        \"total_input_tokens\": s.get(\"compute/total_input_tokens\"),\n",
    "        \"total_output_tokens\": s.get(\"compute/total_output_tokens\"),\n",
    "        \"total_tflops\": s.get(\"compute/total_tflops\"),\n",
    "        \"avg_tokens_per_sample\": s.get(\"compute/avg_tokens_per_sample\"),\n",
    "        \"avg_output_tokens_per_sample\": s.get(\"compute/avg_output_tokens_per_sample\"),\n",
    "        \"avg_tflops_per_sample\": s.get(\"compute/avg_tflops_per_sample\"),\n",
    "        \"total_generations\": s.get(\"compute/total_generations\"),\n",
    "        \"prm_tflops\": s.get(\"compute/prm_tflops\"),\n",
    "        \"total_samples\": s.get(\"total_samples\"),\n",
    "        \"completed\": s.get(\"completed\"),\n",
    "    }\n",
    "\n",
    "\n",
    "# Fetch all specified runs (skip entries with empty group_url or runs)\n",
    "records = []\n",
    "for entry in EXPERIMENT_RUNS:\n",
    "    if not entry.get(\"group_url\") or not entry.get(\"runs\"):\n",
    "        continue\n",
    "\n",
    "    group_info = parse_group_url(entry[\"group_url\"])\n",
    "    group_name = group_info[\"group\"]\n",
    "    print(f\"Group: {group_name}\")\n",
    "\n",
    "    for run_entry in entry[\"runs\"]:\n",
    "        seed = run_entry[\"seed\"]\n",
    "        run_info = parse_run_url(run_entry[\"run_url\"])\n",
    "        try:\n",
    "            record = fetch_run(run_info[\"entity\"], run_info[\"project\"],\n",
    "                               run_info[\"run_id\"], group_name, seed)\n",
    "            records.append(record)\n",
    "            print(f\"  seed={seed}  {record['state']}  \"\n",
    "                  f\"exact_match={record.get('exact_match')}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR fetching seed={seed}: {e}\")\n",
    "\n",
    "raw_df = pd.DataFrame(records)\n",
    "print(f\"\\nTotal runs fetched: {len(raw_df)}\")\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 9/9 finished runs\n",
      "\n",
      "Strategies: ['baseline', 'offline_best_of_n', 'self_consistency']\n",
      "Scorers:    ['entropy']\n",
      "Datasets:   ['math']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strategy</th>\n",
       "      <th>scorer</th>\n",
       "      <th>aggregation</th>\n",
       "      <th>scoring_window</th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>total_tflops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>83.2</td>\n",
       "      <td>5133.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>83.2</td>\n",
       "      <td>5133.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>83.2</td>\n",
       "      <td>5133.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>self_consistency</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>86.2</td>\n",
       "      <td>35634.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>self_consistency</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>87.0</td>\n",
       "      <td>35760.256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>self_consistency</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>86.0</td>\n",
       "      <td>35646.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>offline_best_of_n</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>85.0</td>\n",
       "      <td>37234.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>offline_best_of_n</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>85.4</td>\n",
       "      <td>37780.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>offline_best_of_n</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>math</td>\n",
       "      <td>qwen25_math_7b_instruct</td>\n",
       "      <td>83.4</td>\n",
       "      <td>37954.980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            strategy   scorer aggregation scoring_window dataset                    model  exact_match  total_tflops\n",
       "0           baseline  entropy        None           None    math  qwen25_math_7b_instruct         83.2      5133.156\n",
       "1           baseline  entropy        None           None    math  qwen25_math_7b_instruct         83.2      5133.156\n",
       "2           baseline  entropy        None           None    math  qwen25_math_7b_instruct         83.2      5133.156\n",
       "3   self_consistency  entropy        None           None    math  qwen25_math_7b_instruct         86.2     35634.144\n",
       "4   self_consistency  entropy        None           None    math  qwen25_math_7b_instruct         87.0     35760.256\n",
       "5   self_consistency  entropy        None           None    math  qwen25_math_7b_instruct         86.0     35646.268\n",
       "6  offline_best_of_n  entropy        None           None    math  qwen25_math_7b_instruct         85.0     37234.708\n",
       "7  offline_best_of_n  entropy        None           None    math  qwen25_math_7b_instruct         85.4     37780.848\n",
       "8  offline_best_of_n  entropy        None           None    math  qwen25_math_7b_instruct         83.4     37954.980"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ── Data Cleaning & Parsing ───────────────────────────────────────────────────\n",
    "\n",
    "def parse_group_name(group: str | None) -> dict:\n",
    "    \"\"\"Best-effort extraction of structured fields from the group name.\n",
    "\n",
    "    Expected patterns:\n",
    "      {strategy}_{model}_{dataset}\n",
    "      {strategy}_{model}_{dataset}_{scorer}\n",
    "      {strategy}_{model}_{dataset}_{scorer}_{window}_{aggregation}\n",
    "    \"\"\"\n",
    "    result = {\"_group_strategy\": None, \"_group_model\": None,\n",
    "              \"_group_dataset\": None, \"_group_scorer\": None,\n",
    "              \"_group_window\": None, \"_group_aggregation\": None}\n",
    "    if not group:\n",
    "        return result\n",
    "\n",
    "    known_strategies = {\n",
    "        \"baseline\", \"chain_of_thought\", \"self_consistency\",\n",
    "        \"online_bon\", \"offline_bon\", \"beam_search\",\n",
    "        \"uncertainty_cot\", \"extended_thinking\",\n",
    "        \"adaptive_scaling\", \"deepconf\",\n",
    "    }\n",
    "    known_scorers = {\n",
    "        \"prm\", \"entropy\", \"perplexity\", \"sequence_prob\",\n",
    "        \"uncertainty\", \"uncertainty_pd\", \"uncertainty_uhead\",\n",
    "    }\n",
    "    known_aggregations = {\"mean\", \"min\", \"max\", \"sum\", \"product\", \"median\"}\n",
    "    known_datasets = {\n",
    "        \"minerva_math\", \"math500\", \"aime2024\", \"aime2025\",\n",
    "        \"gaokao2023en\", \"human_eval_plus\", \"olympiadbench\",\n",
    "    }\n",
    "\n",
    "    parts = group.split(\"_\")\n",
    "\n",
    "    # Greedy match strategy prefix (try longest first)\n",
    "    strategy = None\n",
    "    for length in range(min(3, len(parts)), 0, -1):\n",
    "        candidate = \"_\".join(parts[:length])\n",
    "        if candidate in known_strategies:\n",
    "            strategy = candidate\n",
    "            parts = parts[length:]\n",
    "            break\n",
    "    result[\"_group_strategy\"] = strategy\n",
    "\n",
    "    # Scan remaining parts for known tokens\n",
    "    remaining = \"_\".join(parts)\n",
    "    for ds in sorted(known_datasets, key=len, reverse=True):\n",
    "        if ds in remaining:\n",
    "            result[\"_group_dataset\"] = ds\n",
    "            remaining = remaining.replace(ds, \"\", 1)\n",
    "            break\n",
    "    for sc in sorted(known_scorers, key=len, reverse=True):\n",
    "        if f\"_{sc}\" in f\"_{remaining}\":\n",
    "            result[\"_group_scorer\"] = sc\n",
    "            remaining = remaining.replace(sc, \"\", 1)\n",
    "            break\n",
    "    for ag in known_aggregations:\n",
    "        if f\"_{ag}\" in f\"_{remaining}\":\n",
    "            result[\"_group_aggregation\"] = ag\n",
    "            break\n",
    "    # window: look for a bare integer or \"all\"\n",
    "    for p in remaining.split(\"_\"):\n",
    "        if p.isdigit():\n",
    "            result[\"_group_window\"] = p\n",
    "            break\n",
    "        if p == \"all\":\n",
    "            result[\"_group_window\"] = \"all\"\n",
    "            break\n",
    "\n",
    "    # model: whatever remains after removing known tokens is likely the model\n",
    "    for tok in [result[\"_group_dataset\"], result[\"_group_scorer\"],\n",
    "                result[\"_group_aggregation\"], result[\"_group_window\"]]:\n",
    "        if tok:\n",
    "            remaining = remaining.replace(tok, \"\", 1)\n",
    "    model_str = \"_\".join(p for p in remaining.split(\"_\") if p)\n",
    "    result[\"_group_model\"] = model_str or None\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "df = raw_df.copy()\n",
    "\n",
    "# Parse group names to fill missing config columns\n",
    "parsed = df[\"group\"].apply(parse_group_name).apply(pd.Series)\n",
    "df = pd.concat([df, parsed], axis=1)\n",
    "\n",
    "# Fill missing config from parsed group name\n",
    "for col, gcol in [(\"strategy\", \"_group_strategy\"), (\"scorer\", \"_group_scorer\"),\n",
    "                   (\"aggregation\", \"_group_aggregation\"),\n",
    "                   (\"scoring_window\", \"_group_window\"),\n",
    "                   (\"dataset\", \"_group_dataset\"), (\"model\", \"_group_model\")]:\n",
    "    df[col] = df[col].fillna(df[gcol])\n",
    "\n",
    "# Drop helper columns\n",
    "df.drop(columns=[c for c in df.columns if c.startswith(\"_group_\")], inplace=True)\n",
    "\n",
    "# Filter to finished runs only\n",
    "n_before = len(df)\n",
    "df = df[df[\"state\"] == \"finished\"].copy()\n",
    "print(f\"Kept {len(df)}/{n_before} finished runs\")\n",
    "\n",
    "# Optional group filter\n",
    "if GROUP_FILTERS:\n",
    "    mask = df[\"group\"].apply(lambda g: any(f in (g or \"\") for f in GROUP_FILTERS))\n",
    "    df = df[mask].copy()\n",
    "    print(f\"After group filter: {len(df)} runs\")\n",
    "\n",
    "# Normalize accuracy to percentage\n",
    "for col in [\"exact_match\", \"llm_judge_accuracy\"]:\n",
    "    if col in df.columns:\n",
    "        # If values look like fractions (0-1), convert to pct\n",
    "        mask = df[col].notna() & (df[col] <= 1.0)\n",
    "        df.loc[mask, col] = df.loc[mask, col] * 100\n",
    "\n",
    "print(f\"\\nStrategies: {sorted(df['strategy'].dropna().unique())}\")\n",
    "print(f\"Scorers:    {sorted(df['scorer'].dropna().unique())}\")\n",
    "print(f\"Datasets:   {sorted(df['dataset'].dropna().unique())}\")\n",
    "df[[\"strategy\", \"scorer\", \"aggregation\", \"scoring_window\", \"dataset\", \"model\",\n",
    "    \"exact_match\", \"total_tflops\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Seed Averaging ────────────────────────────────────────────────────────────\n",
    "\n",
    "CONFIG_COLS = [\"strategy\", \"scorer\", \"aggregation\", \"scoring_window\",\n",
    "               \"model\", \"dataset\", \"project_label\",\n",
    "               \"beam_size\", \"candidates_per_beam\", \"num_paths\", \"num_candidates\"]\n",
    "\n",
    "METRIC_COLS = [\"exact_match\", \"llm_judge_accuracy\", \"avg_reasoning_steps\",\n",
    "               \"total_tokens\", \"total_tflops\", \"avg_tokens_per_sample\",\n",
    "               \"avg_output_tokens_per_sample\", \"avg_tflops_per_sample\"]\n",
    "\n",
    "\n",
    "def aggregate_seeds(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Group by config columns and compute mean/std over seeds.\"\"\"\n",
    "    present_cfg = [c for c in CONFIG_COLS if c in df.columns]\n",
    "    present_met = [c for c in METRIC_COLS if c in df.columns]\n",
    "\n",
    "    grouped = df.groupby(present_cfg, dropna=False)\n",
    "    agg = grouped[present_met].agg([\"mean\", \"std\", \"count\"]).reset_index()\n",
    "\n",
    "    # Flatten multi-level columns\n",
    "    flat_cols = []\n",
    "    for col in agg.columns:\n",
    "        if isinstance(col, tuple) and col[1]:\n",
    "            flat_cols.append(f\"{col[0]}_{col[1]}\")\n",
    "        else:\n",
    "            flat_cols.append(col[0] if isinstance(col, tuple) else col)\n",
    "    agg.columns = flat_cols\n",
    "\n",
    "    # Add a formatted \"mean +/- std\" column for the primary metric\n",
    "    for m in present_met:\n",
    "        mean_col, std_col = f\"{m}_mean\", f\"{m}_std\"\n",
    "        if mean_col in agg.columns:\n",
    "            agg[f\"{m}_fmt\"] = agg.apply(\n",
    "                lambda r: f\"{r[mean_col]:.1f} +/- {r[std_col]:.1f}\"\n",
    "                if pd.notna(r[std_col]) and r.get(f\"{m}_count\", 0) > 1\n",
    "                else (f\"{r[mean_col]:.1f}\" if pd.notna(r[mean_col]) else \"\"),\n",
    "                axis=1,\n",
    "            )\n",
    "    return agg\n",
    "\n",
    "\n",
    "agg_df = aggregate_seeds(df)\n",
    "print(f\"Aggregated configs: {len(agg_df)}\")\n",
    "agg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Pivot Table Helper ────────────────────────────────────────────────────────\n",
    "\n",
    "def make_comparison_table(\n",
    "    df: pd.DataFrame,\n",
    "    row_field: str,\n",
    "    col_field: str,\n",
    "    value_field: str = \"exact_match_fmt\",\n",
    "    filter_dict: dict | None = None,\n",
    "    title: str | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Build a pivot table from the aggregated DataFrame.\"\"\"\n",
    "    sub = df.copy()\n",
    "    if filter_dict:\n",
    "        for k, v in filter_dict.items():\n",
    "            if isinstance(v, list):\n",
    "                sub = sub[sub[k].isin(v)]\n",
    "            else:\n",
    "                sub = sub[sub[k] == v]\n",
    "\n",
    "    if sub.empty:\n",
    "        print(\"No data after filtering.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    pivot = sub.pivot_table(\n",
    "        index=row_field,\n",
    "        columns=col_field,\n",
    "        values=value_field,\n",
    "        aggfunc=\"first\",\n",
    "    )\n",
    "    if title:\n",
    "        print(f\"\\n{'=' * len(title)}\")\n",
    "        print(title)\n",
    "        print(f\"{'=' * len(title)}\")\n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Table 1: Strategy x Scorer Grid ───────────────────────────────────────────\n",
    "\n",
    "for dataset_label in sorted(agg_df[\"project_label\"].dropna().unique()):\n",
    "    tbl = make_comparison_table(\n",
    "        agg_df,\n",
    "        row_field=\"scorer\",\n",
    "        col_field=\"strategy\",\n",
    "        value_field=\"exact_match_fmt\",\n",
    "        filter_dict={\"project_label\": dataset_label},\n",
    "        title=f\"Exact Match (%) — {dataset_label}\",\n",
    "    )\n",
    "    if not tbl.empty:\n",
    "        display(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Table 2: Aggregation x Scoring Window (beam search only) ──────────────────\n",
    "\n",
    "beam_df = agg_df[agg_df[\"strategy\"] == \"beam_search\"].copy()\n",
    "\n",
    "if beam_df.empty:\n",
    "    print(\"No beam search runs found.\")\n",
    "else:\n",
    "    for scorer in sorted(beam_df[\"scorer\"].dropna().unique()):\n",
    "        for dataset_label in sorted(beam_df[\"project_label\"].dropna().unique()):\n",
    "            tbl = make_comparison_table(\n",
    "                beam_df,\n",
    "                row_field=\"aggregation\",\n",
    "                col_field=\"scoring_window\",\n",
    "                value_field=\"exact_match_fmt\",\n",
    "                filter_dict={\"scorer\": scorer, \"project_label\": dataset_label},\n",
    "                title=f\"Beam Search — scorer={scorer}, dataset={dataset_label}\",\n",
    "            )\n",
    "            if not tbl.empty:\n",
    "                display(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Table 3: Compute Efficiency ───────────────────────────────────────────────\n",
    "\n",
    "eff_cols = [\"strategy\", \"scorer\", \"aggregation\", \"scoring_window\",\n",
    "            \"project_label\", \"model\",\n",
    "            \"exact_match_mean\", \"total_tflops_mean\",\n",
    "            \"avg_tokens_per_sample_mean\", \"avg_reasoning_steps_mean\"]\n",
    "present = [c for c in eff_cols if c in agg_df.columns]\n",
    "eff_df = agg_df[present].copy()\n",
    "\n",
    "# Rename for readability\n",
    "rename_map = {\n",
    "    \"exact_match_mean\": \"Accuracy (%)\",\n",
    "    \"total_tflops_mean\": \"Total TFLOPS\",\n",
    "    \"avg_tokens_per_sample_mean\": \"Tokens/Problem\",\n",
    "    \"avg_reasoning_steps_mean\": \"Reasoning Steps\",\n",
    "}\n",
    "eff_df.rename(columns={k: v for k, v in rename_map.items() if k in eff_df.columns},\n",
    "              inplace=True)\n",
    "\n",
    "eff_df.sort_values(\"Accuracy (%)\", ascending=False, inplace=True)\n",
    "print(\"Compute Efficiency Overview\")\n",
    "print(\"=\" * 40)\n",
    "display(eff_df.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── LaTeX Export ──────────────────────────────────────────────────────────────\n",
    "\n",
    "def to_latex(df: pd.DataFrame, caption: str, label: str) -> str:\n",
    "    \"\"\"Convert a DataFrame to a booktabs LaTeX table string.\"\"\"\n",
    "    latex = df.to_latex(\n",
    "        index=True,\n",
    "        escape=True,\n",
    "        na_rep=\"--\",\n",
    "        caption=caption,\n",
    "        label=label,\n",
    "        position=\"htbp\",\n",
    "    )\n",
    "    # Add booktabs rules\n",
    "    latex = latex.replace(\"\\\\toprule\", \"\\\\toprule\")  # already there with booktabs\n",
    "    return latex\n",
    "\n",
    "\n",
    "# Re-generate tables and export as LaTeX\n",
    "latex_outputs = []\n",
    "\n",
    "# Strategy x Scorer tables\n",
    "for dataset_label in sorted(agg_df[\"project_label\"].dropna().unique()):\n",
    "    tbl = make_comparison_table(\n",
    "        agg_df,\n",
    "        row_field=\"scorer\",\n",
    "        col_field=\"strategy\",\n",
    "        value_field=\"exact_match_fmt\",\n",
    "        filter_dict={\"project_label\": dataset_label},\n",
    "    )\n",
    "    if not tbl.empty:\n",
    "        ltx = to_latex(\n",
    "            tbl,\n",
    "            caption=f\"Exact match accuracy (\\\\%) by strategy and scorer on {dataset_label}.\",\n",
    "            label=f\"tab:strategy_scorer_{dataset_label}\",\n",
    "        )\n",
    "        latex_outputs.append((f\"Strategy x Scorer — {dataset_label}\", ltx))\n",
    "\n",
    "# Beam search aggregation x window tables\n",
    "if not beam_df.empty:\n",
    "    for scorer in sorted(beam_df[\"scorer\"].dropna().unique()):\n",
    "        for dataset_label in sorted(beam_df[\"project_label\"].dropna().unique()):\n",
    "            tbl = make_comparison_table(\n",
    "                beam_df,\n",
    "                row_field=\"aggregation\",\n",
    "                col_field=\"scoring_window\",\n",
    "                value_field=\"exact_match_fmt\",\n",
    "                filter_dict={\"scorer\": scorer, \"project_label\": dataset_label},\n",
    "            )\n",
    "            if not tbl.empty:\n",
    "                ltx = to_latex(\n",
    "                    tbl,\n",
    "                    caption=f\"Beam search accuracy (\\\\%) — scorer={scorer}, dataset={dataset_label}.\",\n",
    "                    label=f\"tab:beam_{scorer}_{dataset_label}\",\n",
    "                )\n",
    "                latex_outputs.append((f\"Beam {scorer} — {dataset_label}\", ltx))\n",
    "\n",
    "# Efficiency table\n",
    "if not eff_df.empty:\n",
    "    ltx = to_latex(\n",
    "        eff_df.reset_index(drop=True),\n",
    "        caption=\"Compute efficiency comparison across strategies.\",\n",
    "        label=\"tab:compute_efficiency\",\n",
    "    )\n",
    "    latex_outputs.append((\"Compute Efficiency\", ltx))\n",
    "\n",
    "# Print all LaTeX\n",
    "for title, ltx in latex_outputs:\n",
    "    print(f\"% ── {title} \" + \"─\" * (60 - len(title)))\n",
    "    print(ltx)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Visualization ─────────────────────────────────────────────────────────────\n",
    "\n",
    "# Bar chart: accuracy by strategy (per dataset)\n",
    "plot_df = agg_df.dropna(subset=[\"exact_match_mean\"]).copy()\n",
    "\n",
    "if not plot_df.empty:\n",
    "    fig, axes = plt.subplots(\n",
    "        1, max(1, plot_df[\"project_label\"].nunique()),\n",
    "        figsize=(6 * max(1, plot_df[\"project_label\"].nunique()), 5),\n",
    "        squeeze=False,\n",
    "    )\n",
    "    for idx, dataset_label in enumerate(sorted(plot_df[\"project_label\"].unique())):\n",
    "        ax = axes[0, idx]\n",
    "        sub = plot_df[plot_df[\"project_label\"] == dataset_label]\n",
    "        # Average across scorers/configs per strategy\n",
    "        bars = sub.groupby(\"strategy\")[\"exact_match_mean\"].mean().sort_values()\n",
    "        bars.plot.barh(ax=ax, color=\"steelblue\")\n",
    "        ax.set_xlabel(\"Exact Match (%)\")\n",
    "        ax.set_title(dataset_label)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data for bar chart.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap: beam search scorer x aggregation x window\n",
    "\n",
    "if sns is None:\n",
    "    print(\"Install seaborn for heatmap visualization: pip install seaborn\")\n",
    "elif not beam_df.empty:\n",
    "    heat_df = beam_df.dropna(subset=[\"exact_match_mean\"]).copy()\n",
    "    heat_df[\"config\"] = heat_df[\"aggregation\"].astype(str) + \" / w=\" + heat_df[\"scoring_window\"].astype(str)\n",
    "\n",
    "    for dataset_label in sorted(heat_df[\"project_label\"].dropna().unique()):\n",
    "        sub = heat_df[heat_df[\"project_label\"] == dataset_label]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        pivot = sub.pivot_table(\n",
    "            index=\"config\", columns=\"scorer\",\n",
    "            values=\"exact_match_mean\", aggfunc=\"first\",\n",
    "        )\n",
    "        if pivot.empty:\n",
    "            continue\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(max(6, pivot.shape[1] * 2), max(4, pivot.shape[0] * 0.6)))\n",
    "        sns.heatmap(pivot, annot=True, fmt=\".1f\", cmap=\"YlGnBu\", ax=ax)\n",
    "        ax.set_title(f\"Beam Search Accuracy — {dataset_label}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No beam search data for heatmap.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm-polygraph-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
