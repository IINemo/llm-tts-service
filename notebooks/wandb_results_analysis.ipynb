{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W&B Results Analysis\n",
    "\n",
    "This notebook pulls experiment results from Weights & Biases, analyzes them, and produces charts and LaTeX tables for the paper.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "You must be logged in to W&B with access to the `nlpresearch.group` entity:\n",
    "\n",
    "```bash\n",
    "wandb login\n",
    "```\n",
    "\n",
    "## Pipeline\n",
    "\n",
    "1. **Configuration** — Define W&B run URLs for each strategy/dataset/seed combination\n",
    "2. **Fetch metrics** — Pull accuracy, TFLOPs, and token counts from W&B runs\n",
    "3. **Download candidates** — Cache `candidates.json` artifacts for offline BoN re-scoring\n",
    "4. **Multi-scorer analysis** — Score offline BoN candidates with every (scorer, aggregation, window) combo\n",
    "5. **Build result tables** — Aggregate across seeds, compute deltas and baselines per model\n",
    "6. **Charts** — Plot accuracy-vs-compute ratio charts (aggregate and per-dataset)\n",
    "7. **LaTeX export** — Generate `.tex` tables for the paper appendix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before committing**, clear all notebook outputs to keep the file lightweight:\n",
    "\n",
    "```bash\n",
    "jupyter nbconvert --clear-output --inplace notebooks/wandb_results_analysis.ipynb\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except ImportError:\n",
    "    sns = None\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "\n",
    "# Load .env from project root (parent of notebooks/)\n",
    "load_dotenv(Path(__file__).resolve().parent.parent / \".env\" if \"__file__\" in dir() else Path.cwd().parent / \".env\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"ANTLR runtime and generated code versions disagree\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", 40)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Configuration ──────────────────────────────────────────────────────────────\n",
    "#\n",
    "# Organized by dataset -> strategy. Each group entry is a dict with:\n",
    "#   \"group_url\":  link to the wandb group workspace\n",
    "#   \"runs\":       list of {\"seed\": <int>, \"run_url\": \"<url>\"}\n",
    "#\n",
    "# Single-group strategies (baseline, self_consistency):\n",
    "#   use a single dict wrapped in a list: [{\"group_url\": ..., \"runs\": [...]}]\n",
    "#\n",
    "# Multi-group strategies (offline_bon, beam_search, MUR — one group per scorer/aggregation/window):\n",
    "#   use a list of dicts: [{\"group_url\": ..., \"runs\": [...]}, ...]\n",
    "#\n",
    "# Fill in the URLs. Entries with empty group_url or runs are skipped.\n",
    "\n",
    "# ── MATH 500 ─────────────────────────────────────────────────────────────────\n",
    "\n",
    "MATH500_BASELINE_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/baseline_qwen25_math_7b_instruct_math500\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/baseline_qwen25_math_7b_instruct_math500/runs/qz0418nv\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/baseline_qwen25_math_7b_instruct_math500/runs/3bqhwvgp\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/baseline_qwen25_math_7b_instruct_math500/runs/bjzqimk4\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MATH500_SELF_CONSISTENCY_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/self_consistency_qwen25_math_7b_math500\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/self_consistency_qwen25_math_7b_math500/runs/ky44b84m\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/self_consistency_qwen25_math_7b_math500/runs/gtia4gii\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/self_consistency_qwen25_math_7b_math500/runs/v87vmndj\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MATH500_OFFLINE_BON_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/offline_bon_qwen25_math_7b_instruct_math500_multi_scorer\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/offline_bon_qwen25_math_7b_instruct_math500_multi_scorer/runs/c35z6knc\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/offline_bon_qwen25_math_7b_instruct_math500_multi_scorer/runs/d7jh7cbj\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/offline_bon_qwen25_math_7b_instruct_math500_multi_scorer/runs/cz45vmb2\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MATH500_OFFLINE_BON_UHEAD_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/offline_bon_qwen25_math_7b_instruct_math500_uhead_vllm/workspace?nw=nwuserkarantonis\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/offline_bon_qwen25_math_7b_instruct_math500_uhead_vllm/runs/4l0rie0z?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MATH500_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_prm_window_all_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_prm_window_all_mean/runs/jhbjo8i7?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy/runs/xwne3zcp?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy/runs/i6h64mu9?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy/runs/q4irrx7s?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity/runs/j52otygf?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity/runs/2jxse47c?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity/runs/furt84c3?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob/runs/p81rd7g2?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob/runs/xzlye3bd?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob/runs/1gqrkkbz?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_all_mean/workspace?nw=nwuserkarantonis\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_all_mean/runs/3vyvg771?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_all_mean/runs/a403svwj?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_all_mean/runs/ym9gurc8?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "        # TODO: LLM_AS_A_CRITIC\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "        # TODO: UHEAD\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MATH500_BEAM_SEARCH_ALL_STEPS_MIN_RUNS = []\n",
    "\n",
    "MATH500_BEAM_SEARCH_5_STEPS_MEAN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_prm_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_prm_window_5_mean/runs/a5czzn30?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_prm_window_5_mean/runs/j93dcmm3?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy_window_5_mean/runs/ymsvscl0?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy_window_5_mean/runs/pwzb338g?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy_window_5_mean/runs/35flk5hs?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity_window_5_mean/runs/wyx5epvb?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity_window_5_mean/runs/6nvxalna?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity_window_5_mean/runs/cr02x91m?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob_window_5_mean/runs/sgz5baov?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob_window_5_mean/runs/3aal8hbt?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob_window_5_mean/runs/invmjf46?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_5_mean/runs/t9izflf2?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_5_mean/runs/jgwxu1tf?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_5_mean/runs/1hib1872?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: LLM_AS_A_CRITIC\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MATH500_BEAM_SEARCH_5_STEPS_MIN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_prm_window_5_min/workspace?nw=nwuserkarantonis\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_prm_window_5_min/runs/xsq5qs98?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_prm_window_5_min/runs/s5gopowo?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "{\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy_window_5_min/runs/s63imxgn?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy_window_5_min/runs/lboffbb6?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_entropy_window_5_min/runs/3ty4qabr?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity_window_5_min/runs/71lpyfud?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity_window_5_min/runs/jdneto0g?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_perplexity_window_5_min/runs/s704cw0h?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob_window_5_min/runs/i0k09agh?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob_window_5_min/runs/xk8esovp?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_sequence_prob_window_5_min/runs/w8p45jwz?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_5_min/runs/9krm0sgu?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_5_min/runs/z0sfyacp?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/beam_search_qwen25_math_7b_instruct_math500_pd_gap_window_5_min/runs/rxvhmt25?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: LLM_AS_A_CRITIC\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MATH500_BEAM_SEARCH_RUNS = [\n",
    "    # *MATH500_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS,\n",
    "    *MATH500_BEAM_SEARCH_ALL_STEPS_MIN_RUNS,\n",
    "    *MATH500_BEAM_SEARCH_5_STEPS_MEAN_RUNS,\n",
    "    *MATH500_BEAM_SEARCH_5_STEPS_MIN_RUNS,\n",
    "]\n",
    "\n",
    "MATH500_MUR_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_prm\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_prm/runs/vd5vmy7u\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_prm/runs/1a781e39\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_prm/runs/rj4rt3i2\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_entropy\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_entropy/runs/tfztdzjl\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_entropy/runs/ggqllnmy\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_entropy/runs/aw88mzyl\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_perplexity\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_perplexity/runs/r6oumz5s\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_perplexity/runs/4ds5ewag\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_perplexity/runs/5xe2x66l\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_sequence_prob\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_sequence_prob/runs/j9a1j7mx\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_sequence_prob/runs/zcdc7nni\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_sequence_prob/runs/otrelz7z\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_uncertainty_pd/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_uncertainty_pd/runs/alb267ge?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_uncertainty_pd/runs/csps436w?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-math500/groups/adaptive_scaling_qwen25_math_7b_instruct_math500_uncertainty_pd/runs/qdng2lkw?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: UHEAD\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MATH500_RUNS = [\n",
    "    *MATH500_BASELINE_RUNS,\n",
    "    *MATH500_SELF_CONSISTENCY_RUNS,\n",
    "    *MATH500_OFFLINE_BON_RUNS,\n",
    "    *MATH500_OFFLINE_BON_UHEAD_RUNS,\n",
    "    *MATH500_BEAM_SEARCH_RUNS,\n",
    "    *MATH500_MUR_RUNS,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"group_url\": \"\",\n",
    "    \"runs\": [\n",
    "        {\"seed\": 42, \"run_url\": \"\"},\n",
    "        {\"seed\": 43, \"run_url\": \"\"},\n",
    "        {\"seed\": 44, \"run_url\": \"\"},\n",
    "    ],\n",
    "},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── OlympiadBench ────────────────────────────────────────────────────────────\n",
    "\n",
    "OLYMPIAD_BASELINE_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/baseline_qwen25_math_7b_instruct_olympiadbench\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/baseline_qwen25_math_7b_instruct_olympiadbench/runs/jzmy8hfc\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/baseline_qwen25_math_7b_instruct_olympiadbench/runs/xlys9l9j\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/baseline_qwen25_math_7b_instruct_olympiadbench/runs/b72k2bg3\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "OLYMPIAD_SELF_CONSISTENCY_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/self_consistency_qwen25_math_7b_instruct_olympiadbench\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/self_consistency_qwen25_math_7b_instruct_olympiadbench/runs/fvfzlj30\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/self_consistency_qwen25_math_7b_instruct_olympiadbench/runs/ig5z868b\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/self_consistency_qwen25_math_7b_instruct_olympiadbench/runs/ivwtmfrj\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "OLYMPIAD_OFFLINE_BON_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/offline_bon_qwen25_math_7b_instruct_olympiadbench_multi_scorer\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/offline_bon_qwen25_math_7b_instruct_olympiadbench_multi_scorer/runs/scg2r5g6\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/offline_bon_qwen25_math_7b_instruct_olympiadbench_multi_scorer/runs/lrbsr0b6\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/offline_bon_qwen25_math_7b_instruct_olympiadbench_multi_scorer/runs/gzpylxq2\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "OLYMPIAD_OFFLINE_BON_UHEAD_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/offline_bon_qwen25_math_7b_instruct_olympiadbench_uhead_vllm/workspace?nw=nwuserkarantonis\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/offline_bon_qwen25_math_7b_instruct_olympiadbench_uhead_vllm/runs/bjfh6fuh?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "OLYMPIAD_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_prm_window_all_mean/workspace?nw=nwuserkarantonis\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_prm_window_all_mean/runs/gui7679t?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_entropy/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_entropy/runs/c6nirtgs?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_entropy/runs/tvpfucx4?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_entropy/runs/juur2mnv?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_perplexity/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_perplexity/runs/xnf5gmhd?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_perplexity/runs/ljtva92n?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_perplexity/runs/npatzl31?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_sequence_prob/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_sequence_prob/runs/g42a9xqq?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_sequence_prob/runs/o3mip5c4?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_sequence_prob/runs/c0jumd2j?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_pd_gap_window_all_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_pd_gap_window_all_mean/runs/50n5dhow?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_pd_gap_window_all_mean/runs/kpnzm4md?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_pd_gap_window_all_mean/runs/h69ak088?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: LLM_AS_A_CRITIC\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: UHEAD\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "OLYMPIAD_BEAM_SEARCH_ALL_STEPS_MIN_RUNS = []\n",
    "\n",
    "OLYMPIAD_BEAM_SEARCH_5_STEPS_MEAN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_prm_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_prm_window_5_mean/runs/887ddodl?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_prm_window_5_mean/runs/522b5ewj?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_entropy_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_entropy_window_5_mean/runs/erqi0w5r?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_entropy_window_5_mean/runs/qc0wn4q6?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_entropy_window_5_mean/runs/bpgur362?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_perplexity_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_perplexity_window_5_mean/runs/gb0mtnvx?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_perplexity_window_5_mean/runs/lgbztevg?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_perplexity_window_5_mean/runs/qod2k0j9?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_sequence_prob_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_sequence_prob_window_5_mean/runs/jnthrv56?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_sequence_prob_window_5_mean/runs/pw48cch0?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_sequence_prob_window_5_mean/runs/jilv4iwk?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_pd_gap_window_5_mean/workspace?nw=nwuserkarantonis\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_pd_gap_window_5_mean/runs/43r2f1wt?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_pd_gap_window_5_mean/runs/jq2jj0lf?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_pd_gap_window_5_mean/runs/fdzegtse?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: LLM_AS_A_CRITIC\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: UHEAD\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "OLYMPIAD_BEAM_SEARCH_5_STEPS_MIN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_prm_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_prm_window_5_min/runs/zqlktvg3?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_prm_window_5_min/runs/qozhgnye?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_entropy_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_entropy_window_5_min/runs/ygh7bxal?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_entropy_window_5_min/runs/6bqzf022?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_entropy_window_5_min/runs/pqo1b5f6?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_perplexity_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_perplexity_window_5_min/runs/nhi6skmj?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_perplexity_window_5_min/runs/piujnzhv?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_perplexity_window_5_min/runs/5u73qqas?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_sequence_prob_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_sequence_prob_window_5_min/runs/egbj74e1?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_sequence_prob_window_5_min/runs/h6v1qr2v?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_sequence_prob_window_5_min/runs/3auslh8z?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_pd_gap_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_pd_gap_window_5_min/runs/9j9zb1s8?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_pd_gap_window_5_min/runs/nrliz7lv?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/beam_search_qwen25_math_7b_instruct_olympiadbench_pd_gap_window_5_min/runs/85lk7n3t?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: LLM_AS_A_CRITIC\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: UHEAD\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "OLYMPIAD_BEAM_SEARCH_RUNS = [\n",
    "    *OLYMPIAD_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS,\n",
    "    *OLYMPIAD_BEAM_SEARCH_ALL_STEPS_MIN_RUNS,\n",
    "    *OLYMPIAD_BEAM_SEARCH_5_STEPS_MEAN_RUNS,\n",
    "    *OLYMPIAD_BEAM_SEARCH_5_STEPS_MIN_RUNS,\n",
    "]\n",
    "\n",
    "OLYMPIAD_MUR_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_prm\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_prm/runs/i6z1krhj\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_prm/runs/6wvon0ez\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_prm/runs/tdm1eork\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_entropy\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_entropy/runs/vd94h0mo\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_entropy/runs/wf7xwmeq\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_entropy/runs/mysyvdxk\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_perplexity\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_perplexity/runs/v94x4z5v\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_perplexity/runs/j0wpb22k\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_perplexity/runs/ma4yye4m\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_sequence_prob\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_sequence_prob/runs/9yrxl5jg\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_sequence_prob/runs/ux4lvczy\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_sequence_prob/runs/3i0vyyzt\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_uncertainty_pd/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_uncertainty_pd/runs/xcooiyeg?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_uncertainty_pd/runs/0h96fgd9?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-olympiadbench/groups/adaptive_scaling_qwen25_math_7b_instruct_olympiadbench_uncertainty_pd/runs/sysmud1n?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "OLYMPIAD_RUNS = [\n",
    "    *OLYMPIAD_BASELINE_RUNS,\n",
    "    *OLYMPIAD_SELF_CONSISTENCY_RUNS,\n",
    "    *OLYMPIAD_OFFLINE_BON_RUNS,\n",
    "    *OLYMPIAD_OFFLINE_BON_UHEAD_RUNS,\n",
    "    *OLYMPIAD_BEAM_SEARCH_RUNS,\n",
    "    *OLYMPIAD_MUR_RUNS,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Minerva Math ─────────────────────────────────────────────────────────────\n",
    "\n",
    "MINERVA_BASELINE_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/baseline_qwen25_math_7b_instruct_minerva_math\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/baseline_qwen25_math_7b_instruct_minerva_math/runs/96zj1bj9\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/baseline_qwen25_math_7b_instruct_minerva_math/runs/uyw4bmip\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/baseline_qwen25_math_7b_instruct_minerva_math/runs/qmm3t3wa\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MINERVA_SELF_CONSISTENCY_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/self_consistency_qwen25_math_7b_minerva_math\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/self_consistency_qwen25_math_7b_minerva_math/runs/pnfkhzub\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/self_consistency_qwen25_math_7b_minerva_math/runs/puabpgai\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/self_consistency_qwen25_math_7b_minerva_math/runs/697xpya5\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MINERVA_OFFLINE_BON_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/offline_bon_qwen25_math_7b_instruct_minerva_math_multi_scorer\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/offline_bon_qwen25_math_7b_instruct_minerva_math_multi_scorer/runs/7syo0ks4\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/offline_bon_qwen25_math_7b_instruct_minerva_math_multi_scorer/runs/y6udmktu\"},\n",
    "            # TODO: seed 44\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MINERVA_OFFLINE_BON_UHEAD_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MINERVA_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_prm_window_all_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_prm_window_all_mean/runs/snoxhz7b?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_entropy/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_entropy/runs/962poto8?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_entropy/runs/6s17gujf?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_entropy/runs/pf024sdv?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_perplexity/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_perplexity/runs/yt9mipkh?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_perplexity/runs/795b6z27?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_perplexity/runs/za5yp87g?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_sequence_prob/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_sequence_prob/runs/4q8i8qwa?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_sequence_prob/runs/retc9zoi?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_sequence_prob/runs/1fmcdnsh?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_pd_gap_window_all_mean/workspace?nw=nwuserkarantonis\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_pd_gap_window_all_mean/runs/zl7hftku?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_pd_gap_window_all_mean/runs/xu155a3m?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_pd_gap_window_all_mean/runs/e201qmog?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: LLM_AS_A_CRITIC\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: UHEAD\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MINERVA_BEAM_SEARCH_ALL_STEPS_MIN_RUNS = []\n",
    "\n",
    "MINERVA_BEAM_SEARCH_5_STEPS_MEAN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_prm_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_prm_window_5_mean/runs/j4fguv8x?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_entropy_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_entropy_window_5_mean/runs/wc2stpgz?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_entropy_window_5_mean/runs/t2jniehz?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_entropy_window_5_mean/runs/kcfrods7?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_perplexity_window_5_mean/workspace?nw=nwuserkarantonis\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_perplexity_window_5_mean/runs/hf1vxco1?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_perplexity_window_5_mean/runs/6y85bwv6?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_perplexity_window_5_mean/runs/wswknexj?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_sequence_prob_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_sequence_prob_window_5_mean/runs/b7g1qnn1?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_sequence_prob_window_5_mean/runs/ry44lrr9?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_sequence_prob_window_5_mean/runs/yqg5cn6j?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_pd_gap_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_pd_gap_window_5_mean/runs/xmcus55r?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_pd_gap_window_5_mean/runs/hvw2hvjr?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_pd_gap_window_5_mean/runs/nvehp4ya?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: LLM_AS_A_CRITIC\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: UHEAD\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MINERVA_BEAM_SEARCH_5_STEPS_MIN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_prm_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_prm_window_5_min/runs/vj9qje88?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_entropy_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_entropy_window_5_min/runs/xbxg75pr?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_entropy_window_5_min/runs/mu1d5ny2?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_entropy_window_5_min/runs/ku1zd1x8?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_perplexity_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_perplexity_window_5_min/runs/gq4xwrgy?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_perplexity_window_5_min/runs/ujdvj8w8?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_perplexity_window_5_min/runs/d7zsrmx3?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_sequence_prob_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_sequence_prob_window_5_min/runs/eninrzri?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_sequence_prob_window_5_min/runs/dkvyuo46?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_sequence_prob_window_5_min/runs/b106fzn7?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_pd_gap_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_pd_gap_window_5_min/runs/j2ahm5j6?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_pd_gap_window_5_min/runs/b1p9fcl8?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/beam_search_qwen25_math_7b_instruct_minerva_math_pd_gap_window_5_min/runs/5avu312g?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: LLM_AS_A_CRITIC\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: UHEAD\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MINERVA_BEAM_SEARCH_RUNS = [\n",
    "    *MINERVA_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS,\n",
    "    *MINERVA_BEAM_SEARCH_ALL_STEPS_MIN_RUNS,\n",
    "    *MINERVA_BEAM_SEARCH_5_STEPS_MEAN_RUNS,\n",
    "    *MINERVA_BEAM_SEARCH_5_STEPS_MIN_RUNS,\n",
    "]\n",
    "\n",
    "MINERVA_MUR_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_prm\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_prm/runs/06l86wmp\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_prm/runs/rj3c55xp\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva-math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_prm/runs/mqxinev9\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_entropy\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_entropy/runs/6x67bplt\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_entropy/runs/9byp8if5\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_entropy/runs/baw3autg\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_perplexity\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_perplexity/runs/fdqevqae\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_perplexity/runs/v9d5f19e\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_perplexity/runs/1kotu42g\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_sequence_prob\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_sequence_prob/runs/hhvycd8w\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_sequence_prob/runs/u9jsfizr\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_sequence_prob/runs/s1mch3ag\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_uncertainty_pd/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_uncertainty_pd/runs/u05a1i4m?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_uncertainty_pd/runs/vg6jcpn8?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-minerva_math/groups/adaptive_scaling_qwen25_math_7b_instruct_minerva_math_uncertainty_pd/runs/i6rpgyy0?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "MINERVA_RUNS = [\n",
    "    *MINERVA_BASELINE_RUNS,\n",
    "    *MINERVA_SELF_CONSISTENCY_RUNS,\n",
    "    *MINERVA_OFFLINE_BON_RUNS,\n",
    "    *MINERVA_OFFLINE_BON_UHEAD_RUNS,\n",
    "    *MINERVA_BEAM_SEARCH_RUNS,\n",
    "    *MINERVA_MUR_RUNS,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Gaokao 2023 EN ──────────────────────────────────────────────────────────\n",
    "\n",
    "GAOKAO_BASELINE_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/baseline_qwen25_math_7b_instruct_gaokao2023en\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/baseline_qwen25_math_7b_instruct_gaokao2023en/runs/kv4jtvgi\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/baseline_qwen25_math_7b_instruct_gaokao2023en/runs/oj4i6jcg\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/baseline_qwen25_math_7b_instruct_gaokao2023en/runs/9jdwpyk5\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "GAOKAO_SELF_CONSISTENCY_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/self_consistency_qwen25_math_7b_gaokao2023en\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/self_consistency_qwen25_math_7b_gaokao2023en/runs/fr4b84ia\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/self_consistency_qwen25_math_7b_gaokao2023en/runs/cbuxlxty\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/self_consistency_qwen25_math_7b_gaokao2023en/runs/66ny6wia\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "GAOKAO_OFFLINE_BON_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/offline_bon_qwen25_math_7b_instruct_gaokao2023en_multi_scorer\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/offline_bon_qwen25_math_7b_instruct_gaokao2023en_multi_scorer/runs/qijvr95c\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/offline_bon_qwen25_math_7b_instruct_gaokao2023en_multi_scorer/runs/jboxbdly\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/offline_bon_qwen25_math_7b_instruct_gaokao2023en_multi_scorer/runs/nh8fx6pk\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "GAOKAO_OFFLINE_BON_UHEAD_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/offline_bon_qwen25_math_7b_instruct_gaokao2023en_uhead_vllm/workspace?nw=nwuserkarantonis\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/offline_bon_qwen25_math_7b_instruct_gaokao2023en_uhead_vllm/runs/d8ghfxec?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "GAOKAO_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_prm_window_all_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_prm_window_all_mean/runs/8l7qf6cl?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_entropy/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_entropy/runs/kn00hw5t?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_entropy/runs/3xobx7ih?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_entropy/runs/9pdu6tur?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_perplexity/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_perplexity/runs/3o578w75?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_perplexity/runs/r4i8by0h?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_perplexity/runs/e2l89n6w?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_sequence_prob/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_sequence_prob/runs/fsd1tf66?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_sequence_prob/runs/163131v4?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_sequence_prob/runs/hp1hq4ff?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_pd_gap_window_all_mean/workspace?nw=nwuserkarantonis\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_pd_gap_window_all_mean/runs/jk68metq?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_pd_gap_window_all_mean/runs/cylhbr2h?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_pd_gap_window_all_mean/runs/ykypchxu?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: LLM_AS_A_CRITIC\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: UHEAD\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "GAOKAO_BEAM_SEARCH_ALL_STEPS_MIN_RUNS = []\n",
    "\n",
    "GAOKAO_BEAM_SEARCH_5_STEPS_MEAN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_prm_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_prm_window_5_mean/runs/1r6s9ry7?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_prm_window_5_mean/runs/8725k7ax?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_entropy_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_entropy_window_5_mean/runs/r3dru40w?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_entropy_window_5_mean/runs/jlvs82nj?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_entropy_window_5_mean/runs/p160naq9?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_perplexity_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_perplexity_window_5_mean/runs/9me7ishc?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_perplexity_window_5_mean/runs/o5cr0fzk?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_perplexity_window_5_mean/runs/cwq73748?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_sequence_prob_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_sequence_prob_window_5_mean/runs/1ou0luos?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_sequence_prob_window_5_mean/runs/dd3hr4mn?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_sequence_prob_window_5_mean/runs/5t8lox6l?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_pd_gap_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_pd_gap_window_5_mean/runs/05wxrqgd?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_pd_gap_window_5_mean/runs/piuuulyg?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_pd_gap_window_5_mean/runs/t8kw05ga?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: LLM_AS_A_CRITIC\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: UHEAD\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "GAOKAO_BEAM_SEARCH_5_STEPS_MIN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_prm_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_prm_window_5_min/runs/jtrfp35y?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_prm_window_5_min/runs/2u4v1zrn?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_entropy_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_entropy_window_5_min/runs/75zw5ooq?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_entropy_window_5_min/runs/ne22jlrg?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_entropy_window_5_min/runs/6h66d1po?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_perplexity_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_perplexity_window_5_min/runs/yn24c04k?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_perplexity_window_5_min/runs/lsfbd32c?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_perplexity_window_5_min/runs/9sdcszbf?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_sequence_prob_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_sequence_prob_window_5_min/runs/csx4i9xa?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_sequence_prob_window_5_min/runs/c7uiu5rq?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_sequence_prob_window_5_min/runs/s980hhyq?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_pd_gap_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_pd_gap_window_5_min/runs/vu34zpxx?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_pd_gap_window_5_min/runs/15es444b?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/beam_search_qwen25_math_7b_instruct_gaokao2023en_pd_gap_window_5_min/runs/td9u11e7?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: LLM_AS_A_CRITIC\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: UHEAD\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "GAOKAO_BEAM_SEARCH_RUNS = [\n",
    "    *GAOKAO_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS,\n",
    "    *GAOKAO_BEAM_SEARCH_ALL_STEPS_MIN_RUNS,\n",
    "    *GAOKAO_BEAM_SEARCH_5_STEPS_MEAN_RUNS,\n",
    "    *GAOKAO_BEAM_SEARCH_5_STEPS_MIN_RUNS,\n",
    "]\n",
    "\n",
    "\n",
    "GAOKAO_MUR_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_prm\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_prm/runs/s0fidl75\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_prm/runs/0ualpblk\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_prm/runs/32rg3g3i\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_entropy\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_entropy/runs/hi6vme52\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_entropy/runs/8803ke4z\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_entropy/runs/2b58rqn2\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_perplexity\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_perplexity/runs/nzfniz34?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_perplexity/runs/t72yerk9\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_perplexity/runs/udabjan5\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_sequence_prob\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_sequence_prob/runs/w39yrjlx\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_sequence_prob/runs/tg0re0ml\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_sequence_prob/runs/h8ceyznr\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_uncertainty_pd/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_uncertainty_pd/runs/cof8zdfa?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_uncertainty_pd/runs/fvfx85er?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-gaokao2023en/groups/adaptive_scaling_qwen25_math_7b_instruct_gaokao2023en_uncertainty_pd/runs/yx8s5z64?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "GAOKAO_RUNS = [\n",
    "    *GAOKAO_BASELINE_RUNS,\n",
    "    *GAOKAO_SELF_CONSISTENCY_RUNS,\n",
    "    *GAOKAO_OFFLINE_BON_RUNS,\n",
    "    *GAOKAO_OFFLINE_BON_UHEAD_RUNS,\n",
    "    *GAOKAO_BEAM_SEARCH_RUNS,\n",
    "    *GAOKAO_MUR_RUNS,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── GPQA Diamond ─────────────────────────────────────────────────────────────\n",
    "\n",
    "GPQA_BASELINE_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "GPQA_EXTENDED_THINKING_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "GPQA_SELF_CONSISTENCY_RUNS = [\n",
    "    {\"group_url\": \"\", \"runs\": []},\n",
    "]\n",
    "\n",
    "GPQA_OFFLINE_BON_RUNS = []\n",
    "\n",
    "GPQA_BEAM_SEARCH_RUNS = []\n",
    "\n",
    "GPQA_RUNS = [\n",
    "    *GPQA_BASELINE_RUNS,\n",
    "    *GPQA_EXTENDED_THINKING_RUNS,\n",
    "    *GPQA_SELF_CONSISTENCY_RUNS,\n",
    "    *GPQA_OFFLINE_BON_RUNS,\n",
    "    *GPQA_BEAM_SEARCH_RUNS,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── AIME 2024 ────────────────────────────────────────────────────────────────\n",
    "\n",
    "AIME_24_BASELINE_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/baseline_qwen3_8b_thinking_aime2024\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/baseline_qwen3_8b_thinking_aime2024/runs/xusm290p\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/baseline_qwen3_8b_thinking_aime2024/runs/rb5f45zd\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/baseline_qwen3_8b_thinking_aime2024/runs/ue7upatj\"},\n",
    "            {\"seed\": 45, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/baseline_qwen3_8b_thinking_aime2024/runs/2pxd5k62\"},\n",
    "            {\"seed\": 46, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/baseline_qwen3_8b_thinking_aime2024/runs/7wjepb0g\"},\n",
    "            {\"seed\": 47, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/baseline_qwen3_8b_thinking_aime2024/runs/mmvefyvq\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "AIME_24_EXTENDED_THINKING_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/extended_thinking_qwen3_8b_thinking_aime2024\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/extended_thinking_qwen3_8b_thinking_aime2024/runs/zpdp973a\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/extended_thinking_qwen3_8b_thinking_aime2024/runs/toj7if32\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/extended_thinking_qwen3_8b_thinking_aime2024/runs/nofu424d\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "AIME_24_SELF_CONSISTENCY_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/self_consistency_qwen3_8b_thinking_aime2024\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/self_consistency_qwen3_8b_thinking_aime2024/runs/myd2mv7s\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/self_consistency_qwen3_8b_thinking_aime2024/runs/xffzht86\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/self_consistency_qwen3_8b_thinking_aime2024/runs/1pwqvj98\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "AIME_24_OFFLINE_BON_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/offline_bon_qwen3_8b_thinking_aime2024_multi_scorer\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/offline_bon_qwen3_8b_thinking_aime2024_multi_scorer/runs/sx8686xk?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/offline_bon_qwen3_8b_thinking_aime2024_multi_scorer/runs/yma1zbec?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/offline_bon_qwen3_8b_thinking_aime2024_multi_scorer/runs/jrvn9z5v?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "{\n",
    "    \"group_url\": \"\",\n",
    "    \"runs\": [\n",
    "        {\"seed\": 42, \"run_url\": \"\"},\n",
    "        {\"seed\": 43, \"run_url\": \"\"},\n",
    "        {\"seed\": 44, \"run_url\": \"\"},\n",
    "    ],\n",
    "},\n",
    "\n",
    "AIME_24_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS = [\n",
    "    # TODO\n",
    "]\n",
    "\n",
    "AIME_24_BEAM_SEARCH_ALL_STEPS_MIN_RUNS = [\n",
    "    # TODO\n",
    "]\n",
    "\n",
    "AIME_24_BEAM_SEARCH_5_STEPS_MEAN_RUNS = [\n",
    "    # TODO\n",
    "]\n",
    "\n",
    "AIME_24_BEAM_SEARCH_5_STEPS_MIN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/beam_search_qwen3_8b_thinking_aime2024_prm_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/beam_search_qwen3_8b_thinking_aime2024_prm_window_5_min/runs/efg8ecwr?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/beam_search_qwen3_8b_thinking_aime2024_prm_window_5_min/runs/aqnb3zq1?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/beam_search_qwen3_8b_thinking_aime2024_prm_window_5_min/runs/oyhmkas7?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/beam_search_qwen3_8b_thinking_aime2024_entropy_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/beam_search_qwen3_8b_thinking_aime2024_entropy_window_5_min/runs/0wbteyc1?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/beam_search_qwen3_8b_thinking_aime2024_entropy_window_5_min/runs/vchbohcx?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/beam_search_qwen3_8b_thinking_aime2024_entropy_window_5_min/runs/qezpea3j?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/beam_search_qwen3_8b_thinking_aime2024_perplexity_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/beam_search_qwen3_8b_thinking_aime2024_perplexity_window_5_min/runs/9n2x29ps?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/beam_search_qwen3_8b_thinking_aime2024_perplexity_window_5_min/runs/7xincnfz?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/beam_search_qwen3_8b_thinking_aime2024_perplexity_window_5_min/runs/ezyltca8?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/beam_search_qwen3_8b_thinking_aime2024_sequence_prob_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/beam_search_qwen3_8b_thinking_aime2024_sequence_prob_window_5_min/runs/8vgy2ikx?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/beam_search_qwen3_8b_thinking_aime2024_sequence_prob_window_5_min/runs/6d681pee?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/beam_search_qwen3_8b_thinking_aime2024_sequence_prob_window_5_min/runs/6b5viy72?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/beam_search_qwen3_8b_thinking_aime2024_pd_gap_window_5_min/workspace?nw=nwuserkarantonis\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/beam_search_qwen3_8b_thinking_aime2024_pd_gap_window_5_min/runs/hbdy4fcn?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/beam_search_qwen3_8b_thinking_aime2024_pd_gap_window_5_min/runs/4uuttpo2?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/beam_search_qwen3_8b_thinking_aime2024_pd_gap_window_5_min/runs/8tdyfcry?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: LLM_AS_A_CRITIC\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: UHEAD\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "AIME_24_BEAM_SEARCH_RUNS = [\n",
    "    *AIME_24_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS,\n",
    "    *AIME_24_BEAM_SEARCH_ALL_STEPS_MIN_RUNS,\n",
    "    *AIME_24_BEAM_SEARCH_5_STEPS_MEAN_RUNS,\n",
    "    *AIME_24_BEAM_SEARCH_5_STEPS_MIN_RUNS,\n",
    "]\n",
    "\n",
    "AIME_24_MUR_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_prm\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_prm/runs/it11687o\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_prm/runs/jff7wjvc\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_prm/runs/lkq82tbw\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_entropy\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_entropy/runs/0e8v1y8k\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_entropy/runs/0ohmk93u\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_entropy/runs/r3835jcu\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_perplexity/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_perplexity/runs/6akbzucw\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_perplexity/runs/mqw6z61b\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_perplexity/runs/27slpoyj\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_sequence_prob\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_sequence_prob/runs/siootyv4\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_sequence_prob/runs/pbeoa8wj\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2024/groups/adaptive_scaling_qwen3_8b_aime2024_sequence_prob/runs/ehlo2jyt\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime24/groups/adaptive_scaling_qwen3_8b_aime2024_uncertainty_pd/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime24/groups/adaptive_scaling_qwen3_8b_aime2024_uncertainty_pd/runs/ogtic3r3?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime24/groups/adaptive_scaling_qwen3_8b_aime2024_uncertainty_pd/runs/l8o7jyti?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime24/groups/adaptive_scaling_qwen3_8b_aime2024_uncertainty_pd/runs/q81qvm2k?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "AIME_24_RUNS = [\n",
    "    *AIME_24_BASELINE_RUNS,\n",
    "    *AIME_24_EXTENDED_THINKING_RUNS,\n",
    "    *AIME_24_SELF_CONSISTENCY_RUNS,\n",
    "    *AIME_24_OFFLINE_BON_RUNS,\n",
    "    *AIME_24_BEAM_SEARCH_RUNS,\n",
    "    *AIME_24_MUR_RUNS,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── AIME 2025 ────────────────────────────────────────────────────────────────\n",
    "\n",
    "AIME_25_BASELINE_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/baseline_qwen3_8b_thinking_aime2025\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/baseline_qwen3_8b_thinking_aime2025/runs/5z4xazfd\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/baseline_qwen3_8b_thinking_aime2025/runs/z8961dmg\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/baseline_qwen3_8b_thinking_aime2025/runs/vqkeqd8l\"},\n",
    "            {\"seed\": 45, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/baseline_qwen3_8b_thinking_aime2025/runs/8ng35cm8\"},\n",
    "            {\"seed\": 46, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/baseline_qwen3_8b_thinking_aime2025/runs/y6l7gl0x\"},\n",
    "            {\"seed\": 47, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/baseline_qwen3_8b_thinking_aime2025/runs/bvz1mgw4\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "AIME_25_EXTENDED_THINKING_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/extended_thinking_qwen3_8b_thinking_aime2025\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/extended_thinking_qwen3_8b_thinking_aime2025/runs/ynjskyb9\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/extended_thinking_qwen3_8b_thinking_aime2025/runs/xw5oie56\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/extended_thinking_qwen3_8b_thinking_aime2025/runs/uufgljky\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "AIME_25_SELF_CONSISTENCY_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/self_consistency_qwen3_8b_thinking_aime2025/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/self_consistency_qwen3_8b_thinking_aime2025/runs/e03jj1df\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/self_consistency_qwen3_8b_thinking_aime2025/runs/4o5fp278\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/self_consistency_qwen3_8b_thinking_aime2025/runs/yvpwgde3\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "AIME_25_OFFLINE_BON_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/offline_bon_qwen3_8b_thinking_aime2025_multi_scorer\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/offline_bon_qwen3_8b_thinking_aime2025_multi_scorer/runs/1cwevp55\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/offline_bon_qwen3_8b_thinking_aime2025_multi_scorer/runs/ahbar3j1\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/offline_bon_qwen3_8b_thinking_aime2025_multi_scorer/runs/rj0hw4tp\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "{\n",
    "    \"group_url\": \"\",\n",
    "    \"runs\": [\n",
    "        {\"seed\": 42, \"run_url\": \"\"},\n",
    "        {\"seed\": 43, \"run_url\": \"\"},\n",
    "        {\"seed\": 44, \"run_url\": \"\"},\n",
    "    ],\n",
    "},\n",
    "\n",
    "AIME_25_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS = [\n",
    "    # TODO\n",
    "]\n",
    "\n",
    "AIME_25_BEAM_SEARCH_ALL_STEPS_MIN_RUNS = [\n",
    "    # TODO\n",
    "]\n",
    "\n",
    "AIME_25_BEAM_SEARCH_5_STEPS_MEAN_RUNS = [\n",
    "    # TODO\n",
    "]\n",
    "\n",
    "AIME_25_BEAM_SEARCH_5_STEPS_MIN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/beam_search_qwen3_8b_thinking_aime2025_prm_window_5_min/workspace?nw=nwuserkarantonis\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/beam_search_qwen3_8b_thinking_aime2025_prm_window_5_min/runs/ywizo975?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/beam_search_qwen3_8b_thinking_aime2025_prm_window_5_min/runs/czvdxny7?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/beam_search_qwen3_8b_thinking_aime2025_prm_window_5_min/runs/o492bbgp?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/beam_search_qwen3_8b_thinking_aime2025_entropy_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/beam_search_qwen3_8b_thinking_aime2025_entropy_window_5_min/runs/lb0vi3qq?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/beam_search_qwen3_8b_thinking_aime2025_entropy_window_5_min/runs/kjwuwim7?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/beam_search_qwen3_8b_thinking_aime2025_entropy_window_5_min/runs/utufdnzh?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/beam_search_qwen3_8b_thinking_aime2025_perplexity_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/beam_search_qwen3_8b_thinking_aime2025_perplexity_window_5_min/runs/awws51rg?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/beam_search_qwen3_8b_thinking_aime2025_perplexity_window_5_min/runs/qa0rie01?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/beam_search_qwen3_8b_thinking_aime2025_perplexity_window_5_min/runs/yhhex0za?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/beam_search_qwen3_8b_thinking_aime2025_sequence_prob_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/beam_search_qwen3_8b_thinking_aime2025_sequence_prob_window_5_min/runs/mi125juu?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/beam_search_qwen3_8b_thinking_aime2025_sequence_prob_window_5_min/runs/7drttyjt?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/beam_search_qwen3_8b_thinking_aime2025_sequence_prob_window_5_min/runs/0fsfajui?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/beam_search_qwen3_8b_thinking_aime2025_pd_gap_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/beam_search_qwen3_8b_thinking_aime2025_pd_gap_window_5_min/runs/ohpmnuco?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/beam_search_qwen3_8b_thinking_aime2025_pd_gap_window_5_min/runs/j5m8fw00?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025/groups/beam_search_qwen3_8b_thinking_aime2025_pd_gap_window_5_min/runs/7g1zrrcp?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: LLM_AS_A_CRITIC\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: UHEAD\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "AIME_25_BEAM_SEARCH_RUNS = [\n",
    "    *AIME_25_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS,\n",
    "    *AIME_25_BEAM_SEARCH_ALL_STEPS_MIN_RUNS,\n",
    "    *AIME_25_BEAM_SEARCH_5_STEPS_MEAN_RUNS,\n",
    "    *AIME_25_BEAM_SEARCH_5_STEPS_MIN_RUNS,\n",
    "]\n",
    "\n",
    "AIME_25_MUR_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_thinking_qwen3_8b_aime2025_prm/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_thinking_qwen3_8b_aime2025_prm/runs/e42u6g0w\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_thinking_qwen3_8b_aime2025_prm/runs/3nne68cg\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_thinking_qwen3_8b_aime2025_prm/runs/upxrnkxo\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_entropy\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_entropy/runs/d8m88x5o\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_entropy/runs/hor6ahou\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_entropy/runs/exlootac\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_thinking_qwen3_8b_aime2025_perplexity\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_thinking_qwen3_8b_aime2025_perplexity/runs/3hsaelln\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_thinking_qwen3_8b_aime2025_perplexity/runs/jertvzag\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_thinking_qwen3_8b_aime2025_perplexity/runs/8o0wi4y3\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_sequence_prob\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_sequence_prob/runs/tce8t6fy\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_sequence_prob/runs/krs5db1u\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_sequence_prob/runs/1ieu2i5k\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_pd_gap/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_pd_gap/runs/8xyihgpg?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_pd_gap/runs/pjd975tp?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-eval-aime25/groups/adaptive_scaling_qwen3_8b_aime2025_pd_gap/runs/8tfhs5vs?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "AIME_25_RUNS = [\n",
    "    *AIME_25_BASELINE_RUNS,\n",
    "    *AIME_25_EXTENDED_THINKING_RUNS,\n",
    "    *AIME_25_SELF_CONSISTENCY_RUNS,\n",
    "    *AIME_25_OFFLINE_BON_RUNS,\n",
    "    *AIME_25_BEAM_SEARCH_RUNS,\n",
    "    *AIME_25_MUR_RUNS,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── HumanEval-Plus ────────────────────────────────────────────────────────────\n",
    "\n",
    "[\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "HUMANEVAL_BASELINE_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/baseline_vllm_qwen3_8b_human_eval_plus/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 0, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/baseline_vllm_qwen3_8b_human_eval_plus/runs/qzbpq9t0?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 1, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/baseline_vllm_qwen3_8b_human_eval_plus/runs/h770ka3u?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/baseline_vllm_qwen3_8b_human_eval_plus/runs/p140hiwl?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "HUMANEVAL_EXTENDED_THINKING_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/extended_thinking_qwen3_8b_thinking_human_eval_plus/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/extended_thinking_qwen3_8b_thinking_human_eval_plus/runs/lnysauwr?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/extended_thinking_qwen3_8b_thinking_human_eval_plus/runs/rco0ur3e?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/extended_thinking_qwen3_8b_thinking_human_eval_plus/runs/g8zegkd1?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "HUMANEVAL_SELF_CONSISTENCY_RUNS = []\n",
    "\n",
    "HUMANEVAL_OFFLINE_BON_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/offline_bon_qwen3_8b_thinking_human_eval_plus_multi_scorer/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/offline_bon_qwen3_8b_thinking_human_eval_plus_multi_scorer/runs/z6vgbfcb?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/offline_bon_qwen3_8b_thinking_human_eval_plus_multi_scorer/runs/gij2g92w?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/offline_bon_qwen3_8b_thinking_human_eval_plus_multi_scorer/runs/hoitoy74?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "HUMANEVAL_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_entropy_window_all_mean/workspace?nw=nwuserkarantonis\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_entropy_window_all_mean/runs/iidhfsiz?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_perplexity_window_all_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_perplexity_window_all_mean/runs/uvbw2kl5?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_sequence_prob_window_all_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_sequence_prob_window_all_mean/runs/e3a0rcup?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_pd_gap_window_all_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_pd_gap_window_all_mean/runs/7pzh9edt?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: LLM_AS_A_CRITIC\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: UHEAD\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "HUMANEVAL_BEAM_SEARCH_ALL_STEPS_MIN_RUNS = [\n",
    "    {\n",
    "        # TODO: add prm\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_entropy_window_all_min/workspace?nw=nwusertsowehh\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_entropy_window_all_min/runs/a9s20fwf?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_perplexity_window_all_min/workspace?nw=nwusertsowehh\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_perplexity_window_all_min/runs/48wc71cj?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_sequence_prob_window_all_min/workspace?nw=nwusertsowehh\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_sequence_prob_window_all_min/runs/su5e8s4i?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_pd_gap_window_all_min/workspace?nw=nwusertsowehh\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_pd_gap_window_all_min/runs/xsb1hp9g?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: LLM_AS_A_CRITIC\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: UHEAD\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "HUMANEVAL_BEAM_SEARCH_5_STEPS_MEAN_RUNS = [\n",
    "    {\n",
    "        # TODO: add prm\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_entropy_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_entropy_window_5_mean/runs/jwnf1dsb?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_perplexity_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_perplexity_window_5_mean/runs/0c7179qy?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_sequence_prob_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_sequence_prob_window_5_mean/runs/9ig7966n?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_pd_gap_window_5_mean/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_pd_gap_window_5_mean/runs/r0mics7n?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: LLM_AS_A_CRITIC\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: UHEAD\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "HUMANEVAL_BEAM_SEARCH_5_STEPS_MIN_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_prm_window_5_min/workspace?nw=nwusertsowehh\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_prm_window_5_min/runs/mwv3ydot?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_prm_window_5_min/runs/diqjyser?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_prm_window_5_min/runs/vuu8s1u9?nw=nwusertsowehh\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_entropy_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_entropy_window_5_min/runs/wp534gi0?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_entropy_window_5_min/runs/u69i5npi?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_entropy_window_5_min/runs/niswh0x4?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_perplexity_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_perplexity_window_5_min/runs/6p6w68ul?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 43, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_perplexity_window_5_min/runs/4g46bojf?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 44, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_perplexity_window_5_min/runs/4vo3nvau?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_sequence_prob_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_sequence_prob_window_5_min/runs/yui20oq0?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 1, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_sequence_prob_window_5_min/runs/hkqix9z9?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 2, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_sequence_prob_window_5_min/runs/yjnynyg8?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_pd_gap_window_5_min/workspace\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_pd_gap_window_5_min/runs/w72n3060?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 1, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_pd_gap_window_5_min/runs/oi9zfd3c?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 2, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/beam_search_qwen3_8b_thinking_human_eval_plus_pd_gap_window_5_min/runs/c4bjiwrf?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: LLM_AS_A_CRITIC\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: UHEAD\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "HUMANEVAL_BEAM_SEARCH_RUNS = [\n",
    "    *HUMANEVAL_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS,\n",
    "    *HUMANEVAL_BEAM_SEARCH_ALL_STEPS_MIN_RUNS,\n",
    "    *HUMANEVAL_BEAM_SEARCH_5_STEPS_MEAN_RUNS,\n",
    "    *HUMANEVAL_BEAM_SEARCH_5_STEPS_MIN_RUNS,\n",
    "]\n",
    "\n",
    "HUMANEVAL_MUR_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/adaptive_scaling_vllm_qwen3_8b_human_eval_plus_prm/workspace?nw=nwusertsowehh\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 0, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/adaptive_scaling_vllm_qwen3_8b_human_eval_plus_prm/runs/axsgb0lp?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 1, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/adaptive_scaling_vllm_qwen3_8b_human_eval_plus_prm/runs/sq0dlul0?nw=nwuserkarantonis\"},\n",
    "            {\"seed\": 2, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/adaptive_scaling_vllm_qwen3_8b_human_eval_plus_prm/runs/2218589y?nw=nwuserkarantonis\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/adaptive_scaling_vllm_qwen3_8b_human_eval_plus_entropy/workspace?nw=nwusertsowehh\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 0, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/adaptive_scaling_vllm_qwen3_8b_human_eval_plus_entropy/runs/4g5ugn1v?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 1, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/adaptive_scaling_vllm_qwen3_8b_human_eval_plus_entropy/runs/3d4dfaib?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 2, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/adaptive_scaling_vllm_qwen3_8b_human_eval_plus_entropy/runs/pddw65g8?nw=nwusertsowehh\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/adaptive_scaling_vllm_qwen3_8b_human_eval_plus_perplexity/workspace?nw=nwusertsowehh\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 0, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/adaptive_scaling_vllm_qwen3_8b_human_eval_plus_perplexity/runs/8empwbo4?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 1, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/adaptive_scaling_vllm_qwen3_8b_human_eval_plus_perplexity/runs/t3w67irm?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 2, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/adaptive_scaling_vllm_qwen3_8b_human_eval_plus_perplexity/runs/19mq91wj?nw=nwusertsowehh\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/adaptive_scaling_vllm_qwen3_8b_human_eval_plus_sequence_prob/workspace?nw=nwusertsowehh\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 0, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/adaptive_scaling_vllm_qwen3_8b_human_eval_plus_sequence_prob/runs/hgp1pfn6?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 1, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/adaptive_scaling_vllm_qwen3_8b_human_eval_plus_sequence_prob/runs/uorbvzui?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 2, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/adaptive_scaling_vllm_qwen3_8b_human_eval_plus_sequence_prob/runs/af7aitxx?nw=nwusertsowehh\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: PD Gap\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/adaptive_scaling_vllm_qwen3_8b_human_eval_plus_pd_gap/workspace?nw=nwusertsowehh\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 0, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/adaptive_scaling_vllm_qwen3_8b_human_eval_plus_pd_gap/runs/2msp2y82?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 1, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/adaptive_scaling_vllm_qwen3_8b_human_eval_plus_pd_gap/runs/05gsk86b?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 2, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/adaptive_scaling_vllm_qwen3_8b_human_eval_plus_pd_gap/runs/6kxvjp71?nw=nwusertsowehh\"},\n",
    "        ],\n",
    "    },\n",
    "    # TODO: UHEAD\n",
    "    {\n",
    "        \"group_url\": \"\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 42, \"run_url\": \"\"},\n",
    "            {\"seed\": 43, \"run_url\": \"\"},\n",
    "            {\"seed\": 44, \"run_url\": \"\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "HUMANEVAL_UNCERT_COT_RUNS = [\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/uncert_cot_vllm_qwen3_8b_human_eval_plus_uncertainty_pd_token/workspace?nw=nwusertsowehh\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 0, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/uncert_cot_vllm_qwen3_8b_human_eval_plus_uncertainty_pd_token/runs/6fgi9n09?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 1, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/uncert_cot_vllm_qwen3_8b_human_eval_plus_uncertainty_pd_token/runs/gnn7ahby?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 2, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/uncert_cot_vllm_qwen3_8b_human_eval_plus_uncertainty_pd_token/runs/wqs9v6ae?nw=nwusertsowehh\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/uncert_cot_vllm_qwen3_8b_human_eval_plus_uncertainty_pd_sequence/workspace?nw=nwusertsowehh\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 0, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/uncert_cot_vllm_qwen3_8b_human_eval_plus_uncertainty_pd_sequence/runs/e7ctq9st?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 1, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/uncert_cot_vllm_qwen3_8b_human_eval_plus_uncertainty_pd_sequence/runs/ip36uwc1?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 2, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/uncert_cot_vllm_qwen3_8b_human_eval_plus_uncertainty_pd_sequence/runs/vuhbms4x?nw=nwusertsowehh\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"google.com/url?q=https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/uncert_cot_vllm_qwen3_8b_human_eval_plus_entropy_token/workspace?nw%3Dnwusertsowehh&sa=D&source=editors&ust=1772036156047322&usg=AOvVaw26Cbh70Rj96_KcWeFRONGm\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 0, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/uncert_cot_vllm_qwen3_8b_human_eval_plus_entropy_token/runs/010jjrzq?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 1, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/uncert_cot_vllm_qwen3_8b_human_eval_plus_entropy_token/runs/513w9284?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 2, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/uncert_cot_vllm_qwen3_8b_human_eval_plus_entropy_token/runs/1kn618b3?nw=nwusertsowehh\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"group_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/uncert_cot_vllm_qwen3_8b_human_eval_plus_entropy_sequence/workspace?nw=nwusertsowehh\",\n",
    "        \"runs\": [\n",
    "            {\"seed\": 0, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/uncert_cot_vllm_qwen3_8b_human_eval_plus_entropy_sequence/runs/ztolj97l?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 1, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/uncert_cot_vllm_qwen3_8b_human_eval_plus_entropy_sequence/runs/5uwi8jld?nw=nwusertsowehh\"},\n",
    "            {\"seed\": 2, \"run_url\": \"https://wandb.ai/nlpresearch.group/llm-tts-human-eval-plus/groups/uncert_cot_vllm_qwen3_8b_human_eval_plus_entropy_sequence/runs/8x8numy8?nw=nwusertsowehh\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "HUMANEVAL_RUNS = [\n",
    "    *HUMANEVAL_BASELINE_RUNS,\n",
    "    *HUMANEVAL_EXTENDED_THINKING_RUNS,\n",
    "    *HUMANEVAL_OFFLINE_BON_RUNS,\n",
    "    *HUMANEVAL_BEAM_SEARCH_RUNS,\n",
    "    *HUMANEVAL_MUR_RUNS,\n",
    "    *HUMANEVAL_UNCERT_COT_RUNS,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── All experiments ──────────────────────────────────────────────────────────\n",
    "\n",
    "EXPERIMENT_RUNS = [\n",
    "    *MATH500_RUNS,\n",
    "    *MINERVA_RUNS,\n",
    "    *GAOKAO_RUNS,\n",
    "    *OLYMPIAD_RUNS,\n",
    "    *GPQA_RUNS,\n",
    "    *AIME_24_RUNS,\n",
    "    *AIME_25_RUNS,\n",
    "    *HUMANEVAL_RUNS,\n",
    "]\n",
    "\n",
    "# Which evaluator metric to use as the primary accuracy column\n",
    "PRIMARY_EVALUATOR = \"exact_match\"  # or \"llm_judge\"\n",
    "\n",
    "GROUP_FILTERS = None  # e.g. [\"beam_search\", \"offline_bon\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed Coverage Tables\n",
    "\n",
    "Quick overview of how many seeds (1/2/3) are registered for each (strategy, scorer, dataset) combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Seed Coverage: Qwen2.5-Math-7B-Instruct (Non-Thinking) ─────────────────\n",
    "\n",
    "import re as _re\n",
    "from urllib.parse import urlparse as _urlparse\n",
    "\n",
    "\n",
    "def _extract_scorer_from_group_url(url: str) -> str:\n",
    "    \"\"\"Extract scorer name from group URL group segment (after /groups/).\"\"\"\n",
    "    path = _urlparse(url).path.strip(\"/\")\n",
    "    parts = path.split(\"/\")\n",
    "    # Take the segment right after 'groups/' — ignores trailing /workspace etc.\n",
    "    try:\n",
    "        group = parts[parts.index(\"groups\") + 1]\n",
    "    except (ValueError, IndexError):\n",
    "        group = parts[-1]\n",
    "    # Check longest names first to avoid partial matches\n",
    "    # uncertainty_pd is an alias for pd_gap\n",
    "    group = group.replace(\"uncertainty_pd\", \"pd_gap\")\n",
    "    for scorer in [\"sequence_prob\", \"llm_critic\", \"multi_scorer\",\n",
    "                   \"pd_gap\", \"prm\", \"entropy\", \"perplexity\", \"uhead\"]:\n",
    "        if group.endswith(f\"_{scorer}\") or f\"_{scorer}_\" in group:\n",
    "            return scorer\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def _count_seeds_with_url(run_list: list) -> tuple:\n",
    "    \"\"\"Count total seeds and return group URL. Returns (count, url).\"\"\"\n",
    "    total = 0\n",
    "    url = \"\"\n",
    "    for entry in run_list:\n",
    "        if entry.get(\"group_url\"):\n",
    "            total += sum(1 for r in entry.get(\"runs\", []) if r.get(\"run_url\"))\n",
    "            if not url:\n",
    "                url = entry[\"group_url\"]\n",
    "    return total, url\n",
    "\n",
    "\n",
    "def _derive_group_url(entry: dict) -> str:\n",
    "    \"\"\"Get group_url from entry, falling back to deriving it from a run_url.\"\"\"\n",
    "    if entry.get(\"group_url\"):\n",
    "        return entry[\"group_url\"]\n",
    "    for run in entry.get(\"runs\", []):\n",
    "        url = run.get(\"run_url\", \"\")\n",
    "        if url and \"/groups/\" in url:\n",
    "            # Reconstruct a group URL from the run URL\n",
    "            # run_url: https://host/entity/project/groups/GROUP/runs/ID\n",
    "            parts = url.split(\"/runs/\")\n",
    "            return parts[0]  # everything up to /runs/RUN_ID\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def _count_seeds_by_scorer_with_url(run_list: list) -> dict:\n",
    "    \"\"\"Count seeds per scorer with group URLs. Returns {scorer: (count, url)}.\"\"\"\n",
    "    result = {}\n",
    "    for entry in run_list:\n",
    "        group_url = _derive_group_url(entry)\n",
    "        if not group_url:\n",
    "            continue\n",
    "        scorer = _extract_scorer_from_group_url(group_url)\n",
    "        n = sum(1 for r in entry.get(\"runs\", []) if r.get(\"run_url\"))\n",
    "        result[scorer] = (n, group_url)\n",
    "    return result\n",
    "\n",
    "\n",
    "def _color_cell(n_seeds, url=\"\"):\n",
    "    \"\"\"Return styled HTML for seed count, optionally as a clickable link.\"\"\"\n",
    "    colors = {0: \"#e74c3c\", 1: \"#e67e22\", 2: \"#f1c40f\", 3: \"#27ae60\"}\n",
    "    bg = {0: \"#fdedec\", 1: \"#fdebd0\", 2: \"#fef9e7\", 3: \"#eafaf1\"}\n",
    "    style = (\n",
    "        f'background:{bg.get(n_seeds, \"#eee\")};'\n",
    "        f'padding:2px 8px;border-radius:3px;'\n",
    "        f'color:{colors.get(n_seeds, \"#333\")};font-weight:bold'\n",
    "    )\n",
    "    if url:\n",
    "        return (\n",
    "            f'<a href=\"{url}\" target=\"_blank\" '\n",
    "            f'style=\"{style};text-decoration:none\">{n_seeds}</a>'\n",
    "        )\n",
    "    return f'<span style=\"{style}\">{n_seeds}</span>'\n",
    "\n",
    "\n",
    "def build_coverage_table(title, coverage_map, datasets, strategy_order, strategy_labels,\n",
    "                         multi_scorer_strategies=None, scorer_list=None,\n",
    "                         scorer_overrides=None):\n",
    "    \"\"\"Build an HTML coverage table with rowspan-merged strategy cells.\n",
    "\n",
    "    Args:\n",
    "        title: Table heading.\n",
    "        coverage_map: {dataset: {strategy_key: run_list, ...}, ...}\n",
    "        datasets: Column order for datasets.\n",
    "        strategy_order: Row order for strategies.\n",
    "        strategy_labels: {strategy_key: display_name}\n",
    "        multi_scorer_strategies: Set of strategy keys that have per-scorer breakdowns.\n",
    "        scorer_list: Ordered list of scorers for multi-scorer strategies.\n",
    "    \"\"\"\n",
    "    if multi_scorer_strategies is None:\n",
    "        multi_scorer_strategies = set()\n",
    "    if scorer_list is None:\n",
    "        scorer_list = [\"prm\", \"entropy\", \"perplexity\", \"sequence_prob\", \"pd_gap\"]\n",
    "    if scorer_overrides is None:\n",
    "        scorer_overrides = {}\n",
    "\n",
    "    # Build row specs: list of (strategy_label, scorer, {ds: (count, url)})\n",
    "    row_specs = []\n",
    "    for strat in strategy_order:\n",
    "        label = strategy_labels.get(strat, strat)\n",
    "        if strat in multi_scorer_strategies:\n",
    "            for scorer in scorer_overrides.get(strat, scorer_list):\n",
    "                cells = {}\n",
    "                for ds in datasets:\n",
    "                    by_scorer = _count_seeds_by_scorer_with_url(coverage_map[ds][strat])\n",
    "                    cells[ds] = by_scorer.get(scorer, (0, \"\"))\n",
    "                row_specs.append((label, scorer, cells))\n",
    "        else:\n",
    "            cells = {}\n",
    "            for ds in datasets:\n",
    "                cells[ds] = _count_seeds_with_url(coverage_map[ds][strat])\n",
    "            row_specs.append((label, \"\", cells))\n",
    "\n",
    "    # Compute rowspans per strategy group\n",
    "    from collections import Counter\n",
    "    strategy_counts = Counter(r[0] for r in row_specs)\n",
    "\n",
    "    th = 'style=\"padding:6px 12px;border-bottom:2px solid #333;text-align:center\"'\n",
    "    html = f\"<h3>{title}</h3>\"\n",
    "    html += '<table style=\"border-collapse:collapse;font-family:sans-serif;font-size:14px\">'\n",
    "    html += f\"<tr><th {th}>Strategy</th><th {th}>Scorer</th>\"\n",
    "    for ds in datasets:\n",
    "        html += f\"<th {th}>{ds}</th>\"\n",
    "    html += \"</tr>\"\n",
    "\n",
    "    seen_strategies = set()\n",
    "    for label, scorer, cells in row_specs:\n",
    "        first_in_group = label not in seen_strategies\n",
    "        border = \"border-top:1px solid #ccc;\" if first_in_group and seen_strategies else \"\"\n",
    "        html += f'<tr style=\"{border}\">'\n",
    "\n",
    "        # Strategy cell: rowspan on first row, skip on subsequent\n",
    "        if first_in_group:\n",
    "            rs = strategy_counts[label]\n",
    "            va = \"vertical-align:middle;\" if rs > 1 else \"\"\n",
    "            html += (\n",
    "                f'<td rowspan=\"{rs}\" style=\"padding:4px 12px;font-weight:bold;'\n",
    "                f'{va}text-align:left\">{label}</td>'\n",
    "            )\n",
    "            seen_strategies.add(label)\n",
    "\n",
    "        # Scorer cell (left-aligned)\n",
    "        scorer_display = scorer if scorer else \"—\"\n",
    "        html += f'<td style=\"padding:4px 12px;text-align:left\">{scorer_display}</td>'\n",
    "\n",
    "        # Dataset cells\n",
    "        for ds in datasets:\n",
    "            n, url = cells[ds]\n",
    "            html += f'<td style=\"padding:4px 12px;text-align:center\">{_color_cell(n, url)}</td>'\n",
    "\n",
    "        html += \"</tr>\"\n",
    "\n",
    "    html += \"</table>\"\n",
    "    return html\n",
    "\n",
    "\n",
    "# ── Build Qwen2.5-Math-7B table ──\n",
    "BS_SCORER_LIST = [\"prm\", \"entropy\", \"perplexity\", \"sequence_prob\", \"pd_gap\", \"llm_critic\", \"uhead\"]\n",
    "\n",
    "QWEN25_COVERAGE = {\n",
    "    \"MATH-500\": {\n",
    "        \"baseline\": MATH500_BASELINE_RUNS,\n",
    "        \"self_consistency\": MATH500_SELF_CONSISTENCY_RUNS,\n",
    "        \"offline_bon\": [*MATH500_OFFLINE_BON_RUNS, *MATH500_OFFLINE_BON_UHEAD_RUNS],\n",
    "        \"bs_all_mean\": MATH500_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS,\n",
    "        \"bs_all_min\": MATH500_BEAM_SEARCH_ALL_STEPS_MIN_RUNS,\n",
    "        \"bs_5_mean\": MATH500_BEAM_SEARCH_5_STEPS_MEAN_RUNS,\n",
    "        \"bs_5_min\": MATH500_BEAM_SEARCH_5_STEPS_MIN_RUNS,\n",
    "        \"mur\": MATH500_MUR_RUNS,\n",
    "    },\n",
    "    \"OlympiadBench\": {\n",
    "        \"baseline\": OLYMPIAD_BASELINE_RUNS,\n",
    "        \"self_consistency\": OLYMPIAD_SELF_CONSISTENCY_RUNS,\n",
    "        \"offline_bon\": [*OLYMPIAD_OFFLINE_BON_RUNS, *OLYMPIAD_OFFLINE_BON_UHEAD_RUNS],\n",
    "        \"bs_all_mean\": OLYMPIAD_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS,\n",
    "        \"bs_all_min\": OLYMPIAD_BEAM_SEARCH_ALL_STEPS_MIN_RUNS,\n",
    "        \"bs_5_mean\": OLYMPIAD_BEAM_SEARCH_5_STEPS_MEAN_RUNS,\n",
    "        \"bs_5_min\": OLYMPIAD_BEAM_SEARCH_5_STEPS_MIN_RUNS,\n",
    "        \"mur\": OLYMPIAD_MUR_RUNS,\n",
    "    },\n",
    "    \"Minerva Math\": {\n",
    "        \"baseline\": MINERVA_BASELINE_RUNS,\n",
    "        \"self_consistency\": MINERVA_SELF_CONSISTENCY_RUNS,\n",
    "        \"offline_bon\": MINERVA_OFFLINE_BON_RUNS,\n",
    "        \"bs_all_mean\": MINERVA_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS,\n",
    "        \"bs_all_min\": MINERVA_BEAM_SEARCH_ALL_STEPS_MIN_RUNS,\n",
    "        \"bs_5_mean\": MINERVA_BEAM_SEARCH_5_STEPS_MEAN_RUNS,\n",
    "        \"bs_5_min\": MINERVA_BEAM_SEARCH_5_STEPS_MIN_RUNS,\n",
    "        \"mur\": MINERVA_MUR_RUNS,\n",
    "    },\n",
    "    \"Gaokao 2023 EN\": {\n",
    "        \"baseline\": GAOKAO_BASELINE_RUNS,\n",
    "        \"self_consistency\": GAOKAO_SELF_CONSISTENCY_RUNS,\n",
    "        \"offline_bon\": [*GAOKAO_OFFLINE_BON_RUNS, *GAOKAO_OFFLINE_BON_UHEAD_RUNS],\n",
    "        \"bs_all_mean\": GAOKAO_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS,\n",
    "        \"bs_all_min\": GAOKAO_BEAM_SEARCH_ALL_STEPS_MIN_RUNS,\n",
    "        \"bs_5_mean\": GAOKAO_BEAM_SEARCH_5_STEPS_MEAN_RUNS,\n",
    "        \"bs_5_min\": GAOKAO_BEAM_SEARCH_5_STEPS_MIN_RUNS,\n",
    "        \"mur\": GAOKAO_MUR_RUNS,\n",
    "    },\n",
    "}\n",
    "\n",
    "DATASETS_QWEN25 = [\"MATH-500\", \"OlympiadBench\", \"Minerva Math\", \"Gaokao 2023 EN\"]\n",
    "\n",
    "html = build_coverage_table(\n",
    "    title=\"Qwen2.5-Math-7B-Instruct (Non-Thinking) \\u2014 Seed Coverage\",\n",
    "    coverage_map=QWEN25_COVERAGE,\n",
    "    datasets=DATASETS_QWEN25,\n",
    "    strategy_order=[\"baseline\", \"self_consistency\", \"offline_bon\",\n",
    "                    \"bs_5_mean\", \"bs_5_min\", \"mur\"],\n",
    "    strategy_labels={\n",
    "        \"baseline\": \"Raw CoT<br>(non-thinking)\",\n",
    "        \"self_consistency\": \"Majority Voting<br>(self-consistency)\",\n",
    "        \"offline_bon\": \"Offline BoN\",\n",
    "        \"bs_5_mean\": \"Beam Search<br>(mean, window=5)\",\n",
    "        \"bs_5_min\": \"Beam Search<br>(min, window=5)\",\n",
    "        \"mur\": \"MUR\",\n",
    "    },\n",
    "    multi_scorer_strategies={\"mur\", \"offline_bon\", \"bs_5_mean\", \"bs_5_min\"},\n",
    "    scorer_overrides={\n",
    "        \"offline_bon\": [\"multi_scorer\", \"uhead\"],\n",
    "        \"bs_5_mean\": BS_SCORER_LIST,\n",
    "        \"bs_5_min\": BS_SCORER_LIST,\n",
    "    },\n",
    ")\n",
    "\n",
    "from IPython.display import HTML\n",
    "display(HTML(html))\n",
    "\n",
    "# ── Seed Coverage: Qwen3-8B (Thinking Mode) ──────────────────────────────────\n",
    "\n",
    "QWEN3_COVERAGE = {\n",
    "    \"AIME-2024\": {\n",
    "        \"baseline\": AIME_24_BASELINE_RUNS,\n",
    "        \"extended_thinking\": AIME_24_EXTENDED_THINKING_RUNS,\n",
    "        \"self_consistency\": AIME_24_SELF_CONSISTENCY_RUNS,\n",
    "        \"offline_bon\": AIME_24_OFFLINE_BON_RUNS,\n",
    "        \"bs_all_mean\": AIME_24_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS,\n",
    "        \"bs_all_min\": AIME_24_BEAM_SEARCH_ALL_STEPS_MIN_RUNS,\n",
    "        \"bs_5_mean\": AIME_24_BEAM_SEARCH_5_STEPS_MEAN_RUNS,\n",
    "        \"bs_5_min\": AIME_24_BEAM_SEARCH_5_STEPS_MIN_RUNS,\n",
    "        \"mur\": AIME_24_MUR_RUNS,\n",
    "    },\n",
    "    \"AIME-2025\": {\n",
    "        \"baseline\": AIME_25_BASELINE_RUNS,\n",
    "        \"extended_thinking\": AIME_25_EXTENDED_THINKING_RUNS,\n",
    "        \"self_consistency\": AIME_25_SELF_CONSISTENCY_RUNS,\n",
    "        \"offline_bon\": AIME_25_OFFLINE_BON_RUNS,\n",
    "        \"bs_all_mean\": AIME_25_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS,\n",
    "        \"bs_all_min\": AIME_25_BEAM_SEARCH_ALL_STEPS_MIN_RUNS,\n",
    "        \"bs_5_mean\": AIME_25_BEAM_SEARCH_5_STEPS_MEAN_RUNS,\n",
    "        \"bs_5_min\": AIME_25_BEAM_SEARCH_5_STEPS_MIN_RUNS,\n",
    "        \"mur\": AIME_25_MUR_RUNS,\n",
    "    },\n",
    "    \"HumanEval-Plus\": {\n",
    "        \"baseline\": HUMANEVAL_BASELINE_RUNS,\n",
    "        \"extended_thinking\": HUMANEVAL_EXTENDED_THINKING_RUNS,\n",
    "        \"self_consistency\": HUMANEVAL_SELF_CONSISTENCY_RUNS,\n",
    "        \"offline_bon\": HUMANEVAL_OFFLINE_BON_RUNS,\n",
    "        \"bs_all_mean\": HUMANEVAL_BEAM_SEARCH_ALL_STEPS_MEAN_RUNS,\n",
    "        \"bs_all_min\": HUMANEVAL_BEAM_SEARCH_ALL_STEPS_MIN_RUNS,\n",
    "        \"bs_5_mean\": HUMANEVAL_BEAM_SEARCH_5_STEPS_MEAN_RUNS,\n",
    "        \"bs_5_min\": HUMANEVAL_BEAM_SEARCH_5_STEPS_MIN_RUNS,\n",
    "        \"mur\": HUMANEVAL_MUR_RUNS,\n",
    "    },\n",
    "}\n",
    "\n",
    "DATASETS_QWEN3 = [\"AIME-2024\", \"AIME-2025\", \"HumanEval-Plus\"]\n",
    "\n",
    "html_qwen3 = build_coverage_table(\n",
    "    title=\"Qwen3-8B (Thinking Mode) \\u2014 Seed Coverage\",\n",
    "    coverage_map=QWEN3_COVERAGE,\n",
    "    datasets=DATASETS_QWEN3,\n",
    "    # bs_all_mean, bs_all_min, bs_5_mean temporarily excluded\n",
    "    strategy_order=[\"baseline\", \"extended_thinking\", \"self_consistency\", \"offline_bon\",\n",
    "                    \"bs_5_min\", \"mur\"],\n",
    "    strategy_labels={\n",
    "        \"baseline\": \"Raw CoT<br>(thinking)\",\n",
    "        \"extended_thinking\": \"Extended Thinking CoT\",\n",
    "        \"self_consistency\": \"Majority Voting<br>(self-consistency)\",\n",
    "        \"offline_bon\": \"Offline BoN\",\n",
    "        \"bs_5_min\": \"Beam Search<br>(min, window=5)\",\n",
    "        \"mur\": \"MUR\",\n",
    "    },\n",
    "    multi_scorer_strategies={\"mur\", \"offline_bon\", \"bs_5_min\"},\n",
    "    scorer_overrides={\n",
    "        \"offline_bon\": [\"multi_scorer\"],\n",
    "        \"bs_5_min\": BS_SCORER_LIST,\n",
    "    },\n",
    ")\n",
    "\n",
    "display(HTML(html_qwen3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Data Fetching ─────────────────────────────────────────────────────────────\n",
    "import re\n",
    "import json as _json\n",
    "from pathlib import Path as _Path\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "# Set to True to force re-fetch from wandb even if cached\n",
    "FORCE_REFRESH = False\n",
    "_RUNS_CACHE_DIR = _Path(\"cache/runs\")\n",
    "_RUNS_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def _unwrap_redirect(url: str) -> str:\n",
    "    \"\"\"Unwrap Google redirect URLs to extract the real destination.\"\"\"\n",
    "    parsed = urlparse(url)\n",
    "    host = parsed.hostname or \"\"\n",
    "    path = parsed.path or \"\"\n",
    "    if \"google.com\" in host or path.startswith(\"google.com/\"):\n",
    "        real = parse_qs(parsed.query).get(\"q\", [None])[0]\n",
    "        if real:\n",
    "            return real\n",
    "    return url\n",
    "\n",
    "\n",
    "def parse_group_url(url: str) -> dict:\n",
    "    \"\"\"Extract entity, project, and group name from a wandb group URL.\"\"\"\n",
    "    url = _unwrap_redirect(url)\n",
    "    path = urlparse(url).path.strip(\"/\")\n",
    "    m = re.match(r\"^(?P<entity>[^/]+)/(?P<project>[^/]+)/groups/(?P<group>[^/]+)\", path)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse group URL: {url}\")\n",
    "    return m.groupdict()\n",
    "\n",
    "\n",
    "def parse_run_url(url: str) -> dict:\n",
    "    \"\"\"Extract entity, project, and run_id from a wandb run URL.\n",
    "\n",
    "    Handles both formats:\n",
    "      .../runs/RUN_ID\n",
    "      .../groups/GROUP/runs/RUN_ID\n",
    "    \"\"\"\n",
    "    url = _unwrap_redirect(url)\n",
    "    path = urlparse(url).path.strip(\"/\")\n",
    "    m = re.match(r\"^(?P<entity>[^/]+)/(?P<project>[^/]+)/(?:groups/[^/]+/)?runs/(?P<run_id>[^/]+)\", path)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse run URL: {url}\")\n",
    "    return m.groupdict()\n",
    "\n",
    "\n",
    "def fetch_run(entity: str, project: str, run_id: str, group_name: str, seed: int) -> dict:\n",
    "    \"\"\"Fetch a single run and return a flat record dict.\"\"\"\n",
    "    run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "    cfg = run.config\n",
    "    s = run.summary._json_dict\n",
    "\n",
    "    strategy_cfg = cfg.get(\"strategy\", {})\n",
    "    scorer_cfg = cfg.get(\"scorer\", {})\n",
    "    model_cfg = cfg.get(\"model\", {})\n",
    "    dataset_cfg = cfg.get(\"dataset\", {})\n",
    "\n",
    "    return {\n",
    "        # identifiers\n",
    "        \"run_id\": run.id,\n",
    "        \"run_name\": run.name,\n",
    "        \"group\": group_name,\n",
    "        \"state\": run.state,\n",
    "        \"project\": project,\n",
    "        \"entity\": entity,\n",
    "        \"seed\": seed,\n",
    "        # config fields\n",
    "        \"strategy\": strategy_cfg.get(\"type\"),\n",
    "        \"scorer\": scorer_cfg.get(\"type\"),\n",
    "        \"aggregation\": strategy_cfg.get(\"aggregation\"),\n",
    "        \"scoring_window\": strategy_cfg.get(\"scoring_window\"),\n",
    "        \"scoring_window_label\": strategy_cfg.get(\"scoring_window_label\"),\n",
    "        \"model\": model_cfg.get(\"model_short_name\") or model_cfg.get(\"model_name\"),\n",
    "        \"dataset\": dataset_cfg.get(\"data_name\"),\n",
    "        \"beam_size\": strategy_cfg.get(\"beam_size\"),\n",
    "        \"candidates_per_beam\": strategy_cfg.get(\"candidates_per_beam\"),\n",
    "        \"num_paths\": strategy_cfg.get(\"num_paths\"),\n",
    "        \"num_candidates\": strategy_cfg.get(\"num_candidates\"),\n",
    "        \"max_steps\": strategy_cfg.get(\"max_steps\"),\n",
    "        # summary metrics\n",
    "        \"exact_match\": s.get(\"exact_match/accuracy\"),\n",
    "        \"llm_judge_accuracy\": next(\n",
    "            (v for k, v in s.items() if k.startswith(\"llm_judge\") and k.endswith(\"/accuracy\")),\n",
    "            None,\n",
    "        ),\n",
    "        \"avg_reasoning_steps\": s.get(\"avg_reasoning_steps_per_trajectory\"),\n",
    "        \"total_tokens\": s.get(\"compute/total_tokens\"),\n",
    "        \"total_input_tokens\": s.get(\"compute/total_input_tokens\"),\n",
    "        \"total_output_tokens\": s.get(\"compute/total_output_tokens\"),\n",
    "        \"total_tflops\": s.get(\"compute/total_tflops\"),\n",
    "        \"avg_tokens_per_sample\": s.get(\"compute/avg_tokens_per_sample\"),\n",
    "        \"avg_output_tokens_per_sample\": s.get(\"compute/avg_output_tokens_per_sample\"),\n",
    "        \"avg_tflops_per_sample\": s.get(\"compute/avg_tflops_per_sample\"),\n",
    "        \"total_generations\": s.get(\"compute/total_generations\"),\n",
    "        \"prm_tflops\": s.get(\"compute/prm_tflops\"),\n",
    "        \"total_samples\": s.get(\"total_samples\"),\n",
    "        \"completed\": s.get(\"completed\"),\n",
    "        \"humaneval_correct\": s.get(\"human_eval_plus/correct\"),\n",
    "        \"humaneval_incorrect\": s.get(\"human_eval_plus/incorrect\"),\n",
    "        \"humaneval_score\": s.get(\"human_eval_plus/accuracy\"),\n",
    "        # full config & summary for future use\n",
    "        \"_config\": cfg,\n",
    "        \"_summary\": s,\n",
    "    }\n",
    "\n",
    "\n",
    "def _load_cached_run(run_id: str) -> dict | None:\n",
    "    \"\"\"Load a cached run record from disk, or return None.\"\"\"\n",
    "    cache_file = _RUNS_CACHE_DIR / f\"{run_id}.json\"\n",
    "    if cache_file.exists() and not FORCE_REFRESH:\n",
    "        with open(cache_file) as f:\n",
    "            return _json.load(f)\n",
    "    return None\n",
    "\n",
    "\n",
    "def _save_run_cache(record: dict) -> None:\n",
    "    \"\"\"Save a run record to disk cache.\"\"\"\n",
    "    cache_file = _RUNS_CACHE_DIR / f\"{record['run_id']}.json\"\n",
    "    with open(cache_file, \"w\") as f:\n",
    "        _json.dump(record, f, indent=2, default=str)\n",
    "\n",
    "\n",
    "\n",
    "def _fmt_metrics(rec: dict) -> str:\n",
    "    \"\"\"Format metrics for log output — dataset-aware.\"\"\"\n",
    "    ds = str(rec.get(\"dataset\", \"\") or \"\")\n",
    "    if \"human_eval\" in ds:\n",
    "        hs = rec.get(\"humaneval_score\")\n",
    "        hs_s = f\"{hs:.4f}\" if hs is not None else \"N/A\"\n",
    "        return f\"humaneval_score={hs_s}\"\n",
    "    em = rec.get(\"exact_match\")\n",
    "    llm = rec.get(\"llm_judge_accuracy\")\n",
    "    em_s = f\"{em:.4f}\" if em is not None else \"N/A\"\n",
    "    llm_s = f\"{llm:.4f}\" if llm is not None else \"N/A\"\n",
    "    parts = f\"exact_match={em_s}  llm_judge={llm_s}\"\n",
    "    if em is not None and llm is not None:\n",
    "        diff = abs(em - llm)\n",
    "        if diff > 0.10:\n",
    "            parts += f\"  Δ={diff:.4f} — METRICS DIVERGE >10%\"\n",
    "    return parts\n",
    "\n",
    "\n",
    "# Validate that all non-empty run_urls are unique across the registry\n",
    "_all_urls = [\n",
    "    r[\"run_url\"]\n",
    "    for entry in EXPERIMENT_RUNS\n",
    "    for r in entry.get(\"runs\", [])\n",
    "    if r.get(\"run_url\")\n",
    "]\n",
    "_seen, _dupes = set(), set()\n",
    "for _u in _all_urls:\n",
    "    (_dupes if _u in _seen else _seen).add(_u)\n",
    "if _dupes:\n",
    "    print(f\"[warn] {len(_dupes)} duplicate run_url(s) detected:\")\n",
    "    for _u in sorted(_dupes):\n",
    "        print(f\"  {_u}\")\n",
    "else:\n",
    "    print(f\"[ok] all {len(_all_urls)} run URLs are unique\")\n",
    "\n",
    "# Fetch all specified runs (skip entries with empty group_url or runs)\n",
    "records = []\n",
    "_cached_count = 0\n",
    "_fetched_count = 0\n",
    "for entry in tqdm(EXPERIMENT_RUNS, desc=\"Fetching runs\", leave=False):\n",
    "    if not entry.get(\"group_url\") or not entry.get(\"runs\"):\n",
    "        continue\n",
    "\n",
    "    group_info = parse_group_url(entry[\"group_url\"])\n",
    "    group_name = group_info[\"group\"]\n",
    "    tqdm.write(f\"Group: {group_name}\")\n",
    "\n",
    "    for run_entry in entry[\"runs\"]:\n",
    "        seed = run_entry[\"seed\"]\n",
    "        run_url = run_entry.get(\"run_url\", \"\")\n",
    "        if not run_url:\n",
    "            tqdm.write(f\"  [warn] seed={seed} in group '{group_name}' has no run_url, skipping\")\n",
    "            continue\n",
    "        run_info = parse_run_url(run_url)\n",
    "        run_id = run_info[\"run_id\"]\n",
    "\n",
    "        # Try cache first\n",
    "        cached = _load_cached_run(run_id)\n",
    "        if cached is not None:\n",
    "            cached_state = cached.get(\"state\", \"\")\n",
    "            # Re-fetch if cached state is not terminal (run might have finished since)\n",
    "            if cached_state not in (\"finished\", \"crashed\", \"failed\"):\n",
    "                try:\n",
    "                    record = fetch_run(run_info[\"entity\"], run_info[\"project\"],\n",
    "                                       run_id, group_name, seed)\n",
    "                    _save_run_cache(record)\n",
    "                    records.append(record)\n",
    "                    _fetched_count += 1\n",
    "                    state = record.get(\"state\", \"?\")\n",
    "                    tqdm.write(f\"  seed={seed}  [{state}]  {_fmt_metrics(record)}  (re-fetched, was {cached_state})\")\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    tqdm.write(f\"  seed={seed}  [re-fetch failed: {e}, using stale cache]\")\n",
    "\n",
    "            # Update group/seed in case registry changed\n",
    "            cached[\"group\"] = group_name\n",
    "            cached[\"seed\"] = seed\n",
    "            records.append(cached)\n",
    "            _cached_count += 1\n",
    "            tqdm.write(f\"  seed={seed}  [cached, {cached_state}]  {_fmt_metrics(cached)}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            record = fetch_run(run_info[\"entity\"], run_info[\"project\"],\n",
    "                               run_id, group_name, seed)\n",
    "            _save_run_cache(record)\n",
    "            records.append(record)\n",
    "            _fetched_count += 1\n",
    "            state = record.get(\"state\", \"?\")\n",
    "            tqdm.write(f\"  seed={seed}  [{state}]  {_fmt_metrics(record)}\")\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"  ERROR fetching seed={seed}: {e}\")\n",
    "\n",
    "raw_df = pd.DataFrame(records)\n",
    "tqdm.write(f\"\\nTotal runs: {len(raw_df)} ({_cached_count} cached, {_fetched_count} fetched)\")\n",
    "\n",
    "# Warn about runs where \"completed\" != \"total_samples\" (dataset size)\n",
    "# For HumanEval-Plus: check human_eval_plus/correct + human_eval_plus/incorrect == 164\n",
    "_incomplete = []\n",
    "_HUMANEVAL_EXPECTED = 164\n",
    "if not raw_df.empty:\n",
    "    for _, r in raw_df.iterrows():\n",
    "        run_link = f\"https://wandb.ai/{r['entity']}/{r['project']}/runs/{r['run_id']}\"\n",
    "        dataset = r.get(\"dataset\", \"\") or \"\"\n",
    "\n",
    "        # HumanEval-Plus: use correct + incorrect\n",
    "        if \"human_eval\" in dataset:\n",
    "            hc = r.get(\"humaneval_correct\")\n",
    "            hi = r.get(\"humaneval_incorrect\")\n",
    "            if pd.notna(hc) and pd.notna(hi):\n",
    "                done = int(hc) + int(hi)\n",
    "                if done != _HUMANEVAL_EXPECTED:\n",
    "                    _incomplete.append({\n",
    "                        \"run_id\": r[\"run_id\"], \"group\": r[\"group\"], \"seed\": r[\"seed\"],\n",
    "                        \"state\": r.get(\"state\", \"?\"),\n",
    "                        \"completed\": done, \"total\": _HUMANEVAL_EXPECTED,\n",
    "                        \"pct\": done / _HUMANEVAL_EXPECTED * 100,\n",
    "                        \"link\": run_link,\n",
    "                    })\n",
    "            continue\n",
    "\n",
    "        # Other datasets: use completed vs total_samples\n",
    "        comp = r.get(\"completed\")\n",
    "        total = r.get(\"total_samples\")\n",
    "        if pd.isna(comp) or pd.isna(total):\n",
    "            continue\n",
    "        comp, total = int(comp), int(total)\n",
    "        if comp != total:\n",
    "            _incomplete.append({\n",
    "                \"run_id\": r[\"run_id\"], \"group\": r[\"group\"], \"seed\": r[\"seed\"],\n",
    "                \"state\": r.get(\"state\", \"?\"), \"completed\": comp, \"total\": total,\n",
    "                \"pct\": comp / total * 100 if total > 0 else 0,\n",
    "                \"link\": run_link,\n",
    "            })\n",
    "\n",
    "if _incomplete:\n",
    "    tqdm.write(f\"\\n⚠ {len(_incomplete)} INCOMPLETE runs detected:\")\n",
    "    for ir in _incomplete:\n",
    "        tqdm.write(\n",
    "            f\"  {ir['group']}  seed={ir['seed']}  state={ir['state']}  \"\n",
    "            f\"completed={ir['completed']}/{ir['total']} ({ir['pct']:.0f}%)  \"\n",
    "            f\"{ir['link']}\"\n",
    "        )\n",
    "else:\n",
    "    tqdm.write(\"All runs completed successfully.\")\n",
    "\n",
    "# Report non-finished runs (running, crashed, failed, etc.)\n",
    "_non_finished = []\n",
    "if not raw_df.empty:\n",
    "    for _, r in raw_df.iterrows():\n",
    "        state = r.get(\"state\", \"\")\n",
    "        if state != \"finished\":\n",
    "            _non_finished.append({\n",
    "                \"run_id\": r[\"run_id\"],\n",
    "                \"group\": r[\"group\"],\n",
    "                \"seed\": r[\"seed\"],\n",
    "                \"state\": state,\n",
    "                \"link\": f\"https://wandb.ai/{r['entity']}/{r['project']}/runs/{r['run_id']}\",\n",
    "            })\n",
    "\n",
    "if _non_finished:\n",
    "    _running = [r for r in _non_finished if r[\"state\"] == \"running\"]\n",
    "    _other = [r for r in _non_finished if r[\"state\"] != \"running\"]\n",
    "    if _running:\n",
    "        tqdm.write(f\"\\n🔄 {len(_running)} RUNNING runs:\")\n",
    "        for r in _running:\n",
    "            tqdm.write(f\"  {r['group']}  seed={r['seed']}  {r['link']}\")\n",
    "    if _other:\n",
    "        tqdm.write(f\"\\n❌ {len(_other)} non-finished runs (crashed/failed/other):\")\n",
    "        for r in _other:\n",
    "            tqdm.write(f\"  {r['group']}  seed={r['seed']}  state={r['state']}  {r['link']}\")\n",
    "else:\n",
    "    tqdm.write(\"\\nAll runs finished.\")\n",
    "\n",
    "# Save cell output to log file\n",
    "_log_path = _Path(\"cache/data_fetching.log\")\n",
    "with open(_log_path, \"w\") as _lf:\n",
    "    _lf.write(f\"Fetched {len(raw_df)} runs ({_cached_count} cached, {_fetched_count} fetched)\\n\\n\")\n",
    "    for _, r in raw_df.iterrows():\n",
    "        state = r.get(\"state\", \"?\")\n",
    "        _lf.write(f\"{r['group']}  seed={r['seed']}  state={state}  \"\n",
    "                   f\"{_fmt_metrics(r.to_dict())}\\n\")\n",
    "    if _incomplete:\n",
    "        _lf.write(f\"\\n{len(_incomplete)} INCOMPLETE runs:\\n\")\n",
    "        for ir in _incomplete:\n",
    "            _lf.write(f\"  {ir['group']}  seed={ir['seed']}  \"\n",
    "                       f\"completed={ir['completed']}/{ir['total']}  {ir['link']}\\n\")\n",
    "    else:\n",
    "        _lf.write(\"\\nAll runs completed successfully.\\n\")\n",
    "    if _non_finished:\n",
    "        _running_log = [r for r in _non_finished if r[\"state\"] == \"running\"]\n",
    "        _other_log = [r for r in _non_finished if r[\"state\"] != \"running\"]\n",
    "        if _running_log:\n",
    "            _lf.write(f\"\\n{len(_running_log)} RUNNING runs:\\n\")\n",
    "            for r in _running_log:\n",
    "                _lf.write(f\"  {r['group']}  seed={r['seed']}  {r['link']}\\n\")\n",
    "        if _other_log:\n",
    "            _lf.write(f\"\\n{len(_other_log)} non-finished runs (crashed/failed/other):\\n\")\n",
    "            for r in _other_log:\n",
    "                _lf.write(f\"  {r['group']}  seed={r['seed']}  state={r['state']}  {r['link']}\\n\")\n",
    "    else:\n",
    "        _lf.write(\"\\nAll runs finished.\\n\")\n",
    "\n",
    "print(f\"Saved fetch log to {_log_path}\")\n",
    "\n",
    "raw_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Data Cleaning & Parsing ───────────────────────────────────────────────────\n",
    "\n",
    "def parse_group_name(group: str | None) -> dict:\n",
    "    \"\"\"Best-effort extraction of structured fields from the group name.\n",
    "\n",
    "    Expected patterns:\n",
    "      {strategy}_{model}_{dataset}\n",
    "      {strategy}_{model}_{dataset}_{scorer}\n",
    "      {strategy}_{model}_{dataset}_{scorer}_{window}_{aggregation}\n",
    "    \"\"\"\n",
    "    result = {\"_group_strategy\": None, \"_group_model\": None,\n",
    "              \"_group_dataset\": None, \"_group_scorer\": None,\n",
    "              \"_group_window\": None, \"_group_aggregation\": None}\n",
    "    if not group:\n",
    "        return result\n",
    "\n",
    "    known_strategies = {\n",
    "        \"baseline\", \"chain_of_thought\", \"self_consistency\",\n",
    "        \"online_bon\", \"offline_bon\", \"beam_search\",\n",
    "        \"uncertainty_cot\", \"extended_thinking\",\n",
    "        \"adaptive_scaling\", \"deepconf\",\n",
    "    }\n",
    "    known_scorers = {\n",
    "        \"prm\", \"entropy\", \"perplexity\", \"sequence_prob\",\n",
    "        \"uncertainty\", \"uncertainty_pd\", \"uncertainty_uhead\",\n",
    "        \"uhead_vllm\", \"uhead\",\n",
    "    }\n",
    "    known_aggregations = {\"mean\", \"min\", \"max\", \"sum\", \"product\", \"median\"}\n",
    "    known_datasets = {\n",
    "        \"minerva_math\", \"math500\", \"aime2024\", \"aime2025\",\n",
    "        \"gaokao2023en\", \"human_eval_plus\", \"olympiadbench\",\n",
    "    }\n",
    "\n",
    "    parts = group.split(\"_\")\n",
    "\n",
    "    # Greedy match strategy prefix (try longest first)\n",
    "    strategy = None\n",
    "    for length in range(min(3, len(parts)), 0, -1):\n",
    "        candidate = \"_\".join(parts[:length])\n",
    "        if candidate in known_strategies:\n",
    "            strategy = candidate\n",
    "            parts = parts[length:]\n",
    "            break\n",
    "    result[\"_group_strategy\"] = strategy\n",
    "\n",
    "    # Scan remaining parts for known tokens\n",
    "    remaining = \"_\".join(parts)\n",
    "    for ds in sorted(known_datasets, key=len, reverse=True):\n",
    "        if ds in remaining:\n",
    "            result[\"_group_dataset\"] = ds\n",
    "            remaining = remaining.replace(ds, \"\", 1)\n",
    "            break\n",
    "    for sc in sorted(known_scorers, key=len, reverse=True):\n",
    "        if f\"_{sc}\" in f\"_{remaining}\":\n",
    "            result[\"_group_scorer\"] = sc\n",
    "            remaining = remaining.replace(sc, \"\", 1)\n",
    "            break\n",
    "    for ag in known_aggregations:\n",
    "        if f\"_{ag}\" in f\"_{remaining}\":\n",
    "            result[\"_group_aggregation\"] = ag\n",
    "            break\n",
    "    # window: look for a bare integer or \"all\"\n",
    "    for p in remaining.split(\"_\"):\n",
    "        if p.isdigit():\n",
    "            result[\"_group_window\"] = p\n",
    "            break\n",
    "        if p == \"all\":\n",
    "            result[\"_group_window\"] = \"all\"\n",
    "            break\n",
    "\n",
    "    # model: whatever remains after removing known tokens is likely the model\n",
    "    for tok in [result[\"_group_dataset\"], result[\"_group_scorer\"],\n",
    "                result[\"_group_aggregation\"], result[\"_group_window\"]]:\n",
    "        if tok:\n",
    "            remaining = remaining.replace(tok, \"\", 1)\n",
    "    model_str = \"_\".join(p for p in remaining.split(\"_\") if p)\n",
    "    result[\"_group_model\"] = model_str or None\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "df = raw_df.copy()\n",
    "\n",
    "# Parse group names to fill missing config columns\n",
    "parsed = df[\"group\"].apply(parse_group_name).apply(pd.Series)\n",
    "df = pd.concat([df, parsed], axis=1)\n",
    "\n",
    "# Fill missing config from parsed group name\n",
    "for col, gcol in [(\"strategy\", \"_group_strategy\"), (\"scorer\", \"_group_scorer\"),\n",
    "                   (\"aggregation\", \"_group_aggregation\"),\n",
    "                   (\"scoring_window\", \"_group_window\"),\n",
    "                   (\"dataset\", \"_group_dataset\"), (\"model\", \"_group_model\")]:\n",
    "    df[col] = df[col].fillna(df[gcol])\n",
    "\n",
    "\n",
    "# Normalize scorer variants\n",
    "df[\"scorer\"] = df[\"scorer\"].replace({\"uhead_vllm\": \"uhead\", \"uncertainty_uhead\": \"uhead\"})\n",
    "\n",
    "# Drop helper columns\n",
    "df.drop(columns=[c for c in df.columns if c.startswith(\"_group_\")], inplace=True)\n",
    "\n",
    "# Filter to finished runs only\n",
    "n_before = len(df)\n",
    "df = df[df[\"state\"] == \"finished\"].copy()\n",
    "print(f\"Kept {len(df)}/{n_before} finished runs\")\n",
    "\n",
    "# Optional group filter\n",
    "if GROUP_FILTERS:\n",
    "    mask = df[\"group\"].apply(lambda g: any(f in (g or \"\") for f in GROUP_FILTERS))\n",
    "    df = df[mask].copy()\n",
    "    print(f\"After group filter: {len(df)} runs\")\n",
    "\n",
    "# Create human-readable project label from wandb project name\n",
    "PROJECT_LABEL_MAP = {\n",
    "    \"llm-tts-eval-math500\": \"MATH-500\",\n",
    "    \"llm-tts-eval-minerva-math\": \"Minerva Math\",\n",
    "    \"llm-tts-eval-minerva_math\": \"Minerva Math\",\n",
    "    \"llm-tts-eval-gaokao2023en\": \"Gaokao 2023 EN\",\n",
    "    \"llm-tts-eval-olympiadbench\": \"OlympiadBench\",\n",
    "    \"llm-tts-eval-gpqa-diamond\": \"GPQA Diamond\",\n",
    "    \"llm-tts-eval-gpqa_diamond\": \"GPQA Diamond\",\n",
    "    \"llm-tts-eval-aime24\": \"AIME 2024\",\n",
    "    \"llm-tts-eval-aime2024\": \"AIME 2024\",\n",
    "    \"llm-tts-eval-aime25\": \"AIME 2025\",\n",
    "    \"llm-tts-eval-aime2025\": \"AIME 2025\",\n",
    "    \"llm-tts-human-eval-plus\": \"HumanEval-Plus\",\n",
    "}\n",
    "df[\"project_label\"] = df[\"project\"].map(PROJECT_LABEL_MAP).fillna(df[\"project\"])\n",
    "\n",
    "# Fill humaneval_score for HumanEval-Plus from correct / (correct + incorrect)\n",
    "# (fallback if human_eval_plus/accuracy was missing from wandb summary)\n",
    "if \"humaneval_correct\" in df.columns and \"humaneval_incorrect\" in df.columns:\n",
    "    _he_mask = (\n",
    "        df[\"humaneval_score\"].isna()\n",
    "        & df[\"humaneval_correct\"].notna()\n",
    "        & df[\"humaneval_incorrect\"].notna()\n",
    "    )\n",
    "    _he_total = df.loc[_he_mask, \"humaneval_correct\"] + df.loc[_he_mask, \"humaneval_incorrect\"]\n",
    "    df.loc[_he_mask, \"humaneval_score\"] = df.loc[_he_mask, \"humaneval_correct\"] / _he_total\n",
    "    _filled = _he_mask.sum()\n",
    "    if _filled:\n",
    "        print(f\"Filled humaneval_score for {_filled} HumanEval-Plus runs from correct/incorrect\")\n",
    "\n",
    "# ── Hardcoded EM fixes ────────────────────────────────────────────────────────\n",
    "# AIME 2025 self-consistency: exact_match was computed with buggy extraction code.\n",
    "# Override with llm_judge_accuracy (verified correct).\n",
    "_AIME25_SC_BUGGY_RUNS = {\"e03jj1df\", \"4o5fp278\", \"yvpwgde3\"}\n",
    "_fix_mask = df[\"run_id\"].isin(_AIME25_SC_BUGGY_RUNS)\n",
    "if _fix_mask.any():\n",
    "    _before = df.loc[_fix_mask, [\"run_id\", \"exact_match\", \"llm_judge_accuracy\"]].copy()\n",
    "    df.loc[_fix_mask, \"exact_match\"] = df.loc[_fix_mask, \"llm_judge_accuracy\"]\n",
    "    for _, row in _before.iterrows():\n",
    "        print(f\"  Fixed {row['run_id']}: EM {row['exact_match']:.4f} → {row['llm_judge_accuracy']:.4f} (using LLM judge)\")\n",
    "    print(f\"Fixed {_fix_mask.sum()} AIME 2025 self-consistency runs (buggy exact_match → llm_judge)\")\n",
    "\n",
    "# Normalize accuracy to percentage\n",
    "for col in [\"exact_match\", \"llm_judge_accuracy\", \"humaneval_score\"]:\n",
    "    if col in df.columns:\n",
    "        # If values look like fractions (0-1), convert to pct\n",
    "        mask = df[col].notna() & (df[col] <= 1.0)\n",
    "        df.loc[mask, col] = df.loc[mask, col] * 100\n",
    "\n",
    "print(f\"\\nStrategies: {sorted(df['strategy'].dropna().unique())}\")\n",
    "print(f\"Scorers:    {sorted(df['scorer'].dropna().unique())}\")\n",
    "print(f\"Datasets:   {sorted(df['project_label'].dropna().unique())}\")\n",
    "df[[\"strategy\", \"scorer\", \"aggregation\", \"scoring_window\", \"project_label\", \"dataset\", \"model\",\n",
    "    \"exact_match\", \"llm_judge_accuracy\", \"humaneval_score\", \"total_tflops\"]].sample(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Seed Averaging ────────────────────────────────────────────────────────────\n",
    "\n",
    "CONFIG_COLS = [\"strategy\", \"scorer\", \"aggregation\", \"scoring_window\",\n",
    "               \"model\", \"dataset\", \"project_label\",\n",
    "               \"beam_size\", \"candidates_per_beam\", \"num_paths\", \"num_candidates\"]\n",
    "\n",
    "METRIC_COLS = [\"exact_match\", \"llm_judge_accuracy\", \"humaneval_score\", \"avg_reasoning_steps\",\n",
    "               \"total_tokens\", \"total_tflops\", \"avg_tokens_per_sample\",\n",
    "               \"avg_output_tokens_per_sample\", \"avg_tflops_per_sample\"]\n",
    "\n",
    "\n",
    "def aggregate_seeds(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Group by config columns and compute mean/std over seeds.\"\"\"\n",
    "    present_cfg = [c for c in CONFIG_COLS if c in df.columns]\n",
    "    present_met = [c for c in METRIC_COLS if c in df.columns]\n",
    "\n",
    "    grouped = df.groupby(present_cfg, dropna=False)\n",
    "    agg = grouped[present_met].agg([\"mean\", \"std\", \"count\"]).reset_index()\n",
    "\n",
    "    # Flatten multi-level columns\n",
    "    flat_cols = []\n",
    "    for col in agg.columns:\n",
    "        if isinstance(col, tuple) and col[1]:\n",
    "            flat_cols.append(f\"{col[0]}_{col[1]}\")\n",
    "        else:\n",
    "            flat_cols.append(col[0] if isinstance(col, tuple) else col)\n",
    "    agg.columns = flat_cols\n",
    "\n",
    "    # Add a formatted \"mean +/- std\" column for the primary metric\n",
    "    for m in present_met:\n",
    "        mean_col, std_col = f\"{m}_mean\", f\"{m}_std\"\n",
    "        if mean_col in agg.columns:\n",
    "            agg[f\"{m}_fmt\"] = agg.apply(\n",
    "                lambda r: f\"{r[mean_col]:.1f} +/- {r[std_col]:.1f}\"\n",
    "                if pd.notna(r[std_col]) and r.get(f\"{m}_count\", 0) > 1\n",
    "                else (f\"{r[mean_col]:.1f}\" if pd.notna(r[mean_col]) else \"\"),\n",
    "                axis=1,\n",
    "            )\n",
    "    return agg\n",
    "\n",
    "\n",
    "agg_df = aggregate_seeds(df)\n",
    "print(f\"Aggregated configs: {len(agg_df)}\")\n",
    "agg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Pivot Table Helper ────────────────────────────────────────────────────────\n",
    "\n",
    "def make_comparison_table(\n",
    "    df: pd.DataFrame,\n",
    "    row_field: str,\n",
    "    col_field: str,\n",
    "    value_field: str = \"exact_match_fmt\",\n",
    "    filter_dict: dict | None = None,\n",
    "    title: str | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Build a pivot table from the aggregated DataFrame.\"\"\"\n",
    "    sub = df.copy()\n",
    "    if filter_dict:\n",
    "        for k, v in filter_dict.items():\n",
    "            if isinstance(v, list):\n",
    "                sub = sub[sub[k].isin(v)]\n",
    "            else:\n",
    "                sub = sub[sub[k] == v]\n",
    "\n",
    "    if sub.empty:\n",
    "        print(\"No data after filtering.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    pivot = sub.pivot_table(\n",
    "        index=row_field,\n",
    "        columns=col_field,\n",
    "        values=value_field,\n",
    "        aggfunc=\"first\",\n",
    "    )\n",
    "    if title:\n",
    "        sep = \"=\" * len(title)\n",
    "        print(f\"\\n{sep}\")\n",
    "        print(title)\n",
    "        print(sep)\n",
    "    return pivot\n",
    "\n",
    "\n",
    "# ── Unified Results Table (Strategy x Scorer → Datasets) ─────────────────────\n",
    "\n",
    "STRATEGY_LABELS = {\n",
    "    \"baseline\": \"Baseline\",\n",
    "    \"extended_thinking\": \"Extended Thinking\",\n",
    "    \"self_consistency\": \"Self-Consistency\",\n",
    "    \"offline_best_of_n\": \"Offline BoN\",\n",
    "    \"offline_bon\": \"Offline BoN\",\n",
    "    \"beam_search\": \"Beam Search\",\n",
    "    \"adaptive\": \"MUR\",\n",
    "    \"online_best_of_n\": \"Online BoN\",\n",
    "}\n",
    "\n",
    "# Strategies that have a single scorer row (no per-scorer breakdown)\n",
    "SINGLE_SCORER_STRATEGIES = {\"baseline\", \"self_consistency\", \"extended_thinking\"}\n",
    "\n",
    "\n",
    "def build_unified_results_table(\n",
    "    model_df,\n",
    "    datasets,\n",
    "    metrics=None,\n",
    "    strategy_order=None,\n",
    "    strategy_labels=None,\n",
    "):\n",
    "    \"\"\"Build a unified table: rows = (Strategy, Scorer), columns = datasets (x metrics).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    metrics : str or list of (col_name, display_name) tuples\n",
    "        Single column name (flat columns) or list of (col, label) for MultiIndex columns.\n",
    "        Default: \"exact_match_fmt\" (single metric, flat columns).\n",
    "    \"\"\"\n",
    "    if strategy_order is None:\n",
    "        strategy_order = [\n",
    "            \"baseline\", \"extended_thinking\", \"self_consistency\",\n",
    "            \"offline_best_of_n\", \"beam_search\", \"adaptive\",\n",
    "        ]\n",
    "    if strategy_labels is None:\n",
    "        strategy_labels = STRATEGY_LABELS\n",
    "\n",
    "    # Normalize metrics spec\n",
    "    if metrics is None:\n",
    "        metrics = \"exact_match_fmt\"\n",
    "    if isinstance(metrics, str):\n",
    "        _metric_specs = [(metrics, None)]  # single metric, flat columns\n",
    "        _multi_col = False\n",
    "    else:\n",
    "        _metric_specs = metrics  # list of (col_name, display_name)\n",
    "        _multi_col = True\n",
    "\n",
    "    def _extract(match_df):\n",
    "        \"\"\"Extract metric values from a single-row match.\"\"\"\n",
    "        if match_df.empty:\n",
    "            return {label or col: \"\" for col, label in _metric_specs}\n",
    "        r = match_df.iloc[0]\n",
    "        return {label or col: r.get(col, \"\") for col, label in _metric_specs}\n",
    "\n",
    "    rows = []\n",
    "    row_index = []\n",
    "\n",
    "    for strat in strategy_order:\n",
    "        strat_df = model_df[model_df[\"strategy\"] == strat]\n",
    "        if strat_df.empty:\n",
    "            continue\n",
    "\n",
    "        if strat == \"beam_search\":\n",
    "            variants = (\n",
    "                strat_df[[\"aggregation\", \"scoring_window\"]]\n",
    "                .drop_duplicates()\n",
    "                .sort_values([\"scoring_window\", \"aggregation\"])\n",
    "            )\n",
    "            for _, vr in variants.iterrows():\n",
    "                agg, win = vr[\"aggregation\"], vr[\"scoring_window\"]\n",
    "                win_label = f\"window={win}\" if pd.notna(win) else \"window=all\"\n",
    "                agg_label = agg if pd.notna(agg) else \"mean\"\n",
    "                label = f\"Beam Search\\n({agg_label}, {win_label})\"\n",
    "\n",
    "                sub = strat_df[\n",
    "                    (strat_df[\"aggregation\"] == agg)\n",
    "                    & (strat_df[\"scoring_window\"] == win)\n",
    "                ]\n",
    "                scorers = sorted(sub[\"scorer\"].dropna().unique())\n",
    "                for scorer in scorers:\n",
    "                    row = {}\n",
    "                    for ds in datasets:\n",
    "                        vals = _extract(sub[(sub[\"scorer\"] == scorer) & (sub[\"project_label\"] == ds)])\n",
    "                        if _multi_col:\n",
    "                            for k, v in vals.items():\n",
    "                                row[(ds, k)] = v\n",
    "                        else:\n",
    "                            row[ds] = list(vals.values())[0]\n",
    "                    rows.append(row)\n",
    "                    row_index.append((label, scorer))\n",
    "\n",
    "        elif strat in SINGLE_SCORER_STRATEGIES:\n",
    "            label = strategy_labels.get(strat, strat)\n",
    "            row = {}\n",
    "            for ds in datasets:\n",
    "                vals = _extract(strat_df[strat_df[\"project_label\"] == ds])\n",
    "                if _multi_col:\n",
    "                    for k, v in vals.items():\n",
    "                        row[(ds, k)] = v\n",
    "                else:\n",
    "                    row[ds] = list(vals.values())[0]\n",
    "            rows.append(row)\n",
    "            row_index.append((label, \"\\u2014\"))\n",
    "\n",
    "        else:\n",
    "            label = strategy_labels.get(strat, strat)\n",
    "            scorers = sorted(strat_df[\"scorer\"].dropna().unique())\n",
    "            for scorer in scorers:\n",
    "                row = {}\n",
    "                for ds in datasets:\n",
    "                    match = strat_df[\n",
    "                        (strat_df[\"scorer\"] == scorer) & (strat_df[\"project_label\"] == ds)\n",
    "                    ]\n",
    "                    vals = _extract(match)\n",
    "                    if _multi_col:\n",
    "                        for k, v in vals.items():\n",
    "                            row[(ds, k)] = v\n",
    "                    else:\n",
    "                        row[ds] = list(vals.values())[0]\n",
    "                rows.append(row)\n",
    "                row_index.append((label, scorer))\n",
    "\n",
    "    if not rows:\n",
    "        print(\"No data found.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    mi_rows = pd.MultiIndex.from_tuples(row_index, names=[\"Strategy\", \"Scorer\"])\n",
    "    if _multi_col:\n",
    "        metric_labels = [label or col for col, label in _metric_specs]\n",
    "        mi_cols = pd.MultiIndex.from_tuples(\n",
    "            [(ds, m) for ds in datasets for m in metric_labels],\n",
    "            names=[\"Dataset\", \"Metric\"],\n",
    "        )\n",
    "        return pd.DataFrame(rows, index=mi_rows, columns=mi_cols)\n",
    "    return pd.DataFrame(rows, index=mi_rows, columns=datasets)\n",
    "\n",
    "\n",
    "\n",
    "def style_results_table(df):\n",
    "    \"\"\"Apply styling: bold + centered strategy names, alternating row colours.\n",
    "    Uses CSS nth-child selectors for reliable row coloring.\"\"\"\n",
    "    _GROUP_COLORS = [(\"#ffffff\", \"#f0f0f0\"), (\"#f0f0f0\", \"#ffffff\")]\n",
    "\n",
    "    base_styles = [\n",
    "        {\"selector\": \"th.row_heading.level0\",\n",
    "         \"props\": [(\"vertical-align\", \"middle\"), (\"font-weight\", \"bold\"),\n",
    "                    (\"text-align\", \"left\"), (\"padding\", \"6px 10px\")]},\n",
    "        {\"selector\": \"th.row_heading.level1\",\n",
    "         \"props\": [(\"text-align\", \"left\"), (\"padding\", \"4px 10px\")]},\n",
    "        {\"selector\": \"td\",\n",
    "         \"props\": [(\"text-align\", \"center\"), (\"padding\", \"4px 8px\")]},\n",
    "        {\"selector\": \"th.col_heading\",\n",
    "         \"props\": [(\"text-align\", \"center\"), (\"padding\", \"4px 8px\")]},\n",
    "        {\"selector\": \"th.index_name\",\n",
    "         \"props\": [(\"text-align\", \"center\"), (\"padding\", \"4px 8px\")]},\n",
    "    ]\n",
    "\n",
    "    if not hasattr(df.index, \"get_level_values\"):\n",
    "        return df.style.set_table_styles(base_styles)\n",
    "\n",
    "    groups = list(df.index.get_level_values(0))\n",
    "    group_idx = 0\n",
    "    row_in_group = 0\n",
    "    for i, g in enumerate(groups):\n",
    "        if i > 0 and g != groups[i - 1]:\n",
    "            group_idx = 1 - group_idx\n",
    "            row_in_group = 0\n",
    "        palette = _GROUP_COLORS[group_idx]\n",
    "        color = palette[row_in_group % 2]\n",
    "        # nth-child is 1-indexed; target both td and th in that row\n",
    "        base_styles.append({\n",
    "            \"selector\": f\"tbody tr:nth-child({i + 1})\",\n",
    "            \"props\": [(\"background-color\", color)],\n",
    "        })\n",
    "        row_in_group += 1\n",
    "\n",
    "    return df.style.set_table_styles(base_styles)\n",
    "\n",
    "print(\"make_comparison_table(), build_unified_results_table(), style_results_table() defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Qwen2.5-Math-7B-Instruct (Non-Thinking) ──────────────────────────────────\n",
    "\n",
    "_QWEN25_DATASETS = [\"MATH-500\", \"OlympiadBench\", \"Minerva Math\", \"Gaokao 2023 EN\"]\n",
    "_model_df = agg_df[agg_df[\"model\"] == \"qwen25_math_7b_instruct\"].copy()\n",
    "\n",
    "# Exclude beam search (mean, window=all) — incomplete runs\n",
    "_bs_exclude = (\n",
    "    (_model_df[\"strategy\"] == \"beam_search\")\n",
    "    & (_model_df[\"aggregation\"] == \"mean\")\n",
    "    & (_model_df[\"scoring_window\"].isna() | _model_df[\"scoring_window\"].astype(str).isin([\"all\", \"nan\", \"None\"]))\n",
    ")\n",
    "_model_df = _model_df[~_bs_exclude].copy()\n",
    "\n",
    "# For offline BoN, keep only UHead (multi_scorer results come from candidates analysis)\n",
    "_bon_non_uhead = (\n",
    "    (_model_df[\"strategy\"] == \"offline_best_of_n\")\n",
    "    & (_model_df[\"scorer\"] != \"uhead\")\n",
    ")\n",
    "_model_df = _model_df[~_bon_non_uhead].copy()\n",
    "print(f\"Qwen2.5-Math-7B-Instruct: {len(_model_df)} aggregated configs\")\n",
    "\n",
    "tbl = build_unified_results_table(\n",
    "    _model_df,\n",
    "    datasets=_QWEN25_DATASETS,\n",
    "    metrics=[\n",
    "        (\"exact_match_fmt\", \"EM (%)\"),\n",
    "        (\"llm_judge_accuracy_fmt\", \"LLM (%)\"),\n",
    "        (\"total_tflops_fmt\", \"TFLOPs\"),\n",
    "    ],\n",
    "    strategy_order=[\n",
    "        \"baseline\", \"self_consistency\",\n",
    "        \"offline_best_of_n\", \"beam_search\", \"adaptive\",\n",
    "    ],\n",
    ")\n",
    "display(style_results_table(tbl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Qwen2.5-Math-7B-Instruct — Core Metric Only ─────────────────────────────\n",
    "# EM (%) for all math datasets (single column per dataset, no LLM distraction)\n",
    "\n",
    "_model_df = agg_df[agg_df[\"model\"] == \"qwen25_math_7b_instruct\"].copy()\n",
    "_bs_exclude = (\n",
    "    (_model_df[\"strategy\"] == \"beam_search\")\n",
    "    & (_model_df[\"aggregation\"] == \"mean\")\n",
    "    & (_model_df[\"scoring_window\"].isna() | _model_df[\"scoring_window\"].astype(str).isin([\"all\", \"nan\", \"None\"]))\n",
    ")\n",
    "_model_df = _model_df[~_bs_exclude].copy()\n",
    "_bon_non_uhead = (\n",
    "    (_model_df[\"strategy\"] == \"offline_best_of_n\")\n",
    "    & (_model_df[\"scorer\"] != \"uhead\")\n",
    ")\n",
    "_model_df = _model_df[~_bon_non_uhead].copy()\n",
    "\n",
    "tbl_core = build_unified_results_table(\n",
    "    _model_df,\n",
    "    datasets=[\"MATH-500\", \"OlympiadBench\", \"Minerva Math\", \"Gaokao 2023 EN\"],\n",
    "    metrics=[\n",
    "        (\"exact_match_fmt\", \"EM (%)\"),\n",
    "        (\"total_tflops_fmt\", \"TFLOPs\"),\n",
    "    ],\n",
    "    strategy_order=[\n",
    "        \"baseline\", \"self_consistency\",\n",
    "        \"offline_best_of_n\", \"beam_search\", \"adaptive\",\n",
    "    ],\n",
    ")\n",
    "display(style_results_table(tbl_core))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Qwen3-8B (Thinking Mode) ──────────────────────────────────────────────────\n",
    "\n",
    "_QWEN3_DATASETS = [\"AIME 2024\", \"AIME 2025\", \"HumanEval-Plus\"]\n",
    "_model_df = agg_df[agg_df[\"model\"].isin([\"vllm_thinking_qwen3_8b\", \"qwen3_8b\"])].copy()\n",
    "\n",
    "# Exclude beam search variants: keep only (min, window=5)\n",
    "_bs_mask = _model_df[\"strategy\"] == \"beam_search\"\n",
    "_bs_keep = (\n",
    "    (_model_df[\"aggregation\"] == \"min\")\n",
    "    & (_model_df[\"scoring_window\"].astype(str).isin([\"5\", \"5.0\"]))\n",
    ")\n",
    "_model_df = _model_df[~_bs_mask | _bs_keep].copy()\n",
    "\n",
    "print(f\"Qwen3-8B: {len(_model_df)} aggregated configs\")\n",
    "\n",
    "tbl = build_unified_results_table(\n",
    "    _model_df,\n",
    "    datasets=_QWEN3_DATASETS,\n",
    "    metrics=[\n",
    "        (\"exact_match_fmt\", \"EM (%)\"),\n",
    "        (\"llm_judge_accuracy_fmt\", \"LLM (%)\"),\n",
    "        (\"total_tflops_fmt\", \"TFLOPs\"),\n",
    "    ],\n",
    "    strategy_order=[\n",
    "        \"baseline\", \"extended_thinking\", \"self_consistency\",\n",
    "        \"beam_search\", \"adaptive\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# HumanEval-Plus: replace EM with humaneval_score, drop LLM, keep TFLOPs\n",
    "_he_tbl = build_unified_results_table(\n",
    "    _model_df,\n",
    "    datasets=[\"HumanEval-Plus\"],\n",
    "    metrics=[\n",
    "        (\"humaneval_score_fmt\", \"Score (%)\"),\n",
    "        (\"total_tflops_fmt\", \"TFLOPs\"),\n",
    "    ],\n",
    "    strategy_order=[\n",
    "        \"baseline\", \"extended_thinking\", \"self_consistency\",\n",
    "        \"beam_search\", \"adaptive\",\n",
    "    ],\n",
    ")\n",
    "# Drop HumanEval EM, LLM, TFLOPs columns and replace with Score + TFLOPs\n",
    "tbl = tbl.drop(columns=[(\"HumanEval-Plus\", \"EM (%)\"), (\"HumanEval-Plus\", \"LLM (%)\"), (\"HumanEval-Plus\", \"TFLOPs\")])\n",
    "if not _he_tbl.empty:\n",
    "    tbl[(\"HumanEval-Plus\", \"Score (%)\")] = _he_tbl[(\"HumanEval-Plus\", \"Score (%)\")]\n",
    "    tbl[(\"HumanEval-Plus\", \"TFLOPs\")] = _he_tbl[(\"HumanEval-Plus\", \"TFLOPs\")]\n",
    "# Reorder columns to keep HumanEval-Plus last\n",
    "_col_order = [(ds, m) for ds, m in tbl.columns if ds != \"HumanEval-Plus\"] + \\\n",
    "             [(\"HumanEval-Plus\", \"Score (%)\"), (\"HumanEval-Plus\", \"TFLOPs\")]\n",
    "tbl = tbl[[c for c in _col_order if c in tbl.columns]]\n",
    "tbl.columns = pd.MultiIndex.from_tuples(tbl.columns, names=[\"Dataset\", \"Metric\"])\n",
    "\n",
    "display(style_results_table(tbl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Qwen3-8B — Core Metric Only ──────────────────────────────────────────────\n",
    "# EM (%) for AIME, Score (%) for HumanEval-Plus\n",
    "\n",
    "_model_df = agg_df[agg_df[\"model\"].isin([\"vllm_thinking_qwen3_8b\", \"qwen3_8b\"])].copy()\n",
    "_bs_mask = _model_df[\"strategy\"] == \"beam_search\"\n",
    "_bs_keep = (\n",
    "    (_model_df[\"aggregation\"] == \"min\")\n",
    "    & (_model_df[\"scoring_window\"].astype(str).isin([\"5\", \"5.0\"]))\n",
    ")\n",
    "_model_df = _model_df[~_bs_mask | _bs_keep].copy()\n",
    "\n",
    "# AIME datasets use exact_match_fmt + TFLOPs\n",
    "tbl_core = build_unified_results_table(\n",
    "    _model_df,\n",
    "    datasets=[\"AIME 2024\", \"AIME 2025\"],\n",
    "    metrics=[\n",
    "        (\"exact_match_fmt\", \"EM (%)\"),\n",
    "        (\"total_tflops_fmt\", \"TFLOPs\"),\n",
    "    ],\n",
    "    strategy_order=[\n",
    "        \"baseline\", \"extended_thinking\", \"self_consistency\",\n",
    "        \"beam_search\", \"adaptive\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# HumanEval-Plus uses humaneval_score_fmt + TFLOPs\n",
    "_he_core = build_unified_results_table(\n",
    "    _model_df,\n",
    "    datasets=[\"HumanEval-Plus\"],\n",
    "    metrics=[\n",
    "        (\"humaneval_score_fmt\", \"Score (%)\"),\n",
    "        (\"total_tflops_fmt\", \"TFLOPs\"),\n",
    "    ],\n",
    "    strategy_order=[\n",
    "        \"baseline\", \"extended_thinking\", \"self_consistency\",\n",
    "        \"beam_search\", \"adaptive\",\n",
    "    ],\n",
    ")\n",
    "if not _he_core.empty:\n",
    "    tbl_core = pd.concat([tbl_core, _he_core], axis=1)\n",
    "display(style_results_table(tbl_core))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── gpt-4o-mini ───────────────────────────────────────────────────────────────\n",
    "\n",
    "_GPT_DATASETS = [\"GPQA Diamond\"]\n",
    "_model_df = agg_df[agg_df[\"model\"] == \"gpt4o_mini\"].copy()\n",
    "print(f\"gpt-4o-mini: {len(_model_df)} aggregated configs\")\n",
    "\n",
    "tbl = build_unified_results_table(\n",
    "    _model_df,\n",
    "    datasets=_GPT_DATASETS,\n",
    "    metrics=[\n",
    "        (\"exact_match_fmt\", \"EM (%)\"),\n",
    "        (\"llm_judge_accuracy_fmt\", \"LLM (%)\"),\n",
    "    ],\n",
    "    strategy_order=[\n",
    "        \"baseline\", \"self_consistency\", \"offline_best_of_n\", \"adaptive\",\n",
    "    ],\n",
    ")\n",
    "display(style_results_table(tbl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── LaTeX Export ──────────────────────────────────────────────────────────────\n",
    "\n",
    "def to_latex(df: pd.DataFrame, caption: str, label: str) -> str:\n",
    "    \"\"\"Convert a DataFrame to a booktabs LaTeX table string.\"\"\"\n",
    "    latex = df.to_latex(\n",
    "        index=True,\n",
    "        escape=True,\n",
    "        na_rep=\"--\",\n",
    "        caption=caption,\n",
    "        label=label,\n",
    "        position=\"htbp\",\n",
    "    )\n",
    "    return latex\n",
    "\n",
    "\n",
    "beam_df = agg_df[agg_df[\"strategy\"] == \"beam_search\"].copy()\n",
    "\n",
    "# Re-generate tables and export as LaTeX\n",
    "latex_outputs = []\n",
    "\n",
    "# Strategy x Scorer tables\n",
    "for dataset_label in sorted(agg_df[\"project_label\"].dropna().unique()):\n",
    "    tbl = make_comparison_table(\n",
    "        agg_df,\n",
    "        row_field=\"scorer\",\n",
    "        col_field=\"strategy\",\n",
    "        value_field=\"exact_match_fmt\",\n",
    "        filter_dict={\"project_label\": dataset_label},\n",
    "    )\n",
    "    if not tbl.empty:\n",
    "        ltx = to_latex(\n",
    "            tbl,\n",
    "            caption=f\"Exact match accuracy (\\\\%) by strategy and scorer on {dataset_label}.\",\n",
    "            label=f\"tab:strategy_scorer_{dataset_label}\",\n",
    "        )\n",
    "        latex_outputs.append((f\"Strategy x Scorer \\u2014 {dataset_label}\", ltx))\n",
    "\n",
    "# Beam search aggregation x window tables\n",
    "if not beam_df.empty:\n",
    "    for scorer in sorted(beam_df[\"scorer\"].dropna().unique()):\n",
    "        for dataset_label in sorted(beam_df[\"project_label\"].dropna().unique()):\n",
    "            tbl = make_comparison_table(\n",
    "                beam_df,\n",
    "                row_field=\"aggregation\",\n",
    "                col_field=\"scoring_window\",\n",
    "                value_field=\"exact_match_fmt\",\n",
    "                filter_dict={\"scorer\": scorer, \"project_label\": dataset_label},\n",
    "            )\n",
    "            if not tbl.empty:\n",
    "                ltx = to_latex(\n",
    "                    tbl,\n",
    "                    caption=f\"Beam search accuracy (\\\\%) \\u2014 scorer={scorer}, dataset={dataset_label}.\",\n",
    "                    label=f\"tab:beam_{scorer}_{dataset_label}\",\n",
    "                )\n",
    "                latex_outputs.append((f\"Beam {scorer} \\u2014 {dataset_label}\", ltx))\n",
    "\n",
    "# Print all LaTeX\n",
    "for title, ltx in latex_outputs:\n",
    "    print(f\"% \\u2500\\u2500 {title} \" + \"\\u2500\" * max(1, 60 - len(title)))\n",
    "    print(ltx)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Visualization ─────────────────────────────────────────────────────────────\n",
    "\n",
    "# Bar chart: accuracy by strategy (per dataset)\n",
    "plot_df = agg_df.dropna(subset=[\"exact_match_mean\"]).copy()\n",
    "\n",
    "if not plot_df.empty:\n",
    "    fig, axes = plt.subplots(\n",
    "        1, max(1, plot_df[\"project_label\"].nunique()),\n",
    "        figsize=(6 * max(1, plot_df[\"project_label\"].nunique()), 5),\n",
    "        squeeze=False,\n",
    "    )\n",
    "    for idx, dataset_label in enumerate(sorted(plot_df[\"project_label\"].unique())):\n",
    "        ax = axes[0, idx]\n",
    "        sub = plot_df[plot_df[\"project_label\"] == dataset_label]\n",
    "        # Average across scorers/configs per strategy\n",
    "        bars = sub.groupby(\"strategy\")[\"exact_match_mean\"].mean().sort_values()\n",
    "        bars.plot.barh(ax=ax, color=\"steelblue\")\n",
    "        ax.set_xlabel(\"Exact Match (%)\")\n",
    "        ax.set_title(dataset_label)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data for bar chart.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Heatmap: beam search scorer x aggregation x window\n",
    "\n",
    "# beam_df = agg_df[agg_df[\"strategy\"] == \"beam_search\"].copy()\n",
    "\n",
    "# if sns is None:\n",
    "#     print(\"Install seaborn for heatmap visualization: pip install seaborn\")\n",
    "# elif not beam_df.empty:\n",
    "#     heat_df = beam_df.dropna(subset=[\"exact_match_mean\"]).copy()\n",
    "#     heat_df[\"config\"] = heat_df[\"aggregation\"].astype(str) + \" / w=\" + heat_df[\"scoring_window\"].astype(str)\n",
    "\n",
    "#     for dataset_label in sorted(heat_df[\"project_label\"].dropna().unique()):\n",
    "#         sub = heat_df[heat_df[\"project_label\"] == dataset_label]\n",
    "#         if sub.empty:\n",
    "#             continue\n",
    "#         pivot = sub.pivot_table(\n",
    "#             index=\"config\", columns=\"scorer\",\n",
    "#             values=\"exact_match_mean\", aggfunc=\"first\",\n",
    "#         )\n",
    "#         if pivot.empty:\n",
    "#             continue\n",
    "\n",
    "#         fig, ax = plt.subplots(figsize=(max(6, pivot.shape[1] * 2), max(4, pivot.shape[0] * 0.6)))\n",
    "#         sns.heatmap(pivot, annot=True, fmt=\".1f\", cmap=\"YlGnBu\", ax=ax)\n",
    "#         ax.set_title(f\"Beam Search Accuracy — {dataset_label}\")\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "# else:\n",
    "#     print(\"No beam search data for heatmap.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline BoN Multi-Scorer Analysis\n",
    "\n",
    "Download `candidates.json` from multi-scorer offline BoN runs and re-analyze\n",
    "with different scorers, aggregation methods, and scoring windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json as _json\n",
    "from pathlib import Path as _Path\n",
    "\n",
    "# Add project root and scripts/ to path so we can import analyze_candidates\n",
    "_project_root = _Path.cwd().parent if _Path.cwd().name == \"notebooks\" else _Path.cwd()\n",
    "for _p in [str(_project_root), str(_project_root / \"scripts\")]:\n",
    "    if _p not in sys.path:\n",
    "        sys.path.insert(0, _p)\n",
    "\n",
    "# Suppress ANTLR version mismatch spam (bare print() in Recognizer.checkVersion)\n",
    "import antlr4\n",
    "\n",
    "def _noop_check(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "antlr4.Recognizer.checkVersion = _noop_check\n",
    "\n",
    "import analyze_candidates as _ac_mod\n",
    "import importlib\n",
    "importlib.reload(_ac_mod)\n",
    "\n",
    "from analyze_candidates import (\n",
    "    aggregate_scores,\n",
    "    select_best_candidate,\n",
    "    precompute_correctness,\n",
    "    analyze,\n",
    "    analyze_windows,\n",
    "    _save_csv,\n",
    ")\n",
    "\n",
    "print(\"Imported analyze_candidates functions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Offline BoN Registry ──────────────────────────────────────────────────────\n",
    "# Maps run lists → (data_name, answer_format, display_label) for candidates.json analysis.\n",
    "\n",
    "OFFLINE_BON_REGISTRY = [\n",
    "    (MATH500_OFFLINE_BON_RUNS, \"math500\", \"numeric\", \"MATH-500\"),\n",
    "    (MINERVA_OFFLINE_BON_RUNS, \"minerva_math\", \"numeric\", \"Minerva Math\"),\n",
    "    (GAOKAO_OFFLINE_BON_RUNS, \"gaokao2023en\", \"numeric\", \"Gaokao 2023 EN\"),\n",
    "    (OLYMPIAD_OFFLINE_BON_RUNS, \"olympiadbench\", \"numeric\", \"OlympiadBench\"),\n",
    "    (AIME_24_OFFLINE_BON_RUNS, \"aime2024\", \"numeric\", \"AIME 2024\"),\n",
    "    (AIME_25_OFFLINE_BON_RUNS, \"aime2025\", \"numeric\", \"AIME 2025\"),\n",
    "    (HUMANEVAL_OFFLINE_BON_RUNS, \"human_eval_plus\", \"code\", \"HumanEval-Plus\"),\n",
    "    # (GPQA_OFFLINE_BON_RUNS, \"gpqa_diamond\", \"char\", \"GPQA Diamond\"),\n",
    "]\n",
    "\n",
    "print(f\"Registry: {len(OFFLINE_BON_REGISTRY)} dataset(s)\")\n",
    "for run_list, dname, fmt, label in OFFLINE_BON_REGISTRY:\n",
    "    n_runs = sum(len(e.get(\"runs\", [])) for e in run_list if e.get(\"group_url\"))\n",
    "    print(f\"  {label}: {n_runs} run(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Download candidates.json from wandb ───────────────────────────────────────\n",
    "\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "CANDIDATES_CACHE_DIR = _Path(\"cache/candidates\")\n",
    "\n",
    "\n",
    "def download_candidates(run_id: str, entity: str, project: str,\n",
    "                        data_name: str, seed: int) -> _Path:\n",
    "    \"\"\"Download candidates.json for a run, with disk caching.\"\"\"\n",
    "    cache_path = CANDIDATES_CACHE_DIR / data_name / f\"seed_{seed}\" / run_id\n",
    "    candidates_file = cache_path / \"candidates.json\"\n",
    "\n",
    "    if candidates_file.exists():\n",
    "        return candidates_file\n",
    "\n",
    "    cache_path.mkdir(parents=True, exist_ok=True)\n",
    "    run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "\n",
    "    # Download to a temp dir then move (atomic-ish)\n",
    "    with tempfile.TemporaryDirectory() as tmp:\n",
    "        try:\n",
    "            f = run.file(\"candidates.json\")\n",
    "            f.download(root=tmp, replace=True)\n",
    "            src = _Path(tmp) / \"candidates.json\"\n",
    "            shutil.move(str(src), str(candidates_file))\n",
    "            print(f\"  Downloaded → {candidates_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR downloading candidates.json for {run_id}: {e}\")\n",
    "            return None\n",
    "\n",
    "    return candidates_file\n",
    "\n",
    "\n",
    "# Download all candidates.json files\n",
    "candidates_store = {}   # (data_name, seed) -> list[dict]\n",
    "run_meta = {}           # (data_name, seed) -> metadata dict\n",
    "\n",
    "for run_list, data_name, answer_format, project_label in OFFLINE_BON_REGISTRY:\n",
    "    print(f\"\\n{project_label} ({data_name})\")\n",
    "    for entry in run_list:\n",
    "        if not entry.get(\"group_url\") or not entry.get(\"runs\"):\n",
    "            continue\n",
    "        for run_entry in entry[\"runs\"]:\n",
    "            seed = run_entry[\"seed\"]\n",
    "            run_url = run_entry.get(\"run_url\", \"\")\n",
    "            if not run_url:\n",
    "                continue\n",
    "            info = parse_run_url(run_url)\n",
    "            cpath = download_candidates(\n",
    "                info[\"run_id\"], info[\"entity\"], info[\"project\"],\n",
    "                data_name, seed,\n",
    "            )\n",
    "            if cpath and cpath.exists():\n",
    "                with open(cpath) as fh:\n",
    "                    data = _json.load(fh)\n",
    "                candidates_store[(data_name, seed)] = data\n",
    "                run_meta[(data_name, seed)] = {\n",
    "                    \"project_label\": project_label,\n",
    "                    \"answer_format\": answer_format,\n",
    "                    \"data_name\": data_name,\n",
    "                    \"run_id\": info[\"run_id\"],\n",
    "                }\n",
    "                print(f\"  seed={seed}  samples={len(data)}\")\n",
    "\n",
    "print(f\"\\nLoaded {len(candidates_store)} candidate file(s)\")\n",
    "\n",
    "# Enrich run_meta with wandb summary metrics (EM, LLM judge, HumanEval score)\n",
    "_enriched = 0\n",
    "for (data_name, seed), meta in run_meta.items():\n",
    "    rid = meta[\"run_id\"]\n",
    "    match = raw_df[raw_df[\"run_id\"] == rid]\n",
    "    if match.empty:\n",
    "        continue\n",
    "    r = match.iloc[0]\n",
    "    meta[\"wandb_exact_match\"] = r.get(\"exact_match\")\n",
    "    meta[\"wandb_total_tflops\"] = r.get(\"total_tflops\")\n",
    "    meta[\"wandb_llm_accuracy\"] = r.get(\"llm_judge_accuracy\")\n",
    "    meta[\"wandb_humaneval_correct\"] = r.get(\"humaneval_correct\")\n",
    "    meta[\"wandb_humaneval_incorrect\"] = r.get(\"humaneval_incorrect\")\n",
    "    _hc, _hi = r.get(\"humaneval_correct\"), r.get(\"humaneval_incorrect\")\n",
    "    if pd.notna(_hc) and pd.notna(_hi) and (_hc + _hi) > 0:\n",
    "        meta[\"wandb_humaneval_score\"] = _hc / (_hc + _hi)\n",
    "    else:\n",
    "        meta[\"wandb_humaneval_score\"] = None\n",
    "    _enriched += 1\n",
    "print(f\"Enriched {_enriched}/{len(run_meta)} run_meta entries with wandb metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Multi-scorer analysis across all windows ──────────────────────────────────\n",
    "# Computes accuracy for every (scorer × aggregation × window) combo per dataset/seed.\n",
    "# Cached: skips analysis if scoring_analysis.csv already exists next to candidates.json.\n",
    "\n",
    "import csv\n",
    "\n",
    "bon_records = []\n",
    "\n",
    "for (data_name, seed), candidates_data in tqdm(sorted(candidates_store.items()), desc=\"Analyzing\"):\n",
    "    meta = run_meta[(data_name, seed)]\n",
    "    label = meta[\"project_label\"]\n",
    "    run_cache = CANDIDATES_CACHE_DIR / data_name / f\"seed_{seed}\" / meta[\"run_id\"]\n",
    "    csv_path = run_cache / \"scoring_analysis.csv\"\n",
    "\n",
    "    if csv_path.exists():\n",
    "        # Load cached results\n",
    "        with open(csv_path) as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                bon_records.append({\n",
    "                    \"dataset\": label,\n",
    "                    \"data_name\": data_name,\n",
    "                    \"seed\": seed,\n",
    "                    \"scorer\": row[\"scorer\"],\n",
    "                    \"aggregation\": row[\"aggregation\"] or \"—\",\n",
    "                    \"window\": row[\"window\"] or \"all\",\n",
    "                    \"exact_match\": float(row[\"exact_match\"]) * 100,\n",
    "                    \"humaneval_score\": meta.get(\"wandb_humaneval_score\"),\n",
    "                    \"total_tflops\": meta.get(\"wandb_total_tflops\"),\n",
    "                })\n",
    "        print(f\"{label} seed={seed}: loaded from {csv_path}\")\n",
    "        continue\n",
    "\n",
    "    # Run analysis\n",
    "    all_results, correctness, oracle_acc, max_steps = analyze_windows(\n",
    "        candidates_data, data_name, meta[\"answer_format\"],\n",
    "        windows=[None, 1, 3, 5, 10, 15, 20, 30, 50],\n",
    "\n",
    "    )\n",
    "    print(f\"{label} seed={seed}: {len(candidates_data)} samples, \"\n",
    "          f\"max_steps={max_steps}, oracle={oracle_acc*100:.1f}%\")\n",
    "\n",
    "    # Save CSV next to candidates.json\n",
    "    _save_csv(all_results, csv_path, oracle_acc=oracle_acc)\n",
    "\n",
    "    for window_label, scorer_dict in all_results.items():\n",
    "        wval = window_label.split(\"=\", 1)[1]\n",
    "        for scorer, agg_dict in scorer_dict.items():\n",
    "            for agg_method, accuracy in agg_dict.items():\n",
    "                bon_records.append({\n",
    "                    \"dataset\": label,\n",
    "                    \"data_name\": data_name,\n",
    "                    \"seed\": seed,\n",
    "                    \"scorer\": scorer,\n",
    "                    \"aggregation\": agg_method,\n",
    "                    \"window\": wval,\n",
    "                    \"exact_match\": accuracy * 100,\n",
    "                    \"humaneval_score\": meta.get(\"wandb_humaneval_score\"),\n",
    "                    \"total_tflops\": meta.get(\"wandb_total_tflops\"),\n",
    "                })\n",
    "        bon_records.append({\n",
    "            \"dataset\": label,\n",
    "            \"data_name\": data_name,\n",
    "            \"seed\": seed,\n",
    "            \"scorer\": \"oracle\",\n",
    "            \"aggregation\": \"—\",\n",
    "            \"window\": wval,\n",
    "            \"exact_match\": oracle_acc * 100,\n",
    "            \"humaneval_score\": meta.get(\"wandb_humaneval_score\"),\n",
    "            \"total_tflops\": meta.get(\"wandb_total_tflops\"),\n",
    "        })\n",
    "\n",
    "bon_analysis_df = pd.DataFrame(bon_records)\n",
    "print(f\"\\nTotal records: {len(bon_analysis_df)}\")\n",
    "bon_analysis_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Recalculate PRM TFLOPs (missing from multi-scorer runs) ──────────────────\n",
    "# Bug: strategy_offline_best_of_n.py merges PRM TFLOPs only from self.scorer\n",
    "# (the primary scorer).  In multi-scorer mode the primary scorer is an\n",
    "# uncertainty metric, and PRM runs via self.prm_scorer — whose TFLOPs are\n",
    "# never merged into the reported total_tflops.\n",
    "#\n",
    "# Fix: reconstruct PRM prompts from candidates.json, count tokens with the\n",
    "# actual PRM tokenizer, and add the PRM TFLOPs to the PRM scorer rows.\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "_PRM_MODEL_NAME   = \"Qwen/Qwen2.5-Math-PRM-7B\"\n",
    "_PRM_MODEL_PARAMS = 7e9          # 7 B parameters\n",
    "_PRM_MAX_TOKENS   = 4000         # config/scorer/prm.yaml\n",
    "_PRM_MODEL_MAX_LEN = 4096        # max_position_embeddings\n",
    "\n",
    "print(f\"Loading PRM tokenizer ({_PRM_MODEL_NAME}) ...\")\n",
    "_prm_tok = AutoTokenizer.from_pretrained(\n",
    "    _PRM_MODEL_NAME, trust_remote_code=True,\n",
    ")\n",
    "print(\"  done.\\n\")\n",
    "\n",
    "\n",
    "# ── helpers (mirror step_scorer_prm.py) ──────────────────────────────────────\n",
    "\n",
    "def _fmt_prm_prompt(question: str, step_texts: list, tokenizer) -> str:\n",
    "    \"\"\"Replicate StepScorerPRM._format_prm_prompt.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"Please reason step by step, and put your final answer within \\\\boxed{}.\"},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "        {\"role\": \"assistant\",\n",
    "         \"content\": \"<extra_0>\".join(step_texts) + \"<extra_0>\"},\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def _count_prm_tokens(question: str, step_texts: list, tokenizer,\n",
    "                      max_tokens: int = _PRM_MAX_TOKENS) -> int:\n",
    "    \"\"\"Count PRM input tokens with tail truncation.\n",
    "\n",
    "    Replicates _truncate_steps_from_tail from step_scorer_prm.py line 824.\n",
    "    \"\"\"\n",
    "    if not step_texts:\n",
    "        return 0\n",
    "\n",
    "    # Frame overhead (system + user + assistant wrapper, no steps)\n",
    "    frame_prompt = _fmt_prm_prompt(question, [], tokenizer)\n",
    "    frame_tokens = len(tokenizer.encode(frame_prompt)) - 1   # trailing <extra_0>\n",
    "\n",
    "    # Per-step token costs (+1 for <extra_0> separator)\n",
    "    step_costs = [len(tokenizer.encode(s)) + 1 for s in step_texts]\n",
    "    budget = max_tokens - frame_tokens - 10                    # safety margin\n",
    "\n",
    "    # Walk backward from last step, include as many as fit\n",
    "    total_cost = 0\n",
    "    first_included_idx = len(step_texts)\n",
    "    for i in range(len(step_texts) - 1, -1, -1):\n",
    "        if total_cost + step_costs[i] <= budget:\n",
    "            total_cost += step_costs[i]\n",
    "            first_included_idx = i\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Edge case: force-include last step even if it exceeds budget\n",
    "    if first_included_idx == len(step_texts) and step_texts:\n",
    "        first_included_idx = len(step_texts) - 1\n",
    "\n",
    "    included_steps = step_texts[first_included_idx:]\n",
    "    prompt = _fmt_prm_prompt(question, included_steps, tokenizer)\n",
    "    n_tokens = len(tokenizer.encode(prompt))\n",
    "\n",
    "    # Hard truncate at model max_position_embeddings\n",
    "    return min(n_tokens, _PRM_MODEL_MAX_LEN)\n",
    "\n",
    "\n",
    "# ── compute per-(dataset, seed) PRM TFLOPs ──────────────────────────────────\n",
    "\n",
    "_PRM_CACHE_CSV = _Path(\"cache/prm_tflops_by_run.csv\")\n",
    "\n",
    "if _PRM_CACHE_CSV.exists():\n",
    "    import csv\n",
    "    prm_tflops_by_run = {}\n",
    "    with open(_PRM_CACHE_CSV) as f:\n",
    "        for row in csv.DictReader(f):\n",
    "            prm_tflops_by_run[(row[\"data_name\"], int(row[\"seed\"]))] = float(row[\"prm_tflops\"])\n",
    "    print(f\"Loaded {len(prm_tflops_by_run)} PRM TFLOPs entries from {_PRM_CACHE_CSV}\")\n",
    "else:\n",
    "    prm_tflops_by_run = {}\n",
    "\n",
    "    for (data_name, seed), cands in tqdm(\n",
    "        sorted(candidates_store.items()), desc=\"Computing PRM TFLOPs\",\n",
    "    ):\n",
    "        total_prm_tokens = 0\n",
    "        n_scored = 0\n",
    "        for sample in cands:\n",
    "            question = sample[\"question\"]\n",
    "            for cand in sample[\"candidates\"]:\n",
    "                if \"prm\" not in cand.get(\"scores\", {}):\n",
    "                    continue\n",
    "                total_prm_tokens += _count_prm_tokens(\n",
    "                    question, cand[\"steps\"], _prm_tok,\n",
    "                )\n",
    "                n_scored += 1\n",
    "\n",
    "        prm_tflops = 2 * _PRM_MODEL_PARAMS * total_prm_tokens / 1e12\n",
    "        prm_tflops_by_run[(data_name, seed)] = prm_tflops\n",
    "        print(\n",
    "            f\"  {data_name:20s} seed={seed}: {n_scored:5d} candidates, \"\n",
    "            f\"PRM tokens={total_prm_tokens:>10,}, PRM TFLOPs={prm_tflops:>10,.1f}\"\n",
    "        )\n",
    "\n",
    "    # Save to CSV cache\n",
    "    import csv\n",
    "    _PRM_CACHE_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(_PRM_CACHE_CSV, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"data_name\", \"seed\", \"prm_tflops\"])\n",
    "        for (dn, sd), tf in sorted(prm_tflops_by_run.items()):\n",
    "            w.writerow([dn, sd, tf])\n",
    "    print(f\"\\nSaved PRM TFLOPs cache to {_PRM_CACHE_CSV}\")\n",
    "\n",
    "\n",
    "# ── patch bon_analysis_df: add PRM TFLOPs to PRM scorer rows ────────────────\n",
    "\n",
    "_patched = 0\n",
    "for idx, row in bon_analysis_df.iterrows():\n",
    "    if row[\"scorer\"] != \"prm\":\n",
    "        continue\n",
    "    key = (row[\"data_name\"], row[\"seed\"])\n",
    "    if key not in prm_tflops_by_run:\n",
    "        continue\n",
    "    old_tf = row[\"total_tflops\"]\n",
    "    if pd.notna(old_tf):\n",
    "        bon_analysis_df.at[idx, \"total_tflops\"] = old_tf + prm_tflops_by_run[key]\n",
    "        _patched += 1\n",
    "\n",
    "print(f\"\\nPatched {_patched} PRM rows in bon_analysis_df\")\n",
    "\n",
    "# Show before/after comparison\n",
    "print(f\"\\n{'Dataset':>20s}  {'Seed':>4s}  {'Gen TFLOPs':>12s}  {'PRM TFLOPs':>12s}  {'Total':>12s}  {'PRM %':>6s}\")\n",
    "print(\"─\" * 75)\n",
    "for key in sorted(prm_tflops_by_run.keys()):\n",
    "    meta = run_meta.get(key)\n",
    "    gen_tf = meta.get(\"wandb_total_tflops\", 0) if meta else 0\n",
    "    prm_tf = prm_tflops_by_run[key]\n",
    "    total = gen_tf + prm_tf\n",
    "    pct = prm_tf / total * 100 if total > 0 else 0\n",
    "    print(\n",
    "        f\"{key[0]:>20s}  {key[1]:>4d}  {gen_tf:>12,.1f}  {prm_tf:>12,.1f}  \"\n",
    "        f\"{total:>12,.1f}  {pct:>5.1f}%\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Aggregate offline BoN results across seeds ────────────────────────────────\n",
    "\n",
    "bon_agg_df = (\n",
    "    bon_analysis_df\n",
    "    .groupby([\"dataset\", \"scorer\", \"aggregation\", \"window\"])\n",
    "    .agg(\n",
    "        exact_match_mean=(\"exact_match\", \"mean\"),\n",
    "        exact_match_std=(\"exact_match\", \"std\"),\n",
    "        exact_match_count=(\"exact_match\", \"count\"),\n",
    "        humaneval_score_mean=(\"humaneval_score\", \"mean\"),\n",
    "        total_tflops_mean=(\"total_tflops\", \"mean\"),\n",
    "        total_tflops_std=(\"total_tflops\", \"std\"),\n",
    "        total_tflops_count=(\"total_tflops\", \"count\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "bon_agg_df[\"exact_match_fmt\"] = bon_agg_df.apply(\n",
    "    lambda r: (\n",
    "        f\"{r['exact_match_mean']:.1f} ± {r['exact_match_std']:.1f}\"\n",
    "        if pd.notna(r[\"exact_match_std\"]) and r[\"exact_match_count\"] > 1\n",
    "        else f\"{r['exact_match_mean']:.1f}\"\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "bon_agg_df[\"humaneval_score_fmt\"] = bon_agg_df.apply(\n",
    "    lambda r: f\"{r['humaneval_score_mean']*100:.1f}\" if pd.notna(r[\"humaneval_score_mean\"]) else \"\",\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "bon_agg_df[\"total_tflops_fmt\"] = bon_agg_df.apply(\n",
    "    lambda r: (\n",
    "        f\"{r['total_tflops_mean']:.1f} ± {r['total_tflops_std']:.1f}\"\n",
    "        if pd.notna(r[\"total_tflops_std\"]) and r[\"total_tflops_count\"] > 1\n",
    "        else (f\"{r['total_tflops_mean']:.1f}\" if pd.notna(r[\"total_tflops_mean\"]) else \"\")\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "bon_agg_df[\"strategy\"] = \"offline_best_of_n\"\n",
    "\n",
    "print(f\"Aggregated: {len(bon_agg_df)} rows\")\n",
    "print(f\"Datasets:   {sorted(bon_agg_df['dataset'].unique())}\")\n",
    "print(f\"Scorers:    {sorted(bon_agg_df['scorer'].unique())}\")\n",
    "print(f\"Windows:    {sorted(bon_agg_df['window'].unique(), key=lambda w: (0, int(w)) if w != 'all' else (1, 0))}\")\n",
    "\n",
    "# Sanity check: show window=all, aggregation=mean — with baseline/self-consistency for reference\n",
    "# Uses same (Strategy, Scorer) MultiIndex format with (Dataset, Metric) columns\n",
    "\n",
    "_bon_sub = bon_agg_df[\n",
    "    (bon_agg_df[\"window\"] == \"all\") & (bon_agg_df[\"aggregation\"].isin([\"mean\", \"\\u2014\"]))\n",
    "].copy()\n",
    "\n",
    "_SCORER_ORDER = [\"oracle\", \"prm\", \"entropy\", \"perplexity\", \"sequence_prob\", \"pd_gap\"]\n",
    "\n",
    "_SANITY_GROUPS = {\n",
    "    \"Qwen2.5-Math-7B-Instruct\": [\"MATH-500\", \"OlympiadBench\", \"Minerva Math\", \"Gaokao 2023 EN\"],\n",
    "    \"Qwen3-8B\": [\"AIME 2024\", \"AIME 2025\", \"HumanEval-Plus\"],\n",
    "}\n",
    "\n",
    "# Per-dataset metric definitions: (metric_label, agg_df_col, bon_em_col, bon_ref_col)\n",
    "_DS_METRICS = {\n",
    "    \"HumanEval-Plus\": [\n",
    "        (\"Score (%)\", \"humaneval_score_fmt\", \"exact_match_fmt\", None),\n",
    "        (\"TFLOPs\", \"total_tflops_fmt\", \"total_tflops_fmt\", None),\n",
    "    ],\n",
    "}\n",
    "_DEFAULT_METRICS = [\n",
    "    (\"EM (%)\", \"exact_match_fmt\", \"exact_match_fmt\", None),\n",
    "    (\"TFLOPs\", \"total_tflops_fmt\", \"total_tflops_fmt\", None),\n",
    "]\n",
    "\n",
    "def _get_ds_metrics(ds):\n",
    "    return _DS_METRICS.get(ds, _DEFAULT_METRICS)\n",
    "\n",
    "for _name, _datasets in _SANITY_GROUPS.items():\n",
    "    rows = []\n",
    "    row_index = []\n",
    "\n",
    "    col_tuples = []\n",
    "    for ds in _datasets:\n",
    "        for ml, *_ in _get_ds_metrics(ds):\n",
    "            col_tuples.append((ds, ml))\n",
    "\n",
    "    # Baseline row\n",
    "    _bl = agg_df[agg_df[\"strategy\"] == \"baseline\"]\n",
    "    _bl_row = {}\n",
    "    for ds in _datasets:\n",
    "        m = _bl[_bl[\"project_label\"] == ds]\n",
    "        for ml, agg_col, _, _ in _get_ds_metrics(ds):\n",
    "            _bl_row[(ds, ml)] = m.iloc[0].get(agg_col, \"\") if not m.empty else \"\"\n",
    "    rows.append(_bl_row)\n",
    "    row_index.append((\"Baseline\", \"\\u2014\"))\n",
    "\n",
    "    # Self-consistency row\n",
    "    _sc = agg_df[agg_df[\"strategy\"] == \"self_consistency\"]\n",
    "    _sc_row = {}\n",
    "    for ds in _datasets:\n",
    "        m = _sc[_sc[\"project_label\"] == ds]\n",
    "        for ml, agg_col, _, _ in _get_ds_metrics(ds):\n",
    "            _sc_row[(ds, ml)] = m.iloc[0].get(agg_col, \"\") if not m.empty else \"\"\n",
    "    rows.append(_sc_row)\n",
    "    row_index.append((\"Self-Consistency\", \"\\u2014\"))\n",
    "\n",
    "    # Offline BoN per-scorer rows\n",
    "    for scorer in _SCORER_ORDER:\n",
    "        _sr = _bon_sub[_bon_sub[\"scorer\"] == scorer]\n",
    "        row = {}\n",
    "        for ds in _datasets:\n",
    "            m = _sr[_sr[\"dataset\"] == ds]\n",
    "            for ml, _, bon_col, bon_ref_col in _get_ds_metrics(ds):\n",
    "                if not m.empty:\n",
    "                    row[(ds, ml)] = m.iloc[0].get(bon_ref_col or bon_col, \"\")\n",
    "                else:\n",
    "                    row[(ds, ml)] = \"\"\n",
    "        rows.append(row)\n",
    "        row_index.append((\"Offline BoN\", scorer))\n",
    "\n",
    "    mi_rows = pd.MultiIndex.from_tuples(row_index, names=[\"Strategy\", \"Scorer\"])\n",
    "    mi_cols = pd.MultiIndex.from_tuples(col_tuples, names=[\"Dataset\", \"Metric\"])\n",
    "    tbl = pd.DataFrame(rows, index=mi_rows, columns=mi_cols)\n",
    "    print(f\"\\n{_name} (window=all, aggregation=mean)\")\n",
    "    display(style_results_table(tbl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Best scoring window per (scorer, aggregation) — averaged across datasets & seeds ──\n",
    "# For each model group, find the window that maximizes accuracy per (scorer, aggregation).\n",
    "# Window is chosen by averaging the core metric across datasets.\n",
    "\n",
    "# Core metric per dataset (used for averaging when selecting best window/aggregation)\n",
    "CORE_METRIC = {\n",
    "    \"MATH-500\": \"exact_match_fmt\",\n",
    "    \"OlympiadBench\": \"exact_match_fmt\",\n",
    "    \"Minerva Math\": \"exact_match_fmt\",\n",
    "    \"Gaokao 2023 EN\": \"exact_match_fmt\",\n",
    "    \"AIME 2024\": \"exact_match_fmt\",\n",
    "    \"AIME 2025\": \"exact_match_fmt\",\n",
    "    \"HumanEval-Plus\": \"humaneval_score_fmt\",\n",
    "}\n",
    "\n",
    "CORE_METRIC_LABEL = {\n",
    "    \"MATH-500\": \"EM (%)\",\n",
    "    \"OlympiadBench\": \"EM (%)\",\n",
    "    \"Minerva Math\": \"EM (%)\",\n",
    "    \"Gaokao 2023 EN\": \"EM (%)\",\n",
    "    \"AIME 2024\": \"EM (%)\",\n",
    "    \"AIME 2025\": \"EM (%)\",\n",
    "    \"HumanEval-Plus\": \"Score (%)\",\n",
    "}\n",
    "\n",
    "MODEL_GROUPS = {\n",
    "    \"Qwen2.5-Math-7B-Instruct\": [\"MATH-500\", \"OlympiadBench\", \"Gaokao 2023 EN\"],  # Minerva Math excluded (anomalous results)\n",
    "    \"Qwen3-8B\": [\"AIME 2024\", \"AIME 2025\", \"HumanEval-Plus\"],\n",
    "}\n",
    "\n",
    "AGGREGATIONS = [\"mean\", \"min\", \"max\", \"product\"]\n",
    "CANDIDATE_WINDOWS = [\"all\", \"1\", \"2\", \"3\", \"5\", \"10\", \"15\", \"20\", \"25\", \"50\"]\n",
    "\n",
    "best_windows = {}  # (model_group, scorer, aggregation) -> {window, accuracy}\n",
    "\n",
    "for model_name, datasets in MODEL_GROUPS.items():\n",
    "\n",
    "    # Filter bon_agg_df to this model's datasets, exclude oracle\n",
    "    mask = (\n",
    "        bon_agg_df[\"dataset\"].isin(datasets)\n",
    "        & (bon_agg_df[\"scorer\"] != \"oracle\")\n",
    "    )\n",
    "    sub = bon_agg_df[mask].copy()\n",
    "\n",
    "    if sub.empty:\n",
    "        continue\n",
    "\n",
    "    # Only consider windows that exist for ALL datasets in the group\n",
    "    _window_sets = []\n",
    "    for ds in datasets:\n",
    "        ds_windows = set(sub[sub[\"dataset\"] == ds][\"window\"].unique())\n",
    "        if ds_windows:\n",
    "            _window_sets.append(ds_windows)\n",
    "    common_windows = set.intersection(*_window_sets) if _window_sets else set()\n",
    "    common_windows = common_windows & set(CANDIDATE_WINDOWS)\n",
    "    sub = sub[sub[\"window\"].isin(common_windows)].copy()\n",
    "\n",
    "    # For each (scorer, aggregation, window): average accuracy_mean across datasets\n",
    "    # Note: bon_agg_df accuracy is always EM-based (from candidates.json re-analysis)\n",
    "    window_perf = (\n",
    "        sub.groupby([\"scorer\", \"aggregation\", \"window\"])[\"exact_match_mean\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"exact_match_mean\": \"avg_accuracy\"})\n",
    "    )\n",
    "\n",
    "    # For each (scorer, aggregation): find the best window\n",
    "    for scorer in sorted(sub[\"scorer\"].unique()):\n",
    "        for agg in AGGREGATIONS:\n",
    "            sa_df = window_perf[\n",
    "                (window_perf[\"scorer\"] == scorer) & (window_perf[\"aggregation\"] == agg)\n",
    "            ]\n",
    "            if sa_df.empty:\n",
    "                continue\n",
    "            best = sa_df.loc[sa_df[\"avg_accuracy\"].idxmax()]\n",
    "            best_windows[(model_name, scorer, agg)] = {\n",
    "                \"window\": best[\"window\"],\n",
    "                \"accuracy\": best[\"avg_accuracy\"],\n",
    "            }\n",
    "\n",
    "\n",
    "# ── Display tables: one per (model_group, aggregation) ───────────────────────\n",
    "_SCORER_ORDER = [\"entropy\", \"perplexity\", \"sequence_prob\", \"pd_gap\", \"prm\"]\n",
    "\n",
    "# Per-dataset metric definitions\n",
    "_DS_METRICS = {\n",
    "    \"HumanEval-Plus\": [\n",
    "        (\"Score (%)\", \"humaneval_score_fmt\", \"exact_match_fmt\", None),\n",
    "        (\"TFLOPs\", \"total_tflops_fmt\", \"total_tflops_fmt\", None),\n",
    "    ],\n",
    "}\n",
    "_DEFAULT_METRICS = [\n",
    "    (\"EM (%)\", \"exact_match_fmt\", \"exact_match_fmt\", None),\n",
    "    (\"TFLOPs\", \"total_tflops_fmt\", \"total_tflops_fmt\", None),\n",
    "]\n",
    "\n",
    "def _get_ds_metrics(ds):\n",
    "    return _DS_METRICS.get(ds, _DEFAULT_METRICS)\n",
    "\n",
    "for model_name, datasets in MODEL_GROUPS.items():\n",
    "    for agg in AGGREGATIONS:\n",
    "        rows = []\n",
    "        row_index = []\n",
    "\n",
    "        col_tuples = []\n",
    "        for ds in datasets:\n",
    "            for ml, *_ in _get_ds_metrics(ds):\n",
    "                col_tuples.append((ds, ml))\n",
    "\n",
    "        # Baseline row\n",
    "        _bl_row = {}\n",
    "        for ds in datasets:\n",
    "            _bl = agg_df[(agg_df[\"strategy\"] == \"baseline\") & (agg_df[\"project_label\"] == ds)]\n",
    "            for ml, agg_col, _, _ in _get_ds_metrics(ds):\n",
    "                _bl_row[(ds, ml)] = _bl.iloc[0].get(agg_col, \"\") if not _bl.empty else \"\"\n",
    "        rows.append(_bl_row)\n",
    "        row_index.append((\"Baseline\", \"\\u2014\"))\n",
    "\n",
    "        # Self-consistency row\n",
    "        _sc_row = {}\n",
    "        for ds in datasets:\n",
    "            _sc = agg_df[(agg_df[\"strategy\"] == \"self_consistency\") & (agg_df[\"project_label\"] == ds)]\n",
    "            for ml, agg_col, _, _ in _get_ds_metrics(ds):\n",
    "                _sc_row[(ds, ml)] = _sc.iloc[0].get(agg_col, \"\") if not _sc.empty else \"\"\n",
    "        rows.append(_sc_row)\n",
    "        row_index.append((\"Self-Consistency\", \"\\u2014\"))\n",
    "\n",
    "        # Oracle row\n",
    "        _orc_row = {}\n",
    "        for ds in datasets:\n",
    "            _orc = bon_agg_df[\n",
    "                (bon_agg_df[\"dataset\"] == ds)\n",
    "                & (bon_agg_df[\"scorer\"] == \"oracle\")\n",
    "                & (bon_agg_df[\"window\"] == \"all\")\n",
    "            ]\n",
    "            for ml, _, bon_col, bon_ref_col in _get_ds_metrics(ds):\n",
    "                if not _orc.empty:\n",
    "                    _orc_row[(ds, ml)] = _orc.iloc[0].get(bon_ref_col or bon_col, \"\")\n",
    "                else:\n",
    "                    _orc_row[(ds, ml)] = \"\"\n",
    "        rows.append(_orc_row)\n",
    "        row_index.append((\"Oracle\", \"\\u2014\"))\n",
    "\n",
    "        # Offline BoN per-scorer rows (best window per scorer)\n",
    "        for scorer in _SCORER_ORDER:\n",
    "            bw = best_windows.get((model_name, scorer, agg))\n",
    "            if bw is None:\n",
    "                continue\n",
    "            w = bw[\"window\"]\n",
    "            row = {}\n",
    "            for ds in datasets:\n",
    "                match = bon_agg_df[\n",
    "                    (bon_agg_df[\"dataset\"] == ds)\n",
    "                    & (bon_agg_df[\"scorer\"] == scorer)\n",
    "                    & (bon_agg_df[\"aggregation\"] == agg)\n",
    "                    & (bon_agg_df[\"window\"] == w)\n",
    "                ]\n",
    "                for ml, _, bon_col, bon_ref_col in _get_ds_metrics(ds):\n",
    "                    if not match.empty:\n",
    "                        row[(ds, ml)] = match.iloc[0].get(bon_ref_col or bon_col, \"\")\n",
    "                    else:\n",
    "                        row[(ds, ml)] = \"\"\n",
    "            rows.append(row)\n",
    "            row_index.append((f\"Offline BoN\\n(best window, {agg})\", f\"{scorer} (w={w})\"))\n",
    "\n",
    "        if not rows:\n",
    "            continue\n",
    "\n",
    "        mi_rows = pd.MultiIndex.from_tuples(row_index, names=[\"Strategy\", \"Scorer\"])\n",
    "        mi_cols = pd.MultiIndex.from_tuples(col_tuples, names=[\"Dataset\", \"Metric\"])\n",
    "        tbl = pd.DataFrame(rows, index=mi_rows, columns=mi_cols)\n",
    "\n",
    "        print(f\"\\n{model_name} — aggregation={agg}\")\n",
    "        print(f\"  Best window selected per scorer by averaging EM across: {', '.join(datasets)}\")\n",
    "        if model_name == \"Qwen2.5-Math-7B-Instruct\":\n",
    "            print(f\"  Note: Minerva Math excluded from averaging (anomalous results)\")\n",
    "        print(f\"  Core metric per dataset: {', '.join(f'{ds}={CORE_METRIC_LABEL[ds]}' for ds in datasets)}\")\n",
    "        display(style_results_table(tbl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Best aggregation per scorer — using core metric ──────────────────────────\n",
    "# For each (model_group, scorer), find the aggregation that maximizes the core metric.\n",
    "# Uses the best window already selected in the previous cell.\n",
    "\n",
    "best_aggregations = {}  # (model_group, scorer) -> {aggregation, window, accuracy}\n",
    "\n",
    "for model_name, datasets in MODEL_GROUPS.items():\n",
    "    print(f\"\\n{model_name}\")\n",
    "    print(f\"  Core metrics: {', '.join(f'{ds}={CORE_METRIC_LABEL[ds]}' for ds in datasets)}\")\n",
    "\n",
    "    for scorer in sorted(set(sc for (mg, sc, _) in best_windows if mg == model_name)):\n",
    "        best_acc = -1\n",
    "        best_agg = None\n",
    "        best_win = None\n",
    "\n",
    "        for agg in AGGREGATIONS:\n",
    "            bw = best_windows.get((model_name, scorer, agg))\n",
    "            if bw is None:\n",
    "                continue\n",
    "            # Use the best window for this (scorer, agg), compute core-metric average\n",
    "            w = bw[\"window\"]\n",
    "            core_vals = []\n",
    "            for ds in datasets:\n",
    "                match = bon_agg_df[\n",
    "                    (bon_agg_df[\"dataset\"] == ds)\n",
    "                    & (bon_agg_df[\"scorer\"] == scorer)\n",
    "                    & (bon_agg_df[\"aggregation\"] == agg)\n",
    "                    & (bon_agg_df[\"window\"] == w)\n",
    "                ]\n",
    "                if not match.empty:\n",
    "                    core_vals.append(match.iloc[0][\"exact_match_mean\"])\n",
    "            if core_vals:\n",
    "                avg = sum(core_vals) / len(core_vals)\n",
    "                if avg > best_acc:\n",
    "                    best_acc = avg\n",
    "                    best_agg = agg\n",
    "                    best_win = w\n",
    "\n",
    "        if best_agg:\n",
    "            best_aggregations[(model_name, scorer)] = {\n",
    "                \"aggregation\": best_agg,\n",
    "                \"window\": best_win,\n",
    "                \"accuracy\": best_acc,\n",
    "            }\n",
    "            print(f\"  {scorer:<16s}  best: {best_agg} (w={best_win}, avg={best_acc:.1f}%)\")\n",
    "\n",
    "# ── Display: best (aggregation, window) per scorer ───────────────────────────\n",
    "_SCORER_ORDER = [\"entropy\", \"perplexity\", \"sequence_prob\", \"pd_gap\", \"prm\"]\n",
    "\n",
    "_DS_METRICS = {\n",
    "    \"HumanEval-Plus\": [\n",
    "        (\"Score (%)\", \"humaneval_score_fmt\", \"exact_match_fmt\", None),\n",
    "        (\"TFLOPs\", \"total_tflops_fmt\", \"total_tflops_fmt\", None),\n",
    "    ],\n",
    "}\n",
    "_DEFAULT_METRICS = [\n",
    "    (\"EM (%)\", \"exact_match_fmt\", \"exact_match_fmt\", None),\n",
    "    (\"TFLOPs\", \"total_tflops_fmt\", \"total_tflops_fmt\", None),\n",
    "]\n",
    "\n",
    "def _get_ds_metrics(ds):\n",
    "    return _DS_METRICS.get(ds, _DEFAULT_METRICS)\n",
    "\n",
    "for model_name, datasets in MODEL_GROUPS.items():\n",
    "    rows = []\n",
    "    row_index = []\n",
    "\n",
    "    col_tuples = []\n",
    "    for ds in datasets:\n",
    "        for ml, *_ in _get_ds_metrics(ds):\n",
    "            col_tuples.append((ds, ml))\n",
    "\n",
    "    # Baseline\n",
    "    _bl_row = {}\n",
    "    for ds in datasets:\n",
    "        _bl = agg_df[(agg_df[\"strategy\"] == \"baseline\") & (agg_df[\"project_label\"] == ds)]\n",
    "        for ml, agg_col, _, _ in _get_ds_metrics(ds):\n",
    "            _bl_row[(ds, ml)] = _bl.iloc[0].get(agg_col, \"\") if not _bl.empty else \"\"\n",
    "    rows.append(_bl_row)\n",
    "    row_index.append((\"Baseline\", \"\\u2014\"))\n",
    "\n",
    "    # Self-consistency\n",
    "    _sc_row = {}\n",
    "    for ds in datasets:\n",
    "        _sc = agg_df[(agg_df[\"strategy\"] == \"self_consistency\") & (agg_df[\"project_label\"] == ds)]\n",
    "        for ml, agg_col, _, _ in _get_ds_metrics(ds):\n",
    "            _sc_row[(ds, ml)] = _sc.iloc[0].get(agg_col, \"\") if not _sc.empty else \"\"\n",
    "    rows.append(_sc_row)\n",
    "    row_index.append((\"Self-Consistency\", \"\\u2014\"))\n",
    "\n",
    "    # Oracle\n",
    "    _orc_row = {}\n",
    "    for ds in datasets:\n",
    "        _orc = bon_agg_df[\n",
    "            (bon_agg_df[\"dataset\"] == ds)\n",
    "            & (bon_agg_df[\"scorer\"] == \"oracle\")\n",
    "            & (bon_agg_df[\"window\"] == \"all\")\n",
    "        ]\n",
    "        for ml, _, bon_col, bon_ref_col in _get_ds_metrics(ds):\n",
    "            if not _orc.empty:\n",
    "                _orc_row[(ds, ml)] = _orc.iloc[0].get(bon_ref_col or bon_col, \"\")\n",
    "            else:\n",
    "                _orc_row[(ds, ml)] = \"\"\n",
    "    rows.append(_orc_row)\n",
    "    row_index.append((\"Oracle\", \"\\u2014\"))\n",
    "\n",
    "    # Offline BoN per-scorer with best (aggregation, window)\n",
    "    for scorer in _SCORER_ORDER:\n",
    "        ba = best_aggregations.get((model_name, scorer))\n",
    "        if ba is None:\n",
    "            continue\n",
    "        agg, w = ba[\"aggregation\"], ba[\"window\"]\n",
    "        row = {}\n",
    "        for ds in datasets:\n",
    "            match = bon_agg_df[\n",
    "                (bon_agg_df[\"dataset\"] == ds)\n",
    "                & (bon_agg_df[\"scorer\"] == scorer)\n",
    "                & (bon_agg_df[\"aggregation\"] == agg)\n",
    "                & (bon_agg_df[\"window\"] == w)\n",
    "            ]\n",
    "            for ml, _, bon_col, bon_ref_col in _get_ds_metrics(ds):\n",
    "                if not match.empty:\n",
    "                    row[(ds, ml)] = match.iloc[0].get(bon_ref_col or bon_col, \"\")\n",
    "                else:\n",
    "                    row[(ds, ml)] = \"\"\n",
    "        rows.append(row)\n",
    "        row_index.append((\"Offline BoN\\n(best agg+window)\", f\"{scorer} ({agg}, w={w})\"))\n",
    "\n",
    "    mi_rows = pd.MultiIndex.from_tuples(row_index, names=[\"Strategy\", \"Scorer\"])\n",
    "    mi_cols = pd.MultiIndex.from_tuples(col_tuples, names=[\"Dataset\", \"Metric\"])\n",
    "    tbl = pd.DataFrame(rows, index=mi_rows, columns=mi_cols)\n",
    "\n",
    "    print(f\"\\n{model_name} — best aggregation & window per scorer\")\n",
    "    print(f\"  Core metric per dataset: {', '.join(f'{ds}={CORE_METRIC_LABEL[ds]}' for ds in datasets)}\")\n",
    "    display(style_results_table(tbl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Results\n",
    "\n",
    "Combined tables showing baseline, self-consistency, offline BoN (per-scorer from\n",
    "`candidates.json` analysis), and MUR (from wandb summary) for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Model results table builder ───────────────────────────────────────────────\n",
    "\n",
    "SCORER_ORDER = [\"prm\", \"entropy\", \"perplexity\", \"sequence_prob\", \"pd_gap\"]\n",
    "\n",
    "STRATEGY_DISPLAY = {\n",
    "    \"baseline\": \"Baseline\",\n",
    "    \"extended_thinking\": \"Extended Thinking\",\n",
    "    \"self_consistency\": \"Self-Consistency\",\n",
    "    \"offline_bon\": \"Offline BoN\",\n",
    "    \"beam_search\": \"Beam Search\",\n",
    "    \"adaptive\": \"MUR\",\n",
    "}\n",
    "\n",
    "# Strategies that have a single row (no per-scorer breakdown)\n",
    "SINGLE_SCORER_STRATEGIES = {\"baseline\", \"self_consistency\", \"extended_thinking\"}\n",
    "\n",
    "\n",
    "def _fmt_metric(val, std=None, count=None):\n",
    "    \"\"\"Format a metric value, optionally with ± std.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return \"\"\n",
    "    if std is not None and pd.notna(std) and count is not None and count > 1:\n",
    "        return f\"{val:.1f} ± {std:.1f}\"\n",
    "    return f\"{val:.1f}\"\n",
    "\n",
    "\n",
    "def _get_wandb_metrics(model_df, strategy, scorer, dataset, humaneval_datasets=None):\n",
    "    \"\"\"Extract (EM, TFLOPs) from wandb agg_df for one (strategy, scorer, dataset).\"\"\"\n",
    "    mask = model_df[\"strategy\"] == strategy\n",
    "    mask &= model_df[\"project_label\"] == dataset\n",
    "    if scorer is not None:\n",
    "        mask &= model_df[\"scorer\"] == scorer\n",
    "    sub = model_df[mask]\n",
    "    if sub.empty:\n",
    "        return \"\", \"\"\n",
    "    r = sub.iloc[0]\n",
    "    # Use humaneval_score_fmt for HumanEval datasets\n",
    "    if humaneval_datasets and dataset in humaneval_datasets:\n",
    "        em = r.get(\"humaneval_score_fmt\", \"\")\n",
    "    else:\n",
    "        em = r.get(\"exact_match_fmt\", _fmt_metric(r.get(\"exact_match_mean\")))\n",
    "    tf = _fmt_metric(r.get(\"total_tflops_mean\"),\n",
    "                     r.get(\"total_tflops_std\"),\n",
    "                     r.get(\"total_tflops_count\"))\n",
    "    return em, tf\n",
    "\n",
    "\n",
    "def build_model_results_table(\n",
    "    agg_df,\n",
    "    bon_agg_df,\n",
    "    best_aggregations,\n",
    "    model_name,\n",
    "    model_filter,\n",
    "    datasets,\n",
    "    strategy_order=None,\n",
    "    humaneval_datasets=None,\n",
    "    beam_search_filter=None,\n",
    "):\n",
    "    \"\"\"Build a combined results table for one model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    best_aggregations : dict\n",
    "        {(model_group, scorer): {\"aggregation\", \"window\", \"accuracy\"}}\n",
    "        from the best-aggregation selection cell.\n",
    "    model_name : str\n",
    "        Key in best_aggregations (e.g. \"Qwen2.5-Math-7B-Instruct\").\n",
    "    model_filter : str or list[str]\n",
    "        Model short name(s) to filter from agg_df.\n",
    "    datasets : list[str]\n",
    "        Ordered list of project_label names for columns.\n",
    "    strategy_order : list[str]\n",
    "        Ordered strategies to include.\n",
    "    humaneval_datasets : set\n",
    "        Dataset names that use humaneval_score instead of exact_match.\n",
    "    beam_search_filter : callable or None\n",
    "        If provided, applied to filter beam search rows from model_df.\n",
    "    \"\"\"\n",
    "    if isinstance(model_filter, str):\n",
    "        model_filter = [model_filter]\n",
    "    if strategy_order is None:\n",
    "        strategy_order = [\"baseline\", \"self_consistency\", \"beam_search\",\n",
    "                          \"offline_bon\", \"adaptive\"]\n",
    "    if humaneval_datasets is None:\n",
    "        humaneval_datasets = set()\n",
    "\n",
    "    model_df = agg_df[agg_df[\"model\"].isin(model_filter)].copy()\n",
    "    # Build per-dataset metric label (Score for HumanEval, EM for others)\n",
    "    _ds_metric_label = {\n",
    "        ds: \"Score (%)\" if ds in humaneval_datasets else \"EM (%)\"\n",
    "        for ds in datasets\n",
    "    }\n",
    "\n",
    "    rows = []\n",
    "    row_index = []\n",
    "\n",
    "    for strat_key in strategy_order:\n",
    "        strat_label = STRATEGY_DISPLAY.get(strat_key, strat_key)\n",
    "\n",
    "        if strat_key == \"offline_bon\":\n",
    "            # Use best (aggregation, window) per scorer from best_aggregations\n",
    "            _bon_settings = []\n",
    "            for scorer in SCORER_ORDER:\n",
    "                _ba = best_aggregations.get((model_name, scorer))\n",
    "                if _ba is not None:\n",
    "                    _bon_settings.append(f\"  {scorer}: aggregation={_ba['aggregation']}, w={_ba['window']}\")\n",
    "            if _bon_settings:\n",
    "                print(f\"Offline BoN best settings for {model_name}:\")\n",
    "                print(\"\\n\".join(_bon_settings))\n",
    "\n",
    "            for scorer in SCORER_ORDER:\n",
    "                ba = best_aggregations.get((model_name, scorer))\n",
    "                if ba is None:\n",
    "                    continue\n",
    "                agg, w = ba[\"aggregation\"], ba[\"window\"]\n",
    "                row = {}\n",
    "                for ds in datasets:\n",
    "                    ml = _ds_metric_label[ds]\n",
    "                    match = bon_agg_df[\n",
    "                        (bon_agg_df[\"dataset\"] == ds)\n",
    "                        & (bon_agg_df[\"scorer\"] == scorer)\n",
    "                        & (bon_agg_df[\"aggregation\"] == agg)\n",
    "                        & (bon_agg_df[\"window\"] == w)\n",
    "                    ]\n",
    "                    if not match.empty:\n",
    "                        row[(ds, ml)] = match.iloc[0].get(\"exact_match_fmt\", \"\")\n",
    "                        row[(ds, \"TFLOPs\")] = match.iloc[0].get(\"total_tflops_fmt\", \"\")\n",
    "                    else:\n",
    "                        row[(ds, ml)] = \"\"\n",
    "                        row[(ds, \"TFLOPs\")] = \"\"\n",
    "                rows.append(row)\n",
    "                row_index.append((strat_label, f\"{scorer}\\n({agg}, w={w})\"))\n",
    "\n",
    "            # UHead offline BoN: temporarily commented out — beam search uhead\n",
    "            # results are better, so we only show beam search uhead in final charts.\n",
    "            # _uhead_df = model_df[(model_df[\"strategy\"] == \"offline_best_of_n\") & (model_df[\"scorer\"] == \"uhead\")]\n",
    "            # if not _uhead_df.empty:\n",
    "            #     row = {}\n",
    "            #     for ds in datasets:\n",
    "            #         ml = _ds_metric_label[ds]\n",
    "            #         em, tf = _get_wandb_metrics(model_df, \"offline_best_of_n\", \"uhead\", ds, humaneval_datasets)\n",
    "            #         row[(ds, ml)] = em\n",
    "            #         row[(ds, \"TFLOPs\")] = tf\n",
    "            #     rows.append(row)\n",
    "            #     row_index.append((strat_label, \"uhead\"))\n",
    "\n",
    "        elif strat_key == \"beam_search\":\n",
    "            strat_df = model_df[model_df[\"strategy\"] == \"beam_search\"]\n",
    "            if beam_search_filter is not None:\n",
    "                strat_df = beam_search_filter(strat_df)\n",
    "            if strat_df.empty:\n",
    "                continue\n",
    "\n",
    "            variants = (\n",
    "                strat_df[[\"aggregation\", \"scoring_window\"]]\n",
    "                .drop_duplicates()\n",
    "                .sort_values([\"scoring_window\", \"aggregation\"])\n",
    "            )\n",
    "            for _, vr in variants.iterrows():\n",
    "                agg_val, win = vr[\"aggregation\"], vr[\"scoring_window\"]\n",
    "                win_label = f\"w={win}\" if pd.notna(win) else \"w=all\"\n",
    "                agg_label = agg_val if pd.notna(agg_val) else \"mean\"\n",
    "                label = f\"Beam Search\\n({agg_label}, {win_label})\"\n",
    "\n",
    "                sub = strat_df[\n",
    "                    (strat_df[\"aggregation\"] == agg_val)\n",
    "                    & (strat_df[\"scoring_window\"] == win)\n",
    "                ]\n",
    "                scorers = sorted(sub[\"scorer\"].dropna().unique())\n",
    "                for scorer in scorers:\n",
    "                    row = {}\n",
    "                    for ds in datasets:\n",
    "                        ml = _ds_metric_label[ds]\n",
    "                        em, tf = _get_wandb_metrics(sub, \"beam_search\", scorer, ds, humaneval_datasets)\n",
    "                        row[(ds, ml)] = em\n",
    "                        row[(ds, \"TFLOPs\")] = tf\n",
    "                    rows.append(row)\n",
    "                    row_index.append((label, scorer))\n",
    "\n",
    "        elif strat_key in SINGLE_SCORER_STRATEGIES:\n",
    "            strat_data = model_df[model_df[\"strategy\"] == strat_key]\n",
    "            if strat_data.empty:\n",
    "                continue\n",
    "            row = {}\n",
    "            for ds in datasets:\n",
    "                ml = _ds_metric_label[ds]\n",
    "                em, tf = _get_wandb_metrics(model_df, strat_key, None, ds, humaneval_datasets)\n",
    "                row[(ds, ml)] = em\n",
    "                row[(ds, \"TFLOPs\")] = tf\n",
    "            rows.append(row)\n",
    "            row_index.append((strat_label, \"\\u2014\"))\n",
    "\n",
    "        else:\n",
    "            # Strategies with per-scorer rows (adaptive/MUR)\n",
    "            strat_df = model_df[model_df[\"strategy\"] == strat_key]\n",
    "            if strat_df.empty:\n",
    "                continue\n",
    "            scorers = sorted(strat_df[\"scorer\"].dropna().unique())\n",
    "            for scorer in scorers:\n",
    "                row = {}\n",
    "                for ds in datasets:\n",
    "                    ml = _ds_metric_label[ds]\n",
    "                    em, tf = _get_wandb_metrics(model_df, strat_key, scorer, ds, humaneval_datasets)\n",
    "                    row[(ds, ml)] = em\n",
    "                    row[(ds, \"TFLOPs\")] = tf\n",
    "                rows.append(row)\n",
    "                row_index.append((strat_label, scorer))\n",
    "\n",
    "    if not rows:\n",
    "        print(\"No data found for this model / dataset combination.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    mi_rows = pd.MultiIndex.from_tuples(row_index, names=[\"Strategy\", \"Scorer\"])\n",
    "\n",
    "    col_tuples = []\n",
    "    for ds in datasets:\n",
    "        col_tuples.append((ds, _ds_metric_label[ds]))\n",
    "        col_tuples.append((ds, \"TFLOPs\"))\n",
    "    mi_cols = pd.MultiIndex.from_tuples(col_tuples, names=[\"Dataset\", \"Metric\"])\n",
    "\n",
    "    result = pd.DataFrame(rows, index=mi_rows, columns=mi_cols)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def _parse_mean(val):\n",
    "    \"\"\"Extract the mean value from a formatted string like '83.2 ± 0.5' or '83.2'.\"\"\"\n",
    "    if not val or not isinstance(val, str):\n",
    "        return None\n",
    "    s = val.split(\"±\")[0].split(\"+/-\")[0].strip()\n",
    "    try:\n",
    "        return float(s)\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def add_baseline_diff(tbl):\n",
    "    \"\"\"Add Δ columns showing difference from baseline for each dataset's accuracy metric.\"\"\"\n",
    "    # Find the baseline row\n",
    "    baseline_idx = None\n",
    "    for idx in tbl.index:\n",
    "        if idx[0] == \"Baseline\":\n",
    "            baseline_idx = idx\n",
    "            break\n",
    "    if baseline_idx is None:\n",
    "        return tbl\n",
    "\n",
    "    datasets = tbl.columns.get_level_values(0).unique()\n",
    "    result = tbl.copy()\n",
    "\n",
    "    # Build new column order with Δ after each accuracy column\n",
    "    new_cols = []\n",
    "    for ds in datasets:\n",
    "        ds_cols = [c for c in tbl.columns if c[0] == ds]\n",
    "        for col in ds_cols:\n",
    "            new_cols.append(col)\n",
    "            # Add Δ after accuracy columns (EM/Score), not after TFLOPs\n",
    "            if col[1] in (\"EM (%)\", \"Score (%)\"):\n",
    "                delta_col = (ds, \"Δ\")\n",
    "                baseline_val = _parse_mean(tbl.loc[baseline_idx, col])\n",
    "                deltas = []\n",
    "                for idx in tbl.index:\n",
    "                    val = _parse_mean(tbl.loc[idx, col])\n",
    "                    if val is not None and baseline_val is not None:\n",
    "                        diff = val - baseline_val\n",
    "                        deltas.append(f\"{diff:+.1f}\")\n",
    "                    else:\n",
    "                        deltas.append(\"\")\n",
    "                result[delta_col] = deltas\n",
    "                new_cols.append(delta_col)\n",
    "\n",
    "    result = result[new_cols]\n",
    "    result.columns = pd.MultiIndex.from_tuples(new_cols, names=[\"Dataset\", \"Metric\"])\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"build_model_results_table(), add_baseline_diff() defined\")\n",
    "\n",
    "_COMBINED_RESULTS_DIR = _Path(\"cache/combined_results\")\n",
    "_COMBINED_RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_combined_results(tbl, model_slug):\n",
    "    \"\"\"Save combined results table to CSV.\"\"\"\n",
    "    path = _COMBINED_RESULTS_DIR / f\"{model_slug}.csv\"\n",
    "    tbl.to_csv(path)\n",
    "    print(f\"  Saved to {path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Qwen2.5-Math-7B-Instruct (Non-Thinking Mode) ─────────────────────────────\n",
    "\n",
    "def _qwen25_bs_filter(bs_df):\n",
    "    \"\"\"Keep only beam search (window=5) for Qwen2.5 — both mean and min.\"\"\"\n",
    "    keep = bs_df[\"scoring_window\"].astype(str).isin([\"5\", \"5.0\"])\n",
    "    return bs_df[keep].copy()\n",
    "\n",
    "_QWEN25_DATASETS = [\"MATH-500\", \"OlympiadBench\", \"Minerva Math\", \"Gaokao 2023 EN\"]\n",
    "\n",
    "tbl = build_model_results_table(\n",
    "    agg_df, bon_agg_df, best_aggregations,\n",
    "    model_name=\"Qwen2.5-Math-7B-Instruct\",\n",
    "    model_filter=\"qwen25_math_7b_instruct\",\n",
    "    datasets=_QWEN25_DATASETS,\n",
    "    strategy_order=[\n",
    "        \"baseline\", \"self_consistency\",\n",
    "        \"offline_bon\", \"beam_search\", \"adaptive\",\n",
    "    ],\n",
    "    beam_search_filter=_qwen25_bs_filter,\n",
    ")\n",
    "\n",
    "# ── Hardcoded UHead Beam Search results (single-seed, no std) ─────────────\n",
    "# Values are raw 0-1 accuracy: (exact_match, llm_judge)\n",
    "# Offline BoN UHead is now fetched from W&B (no longer hardcoded).\n",
    "_UHEAD_BEAM_SEARCH = {  # mean, w=all\n",
    "    \"MATH-500\":       (0.850, 0.860),\n",
    "    \"OlympiadBench\":  (0.4177, 0.4637),\n",
    "    \"Minerva Math\":   (0.4301, 0.4963),\n",
    "    \"Gaokao 2023 EN\": (0.7221, 0.7610),\n",
    "}\n",
    "\n",
    "# Estimate UHead beam search TFLOPs from other lightweight scorers.\n",
    "# UHead is a tiny probe head (<10M params, ~0.15% of base model), so its scoring\n",
    "# overhead is negligible.  We use the average TFLOPs of entropy / perplexity /\n",
    "# uncertainty_pd beam search (mean, w=5.0) as a proxy for generation cost.\n",
    "_UHEAD_BS_TFLOPS_PROXY_SCORERS = [\"entropy\", \"perplexity\", \"uncertainty_pd\"]\n",
    "\n",
    "def _estimate_uhead_tflops(tbl, datasets):\n",
    "    \"\"\"Average TFLOPs of lightweight beam-search scorers per dataset.\"\"\"\n",
    "    est = {}\n",
    "    for ds in datasets:\n",
    "        vals = []\n",
    "        for idx in tbl.index:\n",
    "            strat, scorer = idx\n",
    "            if \"Beam Search\" in strat and \"mean\" in strat:\n",
    "                if any(scorer.startswith(s) for s in _UHEAD_BS_TFLOPS_PROXY_SCORERS):\n",
    "                    raw = tbl.loc[idx, (ds, \"TFLOPs\")]\n",
    "                    if raw and isinstance(raw, str):\n",
    "                        try:\n",
    "                            vals.append(float(raw.split(\"±\")[0].split(\"+/-\")[0].strip()))\n",
    "                        except ValueError:\n",
    "                            pass\n",
    "        est[ds] = f\"{sum(vals) / len(vals):.1f}\" if vals else \"\"\n",
    "    return est\n",
    "\n",
    "def _uhead_row(data, tflops_est):\n",
    "    row = {}\n",
    "    for ds, (em, _llm) in data.items():\n",
    "        row[(ds, \"EM (%)\")] = f\"{em * 100:.1f}\"\n",
    "        row[(ds, \"TFLOPs\")] = tflops_est.get(ds, \"\")\n",
    "    return row\n",
    "\n",
    "_uhead_bs_df = pd.DataFrame(\n",
    "    [_uhead_row(_UHEAD_BEAM_SEARCH, _estimate_uhead_tflops(tbl, _QWEN25_DATASETS))],\n",
    "    index=pd.MultiIndex.from_tuples([\n",
    "        (\"Beam Search\\n(mean, w=all)\", \"uhead\"),\n",
    "    ], names=[\"Strategy\", \"Scorer\"]),\n",
    "    columns=tbl.columns,\n",
    ")\n",
    "\n",
    "# Insert UHead beam search row before MUR\n",
    "_idx = list(tbl.index)\n",
    "_mur_start = next((i for i, x in enumerate(_idx) if x[0] == \"MUR\"), len(tbl))\n",
    "\n",
    "tbl = pd.concat([\n",
    "    tbl.iloc[:_mur_start],\n",
    "    _uhead_bs_df,\n",
    "    tbl.iloc[_mur_start:],\n",
    "])\n",
    "\n",
    "tbl = add_baseline_diff(tbl)\n",
    "print(\"Qwen2.5-Math-7B-Instruct — Combined Results\")\n",
    "display(style_results_table(tbl))\n",
    "_tbl_q25_combined = tbl\n",
    "save_combined_results(tbl, \"qwen25_math_7b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Qwen3-8B (Thinking Mode) ──────────────────────────────────────────────────\n",
    "\n",
    "def _qwen3_bs_filter(bs_df):\n",
    "    \"\"\"Keep only beam search (min, window=5) for Qwen3.\"\"\"\n",
    "    keep = (\n",
    "        (bs_df[\"aggregation\"] == \"min\")\n",
    "        & (bs_df[\"scoring_window\"].astype(str).isin([\"5\", \"5.0\"]))\n",
    "    )\n",
    "    return bs_df[keep].copy()\n",
    "\n",
    "tbl = build_model_results_table(\n",
    "    agg_df, bon_agg_df, best_aggregations,\n",
    "    model_name=\"Qwen3-8B\",\n",
    "    model_filter=[\"vllm_thinking_qwen3_8b\", \"qwen3_8b\"],\n",
    "    datasets=[\"AIME 2024\", \"AIME 2025\", \"HumanEval-Plus\"],\n",
    "    strategy_order=[\n",
    "        \"baseline\", \"extended_thinking\", \"self_consistency\",\n",
    "        \"offline_bon\", \"beam_search\", \"adaptive\",\n",
    "    ],\n",
    "    humaneval_datasets={\"HumanEval-Plus\"},\n",
    "    beam_search_filter=_qwen3_bs_filter,\n",
    ")\n",
    "tbl = add_baseline_diff(tbl)\n",
    "print(\"Qwen3-8B — Combined Results\")\n",
    "display(style_results_table(tbl))\n",
    "_tbl_q3_combined = tbl\n",
    "save_combined_results(tbl, \"qwen3_8b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── gpt-4o-mini ───────────────────────────────────────────────────────────────\n",
    "\n",
    "tbl = build_model_results_table(\n",
    "    agg_df, bon_agg_df, best_aggregations,\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    model_filter=\"gpt4o_mini\",\n",
    "    datasets=[\"GPQA Diamond\"],\n",
    "    strategy_order=[\n",
    "        \"baseline\", \"self_consistency\",\n",
    "    ],\n",
    ")\n",
    "if not tbl.empty:\n",
    "    print(\"gpt-4o-mini — Combined Results\")\n",
    "    display(style_results_table(tbl))\n",
    "    save_combined_results(tbl, \"gpt4o_mini\")\n",
    "else:\n",
    "    print(\"gpt-4o-mini: no data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ── LaTeX Export — Model-Specific Tables ──────────────────────────────────────\n",
    "\n",
    "# MODEL_CONFIGS = [\n",
    "#     (\"Qwen2.5-Math-7B-Instruct\", \"qwen25_math_7b_instruct\",\n",
    "#      [\"MATH-500\", \"OlympiadBench\", \"Minerva Math\", \"Gaokao 2023 EN\"],\n",
    "#      [\"all\"]),\n",
    "#     (\"Qwen3-8B\", [\"vllm_thinking_qwen3_8b\", \"qwen3_8b\"],\n",
    "#      [\"AIME 2024\", \"AIME 2025\"],\n",
    "#      [\"all\"]),\n",
    "#     (\"gpt-4o-mini\", \"gpt4o_mini\",\n",
    "#      [\"GPQA Diamond\"],\n",
    "#      [\"all\"]),\n",
    "# ]\n",
    "\n",
    "# model_latex = []\n",
    "\n",
    "# for model_name, model_filter, datasets, windows in MODEL_CONFIGS:\n",
    "#     for w in windows:\n",
    "#         tbl = build_model_results_table(\n",
    "#             agg_df, bon_agg_df,\n",
    "#             model_filter=model_filter,\n",
    "#             datasets=datasets,\n",
    "#             bon_window=w,\n",
    "#         )\n",
    "#         if tbl.empty:\n",
    "#             continue\n",
    "#         safe_name = model_name.lower().replace(\" \", \"_\").replace(\"-\", \"_\").replace(\".\", \"\")\n",
    "#         ltx = model_table_to_latex(\n",
    "#             tbl,\n",
    "#             caption=(\n",
    "#                 f\"Results for {model_name} (scoring window={w}). \"\n",
    "#                 \"EM and LLM columns show accuracy (\\\\%), TFlops shows total compute.\"\n",
    "#             ),\n",
    "#             label=f\"tab:{safe_name}_w{w}\",\n",
    "#         )\n",
    "#         model_latex.append((f\"{model_name} (window={w})\", ltx))\n",
    "\n",
    "# for title, ltx in model_latex:\n",
    "#     print(f\"% ── {title} \" + \"─\" * max(1, 60 - len(title)))\n",
    "#     print(ltx)\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Final Results: pick best beam search aggregation per scorer ────────────────\n",
    "#\n",
    "# For each scorer, compare mean vs min (or other aggregations) across datasets\n",
    "# and keep only the best one. Other strategies pass through unchanged.\n",
    "\n",
    "def build_final_table(tbl, metric_label=\"EM (%)\"):\n",
    "    \"\"\"From a combined results table, pick best beam search aggregation per scorer.\n",
    "\n",
    "    For beam search rows grouped by scorer, average the parsed EM across datasets\n",
    "    and keep the variant with the highest average.\n",
    "    \"\"\"\n",
    "    datasets = list(dict.fromkeys(c[0] for c in tbl.columns))\n",
    "\n",
    "    # Separate beam search rows from everything else\n",
    "    bs_mask = tbl.index.get_level_values(0).str.startswith(\"Beam Search\")\n",
    "    other_rows = tbl[~bs_mask]\n",
    "    bs_rows = tbl[bs_mask]\n",
    "\n",
    "    if bs_rows.empty:\n",
    "        return tbl.copy()\n",
    "\n",
    "    # Extract scorer name (without variant) from beam search rows\n",
    "    # Index: (\"Beam Search\\n(mean, w=5.0)\", \"prm\") → scorer = \"prm\"\n",
    "    best_per_scorer = {}\n",
    "    for idx in bs_rows.index:\n",
    "        strategy, scorer = idx\n",
    "        # Parse EM values across datasets for this row\n",
    "        ems = []\n",
    "        for ds in datasets:\n",
    "            ml = metric_label if (ds, metric_label) in tbl.columns else \"Score (%)\"\n",
    "            if (ds, ml) not in tbl.columns:\n",
    "                # Try alternative metric label\n",
    "                ml = \"Score (%)\" if ml == \"EM (%)\" else \"EM (%)\"\n",
    "            col = (ds, ml) if (ds, ml) in tbl.columns else None\n",
    "            if col is None:\n",
    "                continue\n",
    "            val = _parse_mean(str(bs_rows.at[idx, col]))\n",
    "            if val is not None:\n",
    "                ems.append(val)\n",
    "\n",
    "        avg_em = sum(ems) / len(ems) if ems else -1\n",
    "\n",
    "        if scorer not in best_per_scorer or avg_em > best_per_scorer[scorer][\"avg\"]:\n",
    "            best_per_scorer[scorer] = {\n",
    "                \"avg\": avg_em,\n",
    "                \"idx\": idx,\n",
    "                \"strategy\": strategy,\n",
    "            }\n",
    "\n",
    "    # Log selection\n",
    "    print(f\"  Beam search: found {len(bs_rows)} rows, {len(best_per_scorer)} scorers\")\n",
    "    for scorer, info in best_per_scorer.items():\n",
    "        print(f\"    {scorer}: avg EM = {info['avg']:.1f} ← {info['strategy']!r}\")\n",
    "\n",
    "    # Build final beam search rows with unified \"Beam Search\" strategy label\n",
    "    bs_final_rows = []\n",
    "    bs_final_idx = []\n",
    "    for scorer in sorted(best_per_scorer, key=lambda s: best_per_scorer[s][\"avg\"], reverse=True):\n",
    "        info = best_per_scorer[scorer]\n",
    "        orig_strategy = info[\"strategy\"]\n",
    "        # Extract variant info (e.g. \"mean, w=5.0\") for the scorer label\n",
    "        variant = orig_strategy.split(\"\\n\")[1].strip(\"() \") if \"\\n\" in orig_strategy else \"\"\n",
    "        scorer_label = f\"{scorer}\\n({variant})\" if variant else scorer\n",
    "        bs_final_rows.append(bs_rows.loc[info[\"idx\"]])\n",
    "        bs_final_idx.append((\"Beam Search\", scorer_label))\n",
    "\n",
    "    bs_final_df = pd.DataFrame(bs_final_rows, columns=tbl.columns)\n",
    "    bs_final_df.index = pd.MultiIndex.from_tuples(bs_final_idx, names=[\"Strategy\", \"Scorer\"])\n",
    "\n",
    "    # Find insertion point: after last non-BS, non-MUR row before MUR\n",
    "    other_idx = list(other_rows.index)\n",
    "    mur_start = next((i for i, x in enumerate(other_idx) if x[0] == \"MUR\"), len(other_idx))\n",
    "\n",
    "    result = pd.concat([\n",
    "        other_rows.iloc[:mur_start],\n",
    "        bs_final_df,\n",
    "        other_rows.iloc[mur_start:],\n",
    "    ])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# ── Qwen2.5-Math-7B ──────────────────────────────────────────────────────────\n",
    "\n",
    "_tbl_q25_final = build_final_table(_tbl_q25_combined)\n",
    "print(\"Qwen2.5-Math-7B-Instruct — Final Results (best beam search per scorer)\")\n",
    "display(style_results_table(_tbl_q25_final))\n",
    "save_combined_results(_tbl_q25_final, \"qwen25_math_7b_final\")\n",
    "\n",
    "\n",
    "# ── Qwen3-8B ─────────────────────────────────────────────────────────────────\n",
    "\n",
    "_tbl_q3_final = build_final_table(_tbl_q3_combined)\n",
    "print(\"\\nQwen3-8B — Final Results (best beam search per scorer)\")\n",
    "display(style_results_table(_tbl_q3_final))\n",
    "save_combined_results(_tbl_q3_final, \"qwen3_8b_final\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Load combined results & chart helpers ─────────────────────────────────────\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "_COMBINED_DIR = _Path(\"cache/combined_results\")\n",
    "\n",
    "# Use final results tables (best beam search per scorer already selected)\n",
    "_tbl_q25 = _tbl_q25_final\n",
    "_tbl_q3 = _tbl_q3_final\n",
    "print(f\"Using final tables: Qwen2.5 {_tbl_q25.shape}, Qwen3 {_tbl_q3.shape}\")\n",
    "\n",
    "from datetime import datetime as _dt\n",
    "_CHARTS_DIR = _COMBINED_DIR / \"charts\" / _dt.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "_CHARTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Charts will be saved to {_CHARTS_DIR}\")\n",
    "\n",
    "\n",
    "def _pv(s):\n",
    "    \"\"\"Parse mean from formatted string like '83.2 ± 0.5', '+1.2', or plain '83.2'.\"\"\"\n",
    "    s = str(s).strip()\n",
    "    if not s or s == \"nan\":\n",
    "        return None\n",
    "    try:\n",
    "        return float(s.split(\"±\")[0].strip())\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "\n",
    "STRATEGY_COLORS = {\n",
    "    \"Baseline\": \"#BBBBBB\",\n",
    "    \"Self-Consistency\": \"#4477AA\",\n",
    "    \"Extended Thinking\": \"#66CCEE\",\n",
    "    \"Offline BoN\": \"#228833\",\n",
    "    \"Beam Search\": \"#CCBB44\",\n",
    "    \"MUR\": \"#EE6677\",\n",
    "}\n",
    "\n",
    "\n",
    "def _strat_color(name):\n",
    "    for key, color in STRATEGY_COLORS.items():\n",
    "        if name.startswith(key):\n",
    "            return color\n",
    "    return \"#555\"\n",
    "\n",
    "\n",
    "# Datasets excluded from averaging (noisy / unreliable results)\n",
    "EXCLUDED_DATASETS = {\"Minerva Math\"}\n",
    "\n",
    "\n",
    "def _segments_intersect(a1, a2, b1, b2):\n",
    "    \"\"\"Check if segment a1-a2 crosses segment b1-b2 (in 2D pixel coords).\"\"\"\n",
    "    def cross(o, a, b):\n",
    "        return (a[0] - o[0]) * (b[1] - o[1]) - (a[1] - o[1]) * (b[0] - o[0])\n",
    "    d1, d2 = cross(b1, b2, a1), cross(b1, b2, a2)\n",
    "    d3, d4 = cross(a1, a2, b1), cross(a1, a2, b2)\n",
    "    return d1 * d2 < 0 and d3 * d4 < 0\n",
    "\n",
    "\n",
    "def _bbox_overlaps(cx, cy, hw, hh, placed_bboxes):\n",
    "    \"\"\"Check if a rectangle (cx, cy, half-width, half-height) overlaps any placed bbox.\"\"\"\n",
    "    for (px, py, pw, ph) in placed_bboxes:\n",
    "        if (abs(cx - px) < hw + pw + 4) and (abs(cy - py) < hh + ph + 2):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def _segment_hits_bbox(seg_a, seg_b, bboxes):\n",
    "    \"\"\"Check if segment (seg_a -> seg_b) passes through any placed label bbox.\"\"\"\n",
    "    for (bx, by, bw, bh) in bboxes:\n",
    "        # Four edges of the bbox rectangle\n",
    "        corners = [\n",
    "            (bx - bw, by - bh), (bx + bw, by - bh),\n",
    "            (bx + bw, by + bh), (bx - bw, by + bh),\n",
    "        ]\n",
    "        edges = [(corners[i], corners[(i + 1) % 4]) for i in range(4)]\n",
    "        for e0, e1 in edges:\n",
    "            if _segments_intersect(seg_a, seg_b, e0, e1):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def _annotate_with_arrows(ax, pts, fontsize=7.5, arrow_len=60, label_overrides=None):\n",
    "    \"\"\"Place labels at fixed pixel distance with bbox-aware collision avoidance.\n",
    "\n",
    "    Uses actual text bounding boxes (not just centre points) so long labels\n",
    "    like 'Self-Consistency' never overlap shorter ones.  Processes points\n",
    "    top-to-bottom and prefers upward label placement.\n",
    "\n",
    "    label_overrides: dict keyed by (strategy_prefix, scorer) -> override dict:\n",
    "        xytext      - position (data coords by default, or offset points if textcoords set)\n",
    "        textcoords  - \"offset points\" or None (data coords)\n",
    "        ha, va      - alignment\n",
    "        arrow       - True/False (default True for overrides)\n",
    "    \"\"\"\n",
    "    if not pts:\n",
    "        return\n",
    "    fig = ax.get_figure()\n",
    "    renderer = fig.canvas.get_renderer()\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    # Axes bounding box in display coords\n",
    "    ax_bbox = ax.get_window_extent(renderer)\n",
    "    _m = 8  # margin\n",
    "    ax_x0, ax_y0 = ax_bbox.x0 + _m, ax_bbox.y0 + _m\n",
    "    ax_x1, ax_y1 = ax_bbox.x1 - _m, ax_bbox.y1 - _m\n",
    "\n",
    "    # Pre-measure text sizes (half-width, half-height) in display coords\n",
    "    text_sizes = {}\n",
    "    for p in pts:\n",
    "        t = ax.text(0, 0, p[\"label\"], fontsize=fontsize, visible=False)\n",
    "        bb = t.get_window_extent(renderer)\n",
    "        text_sizes[id(p)] = (bb.width / 2 + 3, bb.height / 2 + 1)\n",
    "        t.remove()\n",
    "\n",
    "    display_pts = {id(p): ax.transData.transform((p[\"x\"], p[\"y\"])) for p in pts}\n",
    "    sorted_pts = sorted(pts, key=lambda p: -display_pts[id(p)][1])\n",
    "\n",
    "    _angles = np.linspace(0, 2 * np.pi, 36)[:-1]  # every 10 degrees\n",
    "\n",
    "    placed_bboxes = []   # (cx, cy, half_w, half_h)\n",
    "    placed_arrows = []   # ((px, py), (lx, ly))\n",
    "\n",
    "    for p in sorted_pts:\n",
    "        dx, dy = display_pts[id(p)]\n",
    "        hw, hh = text_sizes[id(p)]\n",
    "\n",
    "        # Check if there's an override for this (strat, scorer)\n",
    "        _override = None\n",
    "        if label_overrides:\n",
    "            _scorer = p.get(\"scorer\", \"\")\n",
    "            for (strat_prefix, scorer_key), ov in label_overrides.items():\n",
    "                if p.get(\"strat\", \"\").startswith(strat_prefix) and _scorer.startswith(scorer_key):\n",
    "                    if \"label_contains\" in ov and ov[\"label_contains\"] not in p.get(\"label\", \"\"):\n",
    "                        continue\n",
    "                    _override = ov\n",
    "                    break\n",
    "\n",
    "        if _override:\n",
    "            # Apply per-chart override\n",
    "            kw = {\"fontsize\": fontsize, \"ha\": _override.get(\"ha\", \"left\"), \"va\": _override.get(\"va\", \"center\")}\n",
    "            if _override.get(\"textcoords\"):\n",
    "                kw[\"textcoords\"] = _override[\"textcoords\"]\n",
    "            if _override.get(\"arrow\", True):\n",
    "                kw[\"arrowprops\"] = dict(arrowstyle=\"-\", color=\"gray\", lw=0.6, shrinkA=0, shrinkB=3)\n",
    "            ax.annotate(p[\"label\"], xy=(p[\"x\"], p[\"y\"]), xytext=_override[\"xytext\"], **kw)\n",
    "            continue\n",
    "\n",
    "        # Default: rotational algorithm for best placement\n",
    "        best_angle, best_score = _angles[0], -np.inf\n",
    "        for angle in _angles:\n",
    "            cx = dx + arrow_len * np.cos(angle)\n",
    "            cy = dy + arrow_len * np.sin(angle)\n",
    "\n",
    "            # Must be inside axes\n",
    "            if not (ax_x0 + hw <= cx <= ax_x1 - hw and ax_y0 + hh <= cy <= ax_y1 - hh):\n",
    "                continue\n",
    "\n",
    "            # (a) Bbox overlap — hard penalty\n",
    "            if _bbox_overlaps(cx, cy, hw, hh, placed_bboxes):\n",
    "                overlap_pen = 200.0\n",
    "            else:\n",
    "                overlap_pen = 0.0\n",
    "\n",
    "            # (b) Distance from nearest placed label centre\n",
    "            if placed_bboxes:\n",
    "                min_dist = min(np.hypot(cx - bx, cy - by) for bx, by, _, _ in placed_bboxes)\n",
    "            else:\n",
    "                min_dist = 300.0\n",
    "\n",
    "            # (c) Prefer label above point\n",
    "            vert_bonus = 25.0 * np.sin(angle)\n",
    "\n",
    "            # (d) Arrow crossing other arrows\n",
    "            cross_pen = 0.0\n",
    "            for seg_old in placed_arrows:\n",
    "                if _segments_intersect((dx, dy), (cx, cy), seg_old[0], seg_old[1]):\n",
    "                    cross_pen += 60.0\n",
    "\n",
    "            # (e) Arrow passing through a placed label bbox\n",
    "            if _segment_hits_bbox((dx, dy), (cx, cy), placed_bboxes):\n",
    "                cross_pen += 150.0\n",
    "\n",
    "            score = min_dist + vert_bonus - overlap_pen - cross_pen\n",
    "            if score > best_score:\n",
    "                best_score, best_angle = score, angle\n",
    "\n",
    "        lx = dx + arrow_len * np.cos(best_angle)\n",
    "        ly = dy + arrow_len * np.sin(best_angle)\n",
    "        placed_bboxes.append((lx, ly, hw, hh))\n",
    "        placed_arrows.append(((dx, dy), (lx, ly)))\n",
    "\n",
    "        # Adaptive offset: flip label direction near chart edges, no arrow\n",
    "        xlim = ax.get_xlim()\n",
    "        _xfrac = (np.log10(max(p[\"x\"], 1e-9)) - np.log10(max(xlim[0], 1e-9))) / (\n",
    "            np.log10(max(xlim[1], 1e-9)) - np.log10(max(xlim[0], 1e-9))\n",
    "        ) if xlim[1] > xlim[0] else 0.5\n",
    "        ylim = ax.get_ylim()\n",
    "        _yfrac = (p[\"y\"] - ylim[0]) / (ylim[1] - ylim[0]) if ylim[1] > ylim[0] else 0.5\n",
    "        _xoff = -8 if _xfrac > 0.82 else 8\n",
    "        _ha = \"right\" if _xfrac > 0.82 else \"left\"\n",
    "        _yoff = -6 if _yfrac > 0.90 else 6\n",
    "        ax.annotate(\n",
    "            p[\"label\"], xy=(p[\"x\"], p[\"y\"]),\n",
    "            xytext=(_xoff, _yoff), textcoords=\"offset points\",\n",
    "            fontsize=fontsize, ha=_ha, va=\"center\",\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _make_point_label(strat, scorer_clean, strat_short):\n",
    "    \"\"\"Build chart label, including strategy variant for multi-line names.\"\"\"\n",
    "    # Display name overrides (applied as prefix replacement)\n",
    "    _LABEL_RENAMES = {\n",
    "        \"uhead\": \"ReProbe\",\n",
    "        \"entropy\": \"Entropy\",\n",
    "        \"perplexity\": \"Perplexity\",\n",
    "        \"sequence_prob\": \"Sequence prob.\",\n",
    "        \"pd_gap\": \"PD gap\",\n",
    "        \"prm\": \"PRM\",\n",
    "        \"uncertainty_pd\": \"Uncertainty PD\",\n",
    "    }\n",
    "    for _old_name, _new_name in _LABEL_RENAMES.items():\n",
    "        if scorer_clean == _old_name or scorer_clean.startswith(_old_name + \" \"):\n",
    "            scorer_clean = _new_name + scorer_clean[len(_old_name):]\n",
    "            break\n",
    "    variant = strat.split(\"\\n\")[1].strip(\"() \") if \"\\n\" in strat else \"\"\n",
    "    if scorer_clean and variant:\n",
    "        return f\"{scorer_clean} ({variant})\"\n",
    "    return scorer_clean if scorer_clean else strat_short\n",
    "\n",
    "\n",
    "def plot_accuracy_vs_compute(tbl, title, figsize=(11, 7), save_path=None, include_datasets=None, show=True, label_overrides=None, strip_variant=False):\n",
    "    \"\"\"Scatter: X = avg compute overhead vs baseline (%), Y = avg EM improvement (pp).\n",
    "\n",
    "    Note: datasets listed in EXCLUDED_DATASETS are excluded from averaging.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    all_datasets = list(dict.fromkeys(c[0] for c in tbl.columns))\n",
    "    datasets = [ds for ds in all_datasets if ds not in EXCLUDED_DATASETS]\n",
    "    if EXCLUDED_DATASETS & set(all_datasets):\n",
    "        print(f\"Note: excluding {EXCLUDED_DATASETS & set(all_datasets)} from averaging\")\n",
    "\n",
    "    # ── Baseline reference ──\n",
    "    bl = next((i for i in tbl.index if i[0] == \"Baseline\"), None)\n",
    "    if bl is None:\n",
    "        print(\"No baseline row found\")\n",
    "        return\n",
    "\n",
    "    bl_tf = {}\n",
    "    for ds in datasets:\n",
    "        if (ds, \"TFLOPs\") in tbl.columns:\n",
    "            v = _pv(tbl.at[bl, (ds, \"TFLOPs\")])\n",
    "            if v and v > 0:\n",
    "                bl_tf[ds] = v\n",
    "\n",
    "    # ── Collect data points ──\n",
    "    pts = []\n",
    "    for idx in tbl.index:\n",
    "        strat, scorer = idx\n",
    "        if strat == \"Baseline\":\n",
    "            continue\n",
    "        strat_short = strat.split(\"\\n\")[0]\n",
    "\n",
    "        deltas, overheads = [], []\n",
    "        for ds in datasets:\n",
    "            if (ds, \"Δ\") in tbl.columns:\n",
    "                d = _pv(tbl.at[idx, (ds, \"Δ\")])\n",
    "                if d is not None:\n",
    "                    deltas.append(d)\n",
    "            if (ds, \"TFLOPs\") in tbl.columns and ds in bl_tf:\n",
    "                t = _pv(tbl.at[idx, (ds, \"TFLOPs\")])\n",
    "                if t is not None:\n",
    "                    overheads.append((t / bl_tf[ds] - 1) * 100)\n",
    "\n",
    "        if not deltas or not overheads:\n",
    "            continue\n",
    "\n",
    "        scorer_clean = scorer.replace(\"\\n\", \" \") if scorer != \"—\" else \"\"\n",
    "        pts.append({\n",
    "            \"x\": np.mean(overheads),\n",
    "            \"y\": np.mean(deltas),\n",
    "            \"strat\": strat_short,\n",
    "            \"scorer\": scorer_clean,\n",
    "            \"label\": _make_point_label(strat, scorer_clean, strat_short),\n",
    "        })\n",
    "\n",
    "    # ── Draw ──\n",
    "    # On log scale, baseline (0% overhead) can't be shown at x=0.\n",
    "    # Place it at x = 1% as a reference marker.\n",
    "    _bl_x = 1.0\n",
    "    ax.scatter(_bl_x, 0, color=STRATEGY_COLORS[\"Baseline\"], s=140, marker=\"*\",\n",
    "               zorder=5, edgecolors=\"k\", linewidths=0.5)\n",
    "    ax.annotate(\"Baseline (1%)\", (_bl_x, 0), xytext=(10, -12),\n",
    "                textcoords=\"offset points\", fontsize=18)\n",
    "\n",
    "    for p in pts:\n",
    "        c = _strat_color(p[\"strat\"])\n",
    "        ax.scatter(p[\"x\"], p[\"y\"], color=c, s=70, zorder=5, alpha=0.85,\n",
    "                   edgecolors=\"white\", linewidths=0.5)\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xlabel(\"Avg. Compute Overhead vs Baseline (%, log scale)\", fontsize=18)\n",
    "    ax.set_ylabel(\"Avg. EM Improvement vs Baseline (pp)\", fontsize=18)\n",
    "    ax.set_title(title, fontsize=13, fontweight=\"bold\")\n",
    "    ax.axhline(0, color=\"gray\", ls=\"--\", lw=0.8, alpha=0.4)\n",
    "    ax.tick_params(labelsize=18)\n",
    "    ax.grid(True, alpha=0.2)\n",
    "    if strip_variant:\n",
    "        import re as _re\n",
    "        for _p in pts:\n",
    "            _p[\"label\"] = _re.sub(r'\\s*\\([^)]*\\)$', '', _p[\"label\"])\n",
    "    _annotate_with_arrows(ax, pts, fontsize=18, arrow_len=80, label_overrides=label_overrides)\n",
    "\n",
    "    # Legend by strategy\n",
    "    from matplotlib.lines import Line2D\n",
    "    seen = []\n",
    "    for p in pts:\n",
    "        if p[\"strat\"] not in seen:\n",
    "            seen.append(p[\"strat\"])\n",
    "    handles = [Line2D([0], [0], marker=\"*\", color=\"w\",\n",
    "                      markerfacecolor=STRATEGY_COLORS[\"Baseline\"],\n",
    "                      markersize=10, label=\"Baseline\")]\n",
    "    for s in seen:\n",
    "        handles.append(Line2D([0], [0], marker=\"o\", color=\"w\",\n",
    "                              markerfacecolor=_strat_color(s),\n",
    "                              markersize=8, label=s))\n",
    "    ax.legend(handles=handles, fontsize=18, loc=\"upper left\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        from pathlib import Path as _P\n",
    "        fig.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "        fig.savefig(_P(save_path).with_suffix(\".pdf\"), bbox_inches=\"tight\")\n",
    "        print(f\"  Saved chart to {save_path} (+pdf)\")\n",
    "    if show:\n",
    "        plt.show()\n",
    "    return pts, fig\n",
    "\n",
    "\n",
    "\n",
    "def plot_accuracy_vs_compute_per_dataset(tbl, model_label, figsize_per=(6, 5), save_path=None, label_overrides=None, strip_variant=False):\n",
    "    \"\"\"One scatter plot per dataset: X = compute overhead (%), Y = EM improvement (pp).\"\"\"\n",
    "    all_datasets = list(dict.fromkeys(c[0] for c in tbl.columns))\n",
    "    datasets = [ds for ds in all_datasets if ds not in EXCLUDED_DATASETS]\n",
    "\n",
    "    bl = next((i for i in tbl.index if i[0] == \"Baseline\"), None)\n",
    "    if bl is None:\n",
    "        print(\"No baseline row found\"); return\n",
    "\n",
    "    ncols = min(len(datasets), 3)\n",
    "    nrows = (len(datasets) + ncols - 1) // ncols\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(figsize_per[0] * ncols, figsize_per[1] * nrows))\n",
    "    if nrows * ncols == 1:\n",
    "        axes = np.array([axes])\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for ax_i, ds in enumerate(datasets):\n",
    "        ax = axes[ax_i]\n",
    "\n",
    "        # Baseline TFLOPs for this dataset\n",
    "        bl_tf = _pv(tbl.at[bl, (ds, \"TFLOPs\")]) if (ds, \"TFLOPs\") in tbl.columns else None\n",
    "\n",
    "        pts = []\n",
    "        for idx in tbl.index:\n",
    "            strat, scorer = idx\n",
    "            if strat == \"Baseline\":\n",
    "                continue\n",
    "            strat_short = strat.split(\"\\n\")[0]\n",
    "\n",
    "            delta = _pv(tbl.at[idx, (ds, \"Δ\")]) if (ds, \"Δ\") in tbl.columns else None\n",
    "            tf = _pv(tbl.at[idx, (ds, \"TFLOPs\")]) if (ds, \"TFLOPs\") in tbl.columns else None\n",
    "\n",
    "            if delta is None or tf is None or bl_tf is None or bl_tf <= 0:\n",
    "                continue\n",
    "\n",
    "            overhead = (tf / bl_tf - 1) * 100\n",
    "            scorer_clean = scorer.replace(\"\\n\", \" \") if scorer != \"—\" else \"\"\n",
    "            label = _make_point_label(strat, scorer_clean, strat_short)\n",
    "            pts.append({\n",
    "                \"x\": overhead, \"y\": delta,\n",
    "                \"strat\": strat_short, \"scorer\": scorer_clean,\n",
    "                \"label\": label,\n",
    "            })\n",
    "\n",
    "        # Draw\n",
    "        _bl_x = 1.0\n",
    "        ax.scatter(_bl_x, 0, color=STRATEGY_COLORS[\"Baseline\"], s=120, marker=\"*\",\n",
    "                   zorder=5, edgecolors=\"k\", linewidths=0.5)\n",
    "\n",
    "        for p in pts:\n",
    "            c = _strat_color(p[\"strat\"])\n",
    "            ax.scatter(p[\"x\"], p[\"y\"], color=c, s=60, zorder=5, alpha=0.85,\n",
    "                       edgecolors=\"white\", linewidths=0.5)\n",
    "\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_title(ds, fontsize=12, fontweight=\"bold\")\n",
    "        ax.set_xlabel(\"Compute Overhead (%)\", fontsize=18)\n",
    "        ax.set_ylabel(\"EM Improvement (pp)\", fontsize=18)\n",
    "        ax.axhline(0, color=\"gray\", ls=\"--\", lw=0.7, alpha=0.4)\n",
    "        ax.tick_params(labelsize=18)\n",
    "        ax.grid(True, alpha=0.2)\n",
    "        if strip_variant:\n",
    "            import re as _re\n",
    "            for _p in pts:\n",
    "                _p[\"label\"] = _re.sub(r'\\s*\\([^)]*\\)$', '', _p[\"label\"])\n",
    "        _annotate_with_arrows(ax, pts, fontsize=10, arrow_len=55, label_overrides=label_overrides)\n",
    "\n",
    "    # Hide unused axes\n",
    "    for i in range(len(datasets), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "\n",
    "    # Shared legend\n",
    "    from matplotlib.lines import Line2D\n",
    "    seen = []\n",
    "    for ax_pts in [pts]:  # use last pts for legend; all share same strategies\n",
    "        pass\n",
    "    # Collect all strategies across datasets\n",
    "    all_strats = []\n",
    "    for idx in tbl.index:\n",
    "        s = idx[0].split(\"\\n\")[0]\n",
    "        if s not in all_strats and s != \"Baseline\":\n",
    "            all_strats.append(s)\n",
    "    handles = [Line2D([0], [0], marker=\"*\", color=\"w\",\n",
    "                      markerfacecolor=STRATEGY_COLORS[\"Baseline\"],\n",
    "                      markersize=10, label=\"Baseline\")]\n",
    "    for s in all_strats:\n",
    "        handles.append(Line2D([0], [0], marker=\"o\", color=\"w\",\n",
    "                              markerfacecolor=_strat_color(s),\n",
    "                              markersize=8, label=s))\n",
    "    fig.legend(handles=handles, fontsize=10.5, loc=\"lower center\",\n",
    "               ncol=len(handles), bbox_to_anchor=(0.5, -0.02))\n",
    "\n",
    "    fig.suptitle(f\"{model_label} — Per-Dataset Accuracy vs Compute\", fontsize=14, fontweight=\"bold\")\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "    if save_path:\n",
    "        from pathlib import Path as _P\n",
    "        fig.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "        fig.savefig(_P(save_path).with_suffix(\".pdf\"), bbox_inches=\"tight\")\n",
    "        print(f\"  Saved chart to {save_path} (+pdf)\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_accuracy_vs_compute_ratio(tbl, title, figsize=(11, 7), save_path=None, include_datasets=None, show=True, label_overrides=None, strip_variant=False, legend_loc=\"upper left\", ylim=None):\n",
    "    \"\"\"Scatter: X = TFLOPs / baseline_TFLOPs (ratio), Y = avg EM improvement (pp).\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    all_datasets = list(dict.fromkeys(c[0] for c in tbl.columns))\n",
    "    datasets = [ds for ds in all_datasets if ds not in EXCLUDED_DATASETS]\n",
    "    if include_datasets is not None:\n",
    "        datasets = [ds for ds in datasets if ds in include_datasets]\n",
    "    if EXCLUDED_DATASETS & set(all_datasets):\n",
    "        print(f\"Note: excluding {EXCLUDED_DATASETS & set(all_datasets)} from averaging\")\n",
    "\n",
    "    bl = next((i for i in tbl.index if i[0] == \"Baseline\"), None)\n",
    "    if bl is None:\n",
    "        print(\"No baseline row found\"); return\n",
    "\n",
    "    bl_tf = {}\n",
    "    for ds in datasets:\n",
    "        if (ds, \"TFLOPs\") in tbl.columns:\n",
    "            v = _pv(tbl.at[bl, (ds, \"TFLOPs\")])\n",
    "            if v and v > 0:\n",
    "                bl_tf[ds] = v\n",
    "\n",
    "    pts = []\n",
    "    for idx in tbl.index:\n",
    "        strat, scorer = idx\n",
    "        if strat == \"Baseline\":\n",
    "            continue\n",
    "        strat_short = strat.split(\"\\n\")[0]\n",
    "\n",
    "        deltas, ratios = [], []\n",
    "        for ds in datasets:\n",
    "            if (ds, \"Δ\") in tbl.columns:\n",
    "                d = _pv(tbl.at[idx, (ds, \"Δ\")])\n",
    "                if d is not None:\n",
    "                    deltas.append(d)\n",
    "            if (ds, \"TFLOPs\") in tbl.columns and ds in bl_tf:\n",
    "                t = _pv(tbl.at[idx, (ds, \"TFLOPs\")])\n",
    "                if t is not None:\n",
    "                    ratios.append(t / bl_tf[ds])\n",
    "\n",
    "        if not deltas or not ratios:\n",
    "            continue\n",
    "\n",
    "        scorer_clean = scorer.replace(\"\\n\", \" \") if scorer != \"—\" else \"\"\n",
    "        pts.append({\n",
    "            \"x\": np.mean(ratios),\n",
    "            \"y\": np.mean(deltas),\n",
    "            \"strat\": strat_short,\n",
    "            \"scorer\": scorer_clean,\n",
    "            \"label\": _make_point_label(strat, scorer_clean, strat_short),\n",
    "        })\n",
    "\n",
    "    # Baseline at ratio = 1.0\n",
    "    ax.scatter(1.0, 0, color=STRATEGY_COLORS[\"Baseline\"], s=140, marker=\"*\",\n",
    "               zorder=5, edgecolors=\"k\", linewidths=0.5)\n",
    "    ax.annotate(\"Baseline\", (1.0, 0), xytext=(10, -12),\n",
    "                textcoords=\"offset points\", fontsize=18)\n",
    "\n",
    "    for p in pts:\n",
    "        c = _strat_color(p[\"strat\"])\n",
    "        ax.scatter(p[\"x\"], p[\"y\"], color=c, s=70, zorder=5, alpha=0.85,\n",
    "                   edgecolors=\"white\", linewidths=0.5)\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xlabel(\"Avg. Compute Ratio (TTS / Baseline, log scale)\", fontsize=18)\n",
    "    ax.set_ylabel(\"Avg. EM Improvement vs Baseline (pp)\", fontsize=18)\n",
    "    ax.set_title(title, fontsize=13, fontweight=\"bold\")\n",
    "    ax.axhline(0, color=\"gray\", ls=\"--\", lw=0.8, alpha=0.4)\n",
    "    ax.axvline(1.0, color=\"gray\", ls=\"--\", lw=0.8, alpha=0.4)\n",
    "    ax.tick_params(labelsize=18)\n",
    "    ax.grid(True, alpha=0.2)\n",
    "    if strip_variant:\n",
    "        import re as _re\n",
    "        for _p in pts:\n",
    "            _p[\"label\"] = _re.sub(r'\\s*\\([^)]*\\)$', '', _p[\"label\"])\n",
    "    _annotate_with_arrows(ax, pts, fontsize=18, arrow_len=80, label_overrides=label_overrides)\n",
    "\n",
    "    from matplotlib.lines import Line2D\n",
    "    seen = []\n",
    "    for p in pts:\n",
    "        if p[\"strat\"] not in seen:\n",
    "            seen.append(p[\"strat\"])\n",
    "    handles = [Line2D([0], [0], marker=\"*\", color=\"w\",\n",
    "                      markerfacecolor=STRATEGY_COLORS[\"Baseline\"],\n",
    "                      markersize=10, label=\"Baseline\")]\n",
    "    for s in seen:\n",
    "        handles.append(Line2D([0], [0], marker=\"o\", color=\"w\",\n",
    "                              markerfacecolor=_strat_color(s),\n",
    "                              markersize=8, label=s))\n",
    "    ax.legend(handles=handles, fontsize=18, loc=legend_loc)\n",
    "\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        from pathlib import Path as _P\n",
    "        fig.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "        fig.savefig(_P(save_path).with_suffix(\".pdf\"), bbox_inches=\"tight\")\n",
    "        print(f\"  Saved chart to {save_path} (+pdf)\")\n",
    "    if show:\n",
    "        plt.show()\n",
    "    return pts, fig\n",
    "\n",
    "\n",
    "def plot_accuracy_vs_compute_ratio_per_dataset(tbl, model_label, figsize_per=(6, 5), save_path=None, label_overrides=None, strip_variant=False):\n",
    "    \"\"\"One scatter per dataset: X = TFLOPs / baseline (ratio), Y = EM improvement (pp).\"\"\"\n",
    "    all_datasets = list(dict.fromkeys(c[0] for c in tbl.columns))\n",
    "    datasets = [ds for ds in all_datasets if ds not in EXCLUDED_DATASETS]\n",
    "\n",
    "    bl = next((i for i in tbl.index if i[0] == \"Baseline\"), None)\n",
    "    if bl is None:\n",
    "        print(\"No baseline row found\"); return\n",
    "\n",
    "    ncols = min(len(datasets), 3)\n",
    "    nrows = (len(datasets) + ncols - 1) // ncols\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(figsize_per[0] * ncols, figsize_per[1] * nrows))\n",
    "    if nrows * ncols == 1:\n",
    "        axes = np.array([axes])\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for ax_i, ds in enumerate(datasets):\n",
    "        ax = axes[ax_i]\n",
    "        bl_tf = _pv(tbl.at[bl, (ds, \"TFLOPs\")]) if (ds, \"TFLOPs\") in tbl.columns else None\n",
    "\n",
    "        pts = []\n",
    "        for idx in tbl.index:\n",
    "            strat, scorer = idx\n",
    "            if strat == \"Baseline\":\n",
    "                continue\n",
    "            strat_short = strat.split(\"\\n\")[0]\n",
    "\n",
    "            delta = _pv(tbl.at[idx, (ds, \"Δ\")]) if (ds, \"Δ\") in tbl.columns else None\n",
    "            tf = _pv(tbl.at[idx, (ds, \"TFLOPs\")]) if (ds, \"TFLOPs\") in tbl.columns else None\n",
    "\n",
    "            if delta is None or tf is None or bl_tf is None or bl_tf <= 0:\n",
    "                continue\n",
    "\n",
    "            ratio = tf / bl_tf\n",
    "            scorer_clean = scorer.replace(\"\\n\", \" \") if scorer != \"—\" else \"\"\n",
    "            label = _make_point_label(strat, scorer_clean, strat_short)\n",
    "            c = _strat_color(strat_short)\n",
    "            ax.scatter(ratio, delta, color=c, s=60, zorder=5, alpha=0.85,\n",
    "                       edgecolors=\"white\", linewidths=0.5)\n",
    "            pts.append({\"x\": ratio, \"y\": delta, \"label\": label, \"strat\": strat_short, \"scorer\": scorer_clean})\n",
    "\n",
    "        ax.scatter(1.0, 0, color=STRATEGY_COLORS[\"Baseline\"], s=120, marker=\"*\",\n",
    "                   zorder=5, edgecolors=\"k\", linewidths=0.5)\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_title(ds, fontsize=12, fontweight=\"bold\")\n",
    "        ax.set_xlabel(\"Compute Ratio (TTS / Baseline)\", fontsize=18)\n",
    "        ax.set_ylabel(\"EM Improvement (pp)\", fontsize=18)\n",
    "        ax.axhline(0, color=\"gray\", ls=\"--\", lw=0.7, alpha=0.4)\n",
    "        ax.axvline(1.0, color=\"gray\", ls=\"--\", lw=0.7, alpha=0.4)\n",
    "        ax.tick_params(labelsize=18)\n",
    "        ax.grid(True, alpha=0.2)\n",
    "        if strip_variant:\n",
    "            import re as _re\n",
    "            for _p in pts:\n",
    "                _p[\"label\"] = _re.sub(r'\\s*\\([^)]*\\)$', '', _p[\"label\"])\n",
    "        _annotate_with_arrows(ax, pts, fontsize=10, arrow_len=55, label_overrides=label_overrides)\n",
    "\n",
    "    for i in range(len(datasets), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "\n",
    "    # Shared legend\n",
    "    from matplotlib.lines import Line2D\n",
    "    all_strats = []\n",
    "    for idx in tbl.index:\n",
    "        s = idx[0].split(\"\\n\")[0]\n",
    "        if s not in all_strats and s != \"Baseline\":\n",
    "            all_strats.append(s)\n",
    "    handles = [Line2D([0], [0], marker=\"*\", color=\"w\",\n",
    "                      markerfacecolor=STRATEGY_COLORS[\"Baseline\"],\n",
    "                      markersize=10, label=\"Baseline\")]\n",
    "    for s in all_strats:\n",
    "        handles.append(Line2D([0], [0], marker=\"o\", color=\"w\",\n",
    "                              markerfacecolor=_strat_color(s),\n",
    "                              markersize=8, label=s))\n",
    "    fig.legend(handles=handles, fontsize=10.5, loc=\"lower center\",\n",
    "               ncol=len(handles), bbox_to_anchor=(0.5, -0.02))\n",
    "\n",
    "    fig.suptitle(f\"{model_label} — Per-Dataset Accuracy vs Compute Ratio\", fontsize=14, fontweight=\"bold\")\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "    if save_path:\n",
    "        from pathlib import Path as _P\n",
    "        fig.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "        fig.savefig(_P(save_path).with_suffix(\".pdf\"), bbox_inches=\"tight\")\n",
    "        print(f\"  Saved chart to {save_path} (+pdf)\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Chart helpers defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Ratio Analysis\n",
    "\n",
    "Same improvement metric but X-axis shows **TTS compute / baseline compute** (ratio, log scale).  \n",
    "Baseline sits at x=1. A point at x=10 uses 10x the baseline compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qwen2.5-Math-7B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Per-dataset charts ────────────────────────────────────────────────────────\n",
    "\n",
    "if _tbl_q25 is not None:\n",
    "    plot_accuracy_vs_compute_ratio_per_dataset(_tbl_q25, \"Qwen2.5-Math-7B\",\n",
    "        save_path=_CHARTS_DIR / \"qwen25_per_dataset_ratio.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Aggregate chart ───────────────────────────────────────────────────────────\n",
    "\n",
    "_Q25_LABEL_OVERRIDES = {\n",
    "    # MUR\n",
    "    (\"MUR\", \"prm\"):            {\"xytext\": (-64, 24), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"bottom\", \"arrow\": True},\n",
    "    (\"MUR\", \"perplexity\"):     {\"xytext\": (32, 32), \"textcoords\": \"offset points\", \"ha\": \"center\", \"va\": \"bottom\"},\n",
    "    (\"MUR\", \"sequence_prob\"):  {\"xytext\": (32, 10), \"textcoords\": \"offset points\", \"ha\": \"left\"},\n",
    "    (\"MUR\", \"entropy\"):        {\"xytext\": (-92, 20), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"bottom\", \"arrow\": True},\n",
    "    (\"MUR\", \"uncertainty_pd\"): {\"xytext\": (172, -18), \"textcoords\": \"offset points\", \"ha\": \"right\"},\n",
    "    # Beam Search\n",
    "    (\"Beam Search\", \"prm\"):            {\"xytext\": (-92, -32), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"top\", \"arrow\": True},\n",
    "    (\"Beam Search\", \"perplexity\"):     {\"xytext\": (48, 2), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"bottom\", \"arrow\": True},\n",
    "    (\"Beam Search\", \"entropy\"):        {\"xytext\": (48, -16), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"top\", \"arrow\": True},\n",
    "    (\"Beam Search\", \"sequence_prob\"):  {\"xytext\": (148, -48), \"textcoords\": \"offset points\", \"ha\": \"right\", \"va\": \"bottom\", \"arrow\": True},\n",
    "    (\"Beam Search\", \"uncertainty_pd\"): {\"xytext\": (120, 48), \"textcoords\": \"offset points\", \"ha\": \"right\", \"va\": \"top\", \"arrow\": True},\n",
    "    (\"Beam Search\", \"uhead\"):          {\"xytext\": (64, 16), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"bottom\", \"arrow\": True},\n",
    "    # Offline BoN\n",
    "    (\"Offline BoN\", \"prm\"):           {\"xytext\": (48, 24), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"top\", \"arrow\": True},\n",
    "    (\"Offline BoN\", \"perplexity\"):    {\"xytext\": (-132, 6), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"bottom\", \"arrow\": True},\n",
    "    (\"Offline BoN\", \"entropy\"):       {\"xytext\": (-48, 0), \"textcoords\": \"offset points\", \"ha\": \"right\", \"va\": \"top\", \"arrow\": True},\n",
    "    (\"Offline BoN\", \"sequence_prob\"): {\"xytext\": (-24, 0), \"textcoords\": \"offset points\", \"ha\": \"right\", \"va\": \"bottom\", \"arrow\": True},\n",
    "    (\"Offline BoN\", \"pd_gap\"):        {\"xytext\": (-120, 0), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"top\", \"arrow\": True},\n",
    "    # Self-Consistency & Extended Thinking\n",
    "    (\"Self-Consistency\", \"\"):          {\"xytext\": (24, 12), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"bottom\", \"arrow\": True},\n",
    "}\n",
    "\n",
    "if _tbl_q25 is not None:\n",
    "    print(\"\\n=== Qwen2.5-Math-7B — Aggregate (excl. Minerva Math) ===\\n\")\n",
    "    pts, fig = plot_accuracy_vs_compute_ratio(_tbl_q25, \"\",\n",
    "        save_path=_CHARTS_DIR / \"qwen25_aggregate_ratio.png\", show=False,\n",
    "        label_overrides=_Q25_LABEL_OVERRIDES, strip_variant=True)\n",
    "    if pts:\n",
    "        print(f\"{'Strategy':<35} {'Scorer':<25} {'Avg Δ EM (pp)':>14} {'Avg Ratio (x)':>14}\")\n",
    "        print(\"─\" * 92)\n",
    "        for p in sorted(pts, key=lambda x: x[\"y\"], reverse=True):\n",
    "            print(f\"{p['strat']:<35} {p['scorer']:<25} {p['y']:>+13.1f} {p['x']:>13.1f}x\")\n",
    "        print()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qwen3-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Per-dataset charts ────────────────────────────────────────────────────────\n",
    "\n",
    "if _tbl_q3 is not None:\n",
    "    plot_accuracy_vs_compute_ratio_per_dataset(_tbl_q3, \"Qwen3-8B\",\n",
    "        save_path=_CHARTS_DIR / \"qwen3_per_dataset_ratio.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── HumanEval-Plus separately ──────────────────────────────────────────────────\n",
    "\n",
    "if _tbl_q3 is not None:\n",
    "    _Q3_HUMANEVAL_OVERRIDES = {\n",
    "        # MUR\n",
    "        (\"MUR\", \"entropy\"):            {\"xytext\": (-132, -32), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"bottom\"},\n",
    "        (\"MUR\", \"sequence_prob\"):      {\"xytext\": (-48, -24), \"textcoords\": \"offset points\", \"ha\": \"right\", \"va\": \"top\"},\n",
    "        (\"MUR\", \"perplexity\"):         {\"xytext\": (-164, -32), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"top\"},\n",
    "        (\"MUR\", \"uncertainty_pd\"):     {\"xytext\": (-48, -48), \"textcoords\": \"offset points\", \"ha\": \"right\", \"va\": \"bottom\"},\n",
    "        (\"MUR\", \"prm\"):               {\"xytext\": (90, 32), \"textcoords\": \"offset points\", \"ha\": \"right\", \"va\": \"top\"},\n",
    "        # Beam Search\n",
    "        (\"Beam Search\", \"prm\"):            {\"xytext\": (-72, -32), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"top\"},\n",
    "        (\"Beam Search\", \"entropy\"):        {\"xytext\": (-120, -32), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"bottom\"},\n",
    "        (\"Beam Search\", \"uncertainty_pd\"): {\"xytext\": (-48, -20), \"textcoords\": \"offset points\", \"ha\": \"right\", \"va\": \"top\"},\n",
    "        (\"Beam Search\", \"perplexity\"):     {\"xytext\": (-148, -24), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"top\"},\n",
    "        (\"Beam Search\", \"sequence_prob\"):  {\"xytext\": (-32, -64), \"textcoords\": \"offset points\", \"ha\": \"right\", \"va\": \"bottom\"},\n",
    "        # Offline BoN\n",
    "        (\"Offline BoN\", \"pd_gap\"):         {\"xytext\": (-120, 48), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"bottom\"},\n",
    "        (\"Offline BoN\", \"prm\"):            {\"xytext\": (40, -24), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"top\"},\n",
    "        (\"Offline BoN\", \"perplexity\"):     {\"xytext\": (-48, 24), \"textcoords\": \"offset points\", \"ha\": \"right\", \"va\": \"bottom\"},\n",
    "        (\"Offline BoN\", \"entropy\"):        {\"xytext\": (-32, -32), \"textcoords\": \"offset points\", \"ha\": \"right\", \"va\": \"top\"},\n",
    "        (\"Offline BoN\", \"sequence_prob\"):  {\"xytext\": (24, -24), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"top\"},\n",
    "        # Others\n",
    "        (\"Extended Thinking\", \"\"):         {\"xytext\": (-148, 12), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"bottom\"},\n",
    "    }\n",
    "\n",
    "    print(\"\\n=== Qwen3-8B — HumanEval-Plus ===\\n\")\n",
    "    pts, fig = plot_accuracy_vs_compute_ratio(_tbl_q3, \"\",\n",
    "        save_path=_CHARTS_DIR / \"qwen3_humaneval_ratio.png\",\n",
    "        include_datasets={\"HumanEval-Plus\"}, show=False,\n",
    "        label_overrides=_Q3_HUMANEVAL_OVERRIDES, strip_variant=True)\n",
    "    if pts:\n",
    "        print(f\"{'Strategy':<35} {'Scorer':<25} {'Avg Δ EM (pp)':>14} {'Avg Ratio (x)':>14}\")\n",
    "        print(\"─\" * 92)\n",
    "        for p in sorted(pts, key=lambda x: x[\"y\"], reverse=True):\n",
    "            print(f\"{p['strat']:<35} {p['scorer']:<25} {p['y']:>+13.1f} {p['x']:>13.1f}x\")\n",
    "        print()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Aggregate chart (AIME only) ───────────────────────────────────────────────\n",
    "\n",
    "_AIME_DATASETS = {\"AIME 2024\", \"AIME 2025\"}\n",
    "\n",
    "if _tbl_q3 is not None:\n",
    "    _Q3_AIME_OVERRIDES = {\n",
    "        (\"Beam Search\", \"prm\"):        {\"xytext\": (-24, -24), \"textcoords\": \"offset points\", \"ha\": \"right\", \"va\": \"top\", \"arrow\": True},\n",
    "        (\"Beam Search\", \"entropy\"):    {\"xytext\": (-92, -16), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"bottom\", \"arrow\": True},\n",
    "        (\"Beam Search\", \"perplexity\"):    {\"xytext\": (-58, -32), \"textcoords\": \"offset points\", \"ha\": \"center\", \"va\": \"top\", \"arrow\": True},\n",
    "        (\"Beam Search\", \"uncertainty_pd\"): {\"xytext\": (-92, -24), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"top\", \"arrow\": True},\n",
    "        (\"Beam Search\", \"sequence_prob\"):  {\"xytext\": (64, 32), \"textcoords\": \"offset points\", \"ha\": \"right\", \"va\": \"bottom\", \"arrow\": True},\n",
    "        (\"MUR\", \"prm\"):               {\"xytext\": (32, -24), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"top\", \"arrow\": True},\n",
    "        (\"MUR\", \"entropy\"):           {\"xytext\": (-54, -16), \"textcoords\": \"offset points\", \"ha\": \"right\", \"va\": \"bottom\", \"arrow\": True},\n",
    "        (\"MUR\", \"perplexity\"):        {\"xytext\": (-100, 8), \"textcoords\": \"offset points\", \"ha\": \"center\", \"va\": \"top\", \"arrow\": True},\n",
    "        (\"MUR\", \"sequence_prob\"):     {\"xytext\": (-150, 16), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"bottom\", \"arrow\": True},\n",
    "        (\"MUR\", \"uncertainty_pd\"):    {\"xytext\": (-32, -18), \"textcoords\": \"offset points\", \"ha\": \"right\", \"va\": \"top\", \"arrow\": True},\n",
    "        (\"Offline BoN\", \"prm\"):        {\"xytext\": (32, -24), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"top\", \"arrow\": True},\n",
    "        (\"Offline BoN\", \"entropy\"):    {\"xytext\": (-64, -32), \"textcoords\": \"offset points\", \"ha\": \"right\", \"va\": \"bottom\", \"arrow\": True},\n",
    "        (\"Offline BoN\", \"perplexity\"): {\"xytext\": (-64, -32), \"textcoords\": \"offset points\", \"ha\": \"center\", \"va\": \"top\", \"arrow\": True},\n",
    "        (\"Offline BoN\", \"sequence_prob\"): {\"xytext\": (-150, 16), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"bottom\", \"arrow\": True},\n",
    "        (\"Offline BoN\", \"pd_gap\"):     {\"xytext\": (-48, -18), \"textcoords\": \"offset points\", \"ha\": \"right\", \"va\": \"top\", \"arrow\": True},\n",
    "        (\"Self-Consistency\", \"\"):      {\"xytext\": (-132, 24), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"bottom\", \"arrow\": True},\n",
    "        (\"Extended Thinking\", \"\"):     {\"xytext\": (-150, 16), \"textcoords\": \"offset points\", \"ha\": \"left\", \"va\": \"bottom\", \"arrow\": True},\n",
    "    }\n",
    "\n",
    "    print(\"\\n=== Qwen3-8B — AIME Aggregate (AIME 2024 + AIME 2025) ===\\n\")\n",
    "    pts, fig = plot_accuracy_vs_compute_ratio(_tbl_q3, \"\",\n",
    "        save_path=_CHARTS_DIR / \"qwen3_aime_aggregate_ratio.png\",\n",
    "        include_datasets=_AIME_DATASETS, show=False,\n",
    "        label_overrides=_Q3_AIME_OVERRIDES, strip_variant=True,\n",
    "        legend_loc=\"upper right\", ylim=(-6, 10))\n",
    "    if pts:\n",
    "        print(f\"{'Strategy':<35} {'Scorer':<25} {'Avg Δ EM (pp)':>14} {'Avg Ratio (x)':>14}\")\n",
    "        print(\"─\" * 92)\n",
    "        for p in sorted(pts, key=lambda x: x[\"y\"], reverse=True):\n",
    "            print(f\"{p['strat']:<35} {p['scorer']:<25} {p['y']:>+13.1f} {p['x']:>13.1f}x\")\n",
    "        print()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Results — LaTeX Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Final Results → LaTeX tables for appendix ─────────────────────────────────\n",
    "\n",
    "def results_to_latex(tbl, caption, label, compact=True):\n",
    "    \"\"\"Convert a combined results table to a LaTeX table for the appendix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tbl : pd.DataFrame\n",
    "        Multi-index table with (Strategy, Scorer) rows and (Dataset, Metric) cols.\n",
    "    caption : str\n",
    "        LaTeX caption.\n",
    "    label : str\n",
    "        LaTeX label for \\\\ref.\n",
    "    compact : bool\n",
    "        If True, show only metric + Δ (no TFLOPs) to save space.\n",
    "    \"\"\"\n",
    "    datasets = list(dict.fromkeys(c[0] for c in tbl.columns))\n",
    "    # Per-dataset metric label: first non-Δ non-TFLOPs column for each dataset\n",
    "    # Number of columns per dataset: metric + Δ [+ TFLOPs]\n",
    "    n_cols_per_ds = 2 if compact else 3\n",
    "    _ds_metric = {ds: next(c[1] for c in tbl.columns if c[0] == ds and c[1] not in (\"Δ\", \"TFLOPs\")) for ds in datasets}\n",
    "\n",
    "\n",
    "    \n",
    "    # LaTeX-safe column header mapping\n",
    "    _col_header = {\"Δ\": r\"$\\Delta$\", \"EM (%)\": r\"EM (\\%)\", \"Score (%)\": r\"Score (\\%)\"}\n",
    "    \n",
    "    n_ds = len(datasets)\n",
    "\n",
    "    \n",
    "    # Build header\n",
    "    lines = []\n",
    "    lines.append(r\"\\begin{table*}[h]\")\n",
    "    lines.append(r\"\\centering\")\n",
    "    lines.append(r\"\\footnotesize\")\n",
    "    \n",
    "    col_spec = \"ll|\" + \"|\".join([\"r\" * n_cols_per_ds] * n_ds)\n",
    "    lines.append(r\"\\resizebox{\\textwidth}{!}{\\begin{tabular}{\" + col_spec + \"}\")\n",
    "    lines.append(r\"\\toprule\")\n",
    "    \n",
    "    # Dataset header row\n",
    "    ds_header = r\"\\textbf{Strategy} & \\textbf{Scorer}\"\n",
    "    for ds in datasets:\n",
    "        ds_clean = ds.replace(\"_\", r\"\\_\")\n",
    "        ds_header += f\" & \\\\multicolumn{{{n_cols_per_ds}}}{{c|}}{{{ds_clean}}}\"\n",
    "    # Remove trailing | from last multicolumn\n",
    "    ds_header = ds_header.rsplit(\"|}\", 1)\n",
    "    ds_header = \"|}\".join(ds_header[:-1]) + \"}\" + ds_header[-1] if len(ds_header) > 1 else ds_header[0]\n",
    "    ds_header = ds_header.rstrip(\"|}\")  + \"}\"\n",
    "    lines.append(ds_header + r\" \\\\\")\n",
    "    \n",
    "    # Metric sub-header\n",
    "    metric_header = \" & \"\n",
    "    for ds in datasets:\n",
    "        for ck in ([_ds_metric[ds], \"Δ\"] if compact else [_ds_metric[ds], \"Δ\", \"TFLOPs\"]):\n",
    "            metric_header += f\" & {_col_header.get(ck, ck.replace(chr(37), chr(92) + chr(37)))}\"\n",
    "    lines.append(metric_header + r\" \\\\\")\n",
    "    lines.append(r\"\\midrule\")\n",
    "    \n",
    "    # Data rows\n",
    "    prev_strategy = None\n",
    "    for idx in tbl.index:\n",
    "        strategy, scorer = idx\n",
    "        # Clean strategy name (remove newlines from beam search variants)\n",
    "        strat_clean = strategy.replace(\"\\n\", \" \")\n",
    "        \n",
    "        # Add midrule between strategy groups\n",
    "        if prev_strategy is not None and strat_clean != prev_strategy:\n",
    "            lines.append(r\"\\midrule\")\n",
    "        prev_strategy = strat_clean\n",
    "        \n",
    "        # Escape LaTeX special chars\n",
    "        strat_clean = strat_clean.replace(\"_\", r\"\\_\")\n",
    "        scorer_clean = str(scorer).replace(\"\\n\", \" \").replace(\"_\", r\"\\_\").replace(\"—\", \"---\")\n",
    "        \n",
    "        row = f\"{strat_clean} & {scorer_clean}\"\n",
    "        for ds in datasets:\n",
    "            for ck in ([_ds_metric[ds], \"Δ\"] if compact else [_ds_metric[ds], \"Δ\", \"TFLOPs\"]):\n",
    "                col = (ds, ck)\n",
    "                if col in tbl.columns:\n",
    "                    val = str(tbl.loc[idx, col])\n",
    "                    if val == \"nan\" or val == \"\":\n",
    "                        val = \"---\"\n",
    "                    # Clean ± for LaTeX\n",
    "                    val = val.replace(\"±\", r\"$\\pm$\").replace(\"+/-\", r\"$\\pm$\").replace(\"Δ\", r\"$\\Delta$\")\n",
    "                    row += f\" & {val}\"\n",
    "                else:\n",
    "                    row += \" & ---\"\n",
    "        lines.append(row + r\" \\\\\")\n",
    "    \n",
    "    lines.append(r\"\\bottomrule\")\n",
    "    lines.append(r\"\\end{tabular}}\")\n",
    "    lines.append(r\"\\caption{\" + caption + \"}\")\n",
    "    lines.append(r\"\\label{\" + label + \"}\")\n",
    "    lines.append(r\"\\end{table*}\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# ── Generate LaTeX for Qwen2.5 ───────────────────────────────────────────────\n",
    "if _tbl_q25_combined is not None:\n",
    "    latex_q25 = results_to_latex(\n",
    "        _tbl_q25_combined,\n",
    "        caption=\"Full results for Qwen2.5-Math-7B-Instruct across mathematical benchmarks. \"\n",
    "                \"For each strategy--scorer pair, we report exact match (EM) accuracy with standard deviation, \"\n",
    "                \"improvement over the baseline ($\\\\Delta$), and compute cost in TFLOPs.\",\n",
    "        label=\"tab:qwen25-full-results\",\n",
    "        compact=False,\n",
    "    )\n",
    "    print(\"% \" + \"=\" * 78)\n",
    "    print(\"% Qwen2.5-Math-7B-Instruct — Full Results\")\n",
    "    print(\"% \" + \"=\" * 78)\n",
    "    print(latex_q25)\n",
    "    print()\n",
    "\n",
    "# ── Generate LaTeX for Qwen3 ─────────────────────────────────────────────────\n",
    "if _tbl_q3_combined is not None:\n",
    "    latex_q3 = results_to_latex(\n",
    "        _tbl_q3_combined,\n",
    "        caption=\"Full results for Qwen3-8B across mathematical and coding benchmarks. \"\n",
    "                \"For each strategy--scorer pair, we report accuracy with standard deviation, \"\n",
    "                \"improvement over the baseline ($\\\\Delta$), and compute cost in TFLOPs.\",\n",
    "        label=\"tab:qwen3-full-results\",\n",
    "        compact=False,\n",
    "    )\n",
    "    print(\"% \" + \"=\" * 78)\n",
    "    print(\"% Qwen3-8B — Full Results\")\n",
    "    print(\"% \" + \"=\" * 78)\n",
    "    print(latex_q3)\n",
    "\n",
    "\n",
    "# ── Save to .tex files for direct \\input in the paper ────────────────────────\n",
    "_TABLES_DIR = _Path(\"../_ACL_2026_paper/tables\")\n",
    "_TABLES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if _tbl_q25_combined is not None:\n",
    "    _path = _TABLES_DIR / \"qwen25_full_results.tex\"\n",
    "    _path.write_text(latex_q25)\n",
    "    print(f\"\\nSaved: {_path}\")\n",
    "\n",
    "if _tbl_q3_combined is not None:\n",
    "    _path = _TABLES_DIR / \"qwen3_full_results.tex\"\n",
    "    _path.write_text(latex_q3)\n",
    "    print(f\"Saved: {_path}\")\n",
    "\n",
    "print(\"\\nTo include in appendix, add:\")\n",
    "print(r\"  \\input{tables/qwen25_full_results}\")\n",
    "print(r\"  \\input{tables/qwen3_full_results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Before committing**, clear all notebook outputs to keep the file lightweight:\n",
    "\n",
    "```bash\n",
    "jupyter nbconvert --clear-output --inplace notebooks/wandb_results_analysis.ipynb\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm-polygraph-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}