# AIME 2025 Results

Dataset: [test-time-compute/aime_2025](https://huggingface.co/datasets/test-time-compute/aime_2025) (30 samples)

---

## Summary

| Strategy | Model | Accuracy | Avg Tokens | Avg TFLOPs | WandB Runs | Notes |
|----------|-------|----------|------------|------------|------------|-------|
| DeepConf (b=16) | Qwen3-8B | 16.7% (5/30) | TBD | TBD | - | vLLM, non-thinking mode |
| Self-Consistency (n=16) | Qwen3-8B | TBD | TBD | TBD | - | vLLM, non-thinking mode |

---

## DeepConf

### Qwen3-8B

**Configuration**:
- Strategy: DeepConf Offline
- Budget: 16 traces
- Filter: top10
- Window: 2048
- Temperature: 0.7 (non-thinking mode)
- Top-p: 0.8
- Max tokens: 32768
- Thinking mode: disabled

**Config file**: `config/experiments/deepconf/deepconf_vllm_qwen3_aime2025_nothink.yaml`

---

## Self-Consistency

### Qwen3-8B

**Configuration**:
- Strategy: Self-Consistency
- Num paths: 16
- Temperature: 0.7 (non-thinking mode)
- Top-p: 0.8
- Selection: Majority voting
- Thinking mode: disabled

**Config file**: `config/experiments/self_consistency/sc_vllm_qwen3_aime2025.yaml`
