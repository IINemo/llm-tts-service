# AIME 2025 Results

Dataset: [test-time-compute/aime_2025](https://huggingface.co/datasets/test-time-compute/aime_2025) (30 samples)

---

## Summary

| Strategy | Model | Accuracy | Avg Tokens | Avg TFLOPs | WandB Runs | Notes |
|----------|-------|----------|------------|------------|------------|-------|
| DeepConf (b=16) | Qwen3-8B | 73.3% (22/30) | TBD | TBD | [runs](https://wandb.ai/nlpresearch.group/llm-tts-eval-aime2025-deepconf-qwen3-8b) | vLLM backend |
| Self-Consistency (n=16) | Qwen3-8B | TBD | TBD | TBD | - | vLLM backend |

---

## DeepConf

### Qwen3-8B

**Configuration**:
- Strategy: DeepConf Offline
- Budget: 16 traces
- Filter: top10
- Window: 2048
- Temperature: 0.6
- Max tokens: 32768

**Config file**: `config/experiments/deepconf/deepconf_qwen3_aime2025.yaml`

---

## Self-Consistency

### Qwen3-8B

**Configuration**:
- Strategy: Self-Consistency
- Num paths: 16
- Temperature: 0.6
- Selection: Majority voting

**Config file**: `config/experiments/self_consistency/sc_qwen3_aime2025.yaml`
